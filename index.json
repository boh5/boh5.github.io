[{"categories":["学习笔记","K8s"],"content":"1. Service 介绍 在kubernetes中，pod是应用程序的载体，我们可以通过pod的ip来访问应用程序，但是pod的ip地址不是固定的，这也就意味着不方便直接采用pod的ip对服务进行访问。 为了解决这个问题，kubernetes提供了Service资源，Service会对提供同一个服务的多个pod进行聚合，并且提供一个统一的入口地址。通过访问Service的入口地址就能访问到后面的pod服务。 Service在很多情况下只是一个概念，真正起作用的其实是kube-proxy服务进程，每个Node节点上都运行着一个kube-proxy服务进程。当创建Service的时候会通过api-server向etcd写入创建的service的信息，而kube-proxy会基于监听的机制发现这种Service的变动，然后它会将最新的Service信息转换成对应的访问规则。 ","date":"2022-08-21","objectID":"/posts/notes/devops/k8s/itheima/5-k8s-service-advanced/:1:0","tags":["K8s","Kubernetes","pod","service","ingress"],"title":"K8s 学习笔记（五）Service 详解","uri":"/posts/notes/devops/k8s/itheima/5-k8s-service-advanced/"},{"categories":["学习笔记","K8s"],"content":"1.1 kube-proxy 的三种工作模式 1.1.1 userspace模式 userspace模式下，kube-proxy会为每一个Service创建一个监听端口，发向Cluster IP的请求被Iptables规则重定向到kube-proxy监听的端口上，kube-proxy根据LB算法选择一个提供服务的Pod并和其建立链接，以将请求转发到Pod上。 kube-proxy充当了一个四层负责均衡器的角色 kube-proxy运行在userspace中，在进行转发处理时会增加内核和用户空间之间的数据拷贝，虽然比较稳定，但是效率比较低。 1.1.2 iptables 模式 iptables模式下，kube-proxy为service后端的每个Pod创建对应的iptables规则，直接将发向Cluster IP的请求重定向到一个Pod IP。 kube-proxy不承担四层负责均衡器的角色，只负责创建iptables规则 较userspace模式效率更高，但不能提供灵活的LB策略，当后端Pod不可用时也无法进行重试 1.1.3 ipvs 模式 pvs模式和iptables类似，kube-proxy监控Pod的变化并创建相应的ipvs规则。 ipvs相对iptables转发效率更高 ipvs支持更多的LB算法 此模式必须安装ipvs内核模块，否则会降级为iptables 启用 ipvs： # 编辑 kube-proxy 的 ConfigMap，设置 data.config_conf.mode = \"ipvs\" kubectl edit cm kube-proxy -n kube-system # 删除已存在的 kube-proxy，让系统新建 kubectl delete pod -l k8s-app=kube-proxy -n kube-system ","date":"2022-08-21","objectID":"/posts/notes/devops/k8s/itheima/5-k8s-service-advanced/:1:1","tags":["K8s","Kubernetes","pod","service","ingress"],"title":"K8s 学习笔记（五）Service 详解","uri":"/posts/notes/devops/k8s/itheima/5-k8s-service-advanced/"},{"categories":["学习笔记","K8s"],"content":"2. Service 类型 Service 的资源清单 apiVersion: v1 # 资源版本 kind: Service # 资源类型 metadata: # 元数据 name: service # 资源名称 namespace: dev # 命名空间 spec: # 描述 selector: # 标签选择器，用于确定当前service代理哪些pod app: nginx type: ClusterIP # Service类型，指定service的访问方式 clusterIP: '' # 虚拟服务的ip地址，默认随机值 sessionAffinity: ClientIP # session亲和性，支持ClientIP(同一个客户的的请求打到同一个pod)、None两个选项 ports: # 端口信息 - protocol: TCP port: 3017 # service端口 targetPort: 5003 # pod端口 nodePort: 31122 # 主机端口 Service 类型： ClusterIP：默认值，它是Kubernetes系统自动分配的虚拟IP，只能在集群内部访问 HeadLiness(ClusterIP 类型，并把 clusterIP 设为 None)：这类Service不会分配Cluster IP，如果想要访问service，只能通过service的域名进行查询 NodePort：将Service通过指定的Node上的端口暴露给外部，通过此方法，就可以在集群外部访问服务 LoadBalancer：使用外接负载均衡器完成到服务的负载分发，注意此模式需要外部云环境支持 ExternalName： 把集群外部的服务引入集群内部，直接使用 ","date":"2022-08-21","objectID":"/posts/notes/devops/k8s/itheima/5-k8s-service-advanced/:2:0","tags":["K8s","Kubernetes","pod","service","ingress"],"title":"K8s 学习笔记（五）Service 详解","uri":"/posts/notes/devops/k8s/itheima/5-k8s-service-advanced/"},{"categories":["学习笔记","K8s"],"content":"2.1 ClusterIP ClusterIP Service 资源清单 apiVersion: v1 kind: Service metadata: name: service-clusterip namespace: dev spec: selector: app: nginx-pod clusterIP: 10.97.97.97 # service的ip地址，如果不写，默认会生成一个 type: ClusterIP ports: - port: 80 # Service端口 targetPort: 80 # pod端口 查看 ClusterIP 类型 service 的详细信息 # 在这里有一个Endpoints列表，里面就是当前service可以负载到的服务入口 $ kubectl describe svc service-clusterip -n dev Name: service-clusterip Namespace: dev Labels: \u003cnone\u003e Annotations: \u003cnone\u003e Selector: app=nginx-pod Type: ClusterIP IP: 10.97.97.97 Port: \u003cunset\u003e 80/TCP TargetPort: 80/TCP Endpoints: 10.244.1.39:80,10.244.1.40:80,10.244.2.33:80 Session Affinity: None Events: \u003cnone\u003e 添加 Service 后可以看到 ipvs 映射规则 $ sudo ipvsadm -Ln IP Virtual Server version 1.2.1 (size=4096) Prot LocalAddress:Port Scheduler Flags -\u003e RemoteAddress:Port Forward Weight ActiveConn InActConn TCP 172.17.0.1:31070 rr -\u003e 10.244.1.48:80 Masq 1 0 0 TCP 192.168.31.101:31070 rr -\u003e 10.244.1.48:80 Masq 1 0 0 TCP 10.96.0.1:443 rr -\u003e 192.168.31.101:6443 Masq 1 0 0 TCP 10.96.0.10:53 rr -\u003e 10.244.0.4:53 Masq 1 0 0 -\u003e 10.244.0.5:53 Masq 1 0 0 TCP 10.96.0.10:9153 rr -\u003e 10.244.0.4:9153 Masq 1 0 0 -\u003e 10.244.0.5:9153 Masq 1 0 0 TCP 10.97.97.97:80 rr # 这里就是我们创建的 service 生成的 ipvs 转发规则，rr 表示轮询 -\u003e 10.244.1.57:80 Masq 1 0 0 -\u003e 10.244.2.67:80 Masq 1 0 0 -\u003e 10.244.2.68:80 Masq 1 0 0 Endpoints Endpoints是kubernetes中的一个资源对象，存储在etcd中，用来记录一个service对应的所有pod的访问地址，它是根据service配置文件中selector描述产生的。 一个Service由一组Pod组成，这些Pod通过Endpoints暴露出来，Endpoints是实现实际服务的端点集合。换句话说，service和pod之间的联系是通过endpoints实现的。 负载分发策略(sessionAffinity) 对Service的访问被分发到了后端的Pod上去，目前kubernetes提供了两种负载分发策略： None: 如果不定义，默认使用kube-proxy的策略，比如随机、轮询 ClientIP: 基于客户端地址的会话保持模式，即来自同一个客户端发起的所有请求都会转发到固定的一个Pod上 ","date":"2022-08-21","objectID":"/posts/notes/devops/k8s/itheima/5-k8s-service-advanced/:2:1","tags":["K8s","Kubernetes","pod","service","ingress"],"title":"K8s 学习笔记（五）Service 详解","uri":"/posts/notes/devops/k8s/itheima/5-k8s-service-advanced/"},{"categories":["学习笔记","K8s"],"content":"2.2 Headless 在某些场景中，开发人员可能不想使用Service提供的负载均衡功能，而希望自己来控制负载均衡策略，针对这种情况，kubernetes提供了HeadLess Service，这类Service不会分配Cluster IP，如果想要访问service，只能通过service的域名进行查询。 Headless Service 资源清单 apiVersion: v1 kind: Service metadata: name: service-headless namespace: dev spec: selector: app: nginx-pod clusterIP: None # 将clusterIP设置为None，即可创建headless Service type: ClusterIP ports: - port: 80 targetPort: 80 ","date":"2022-08-21","objectID":"/posts/notes/devops/k8s/itheima/5-k8s-service-advanced/:2:2","tags":["K8s","Kubernetes","pod","service","ingress"],"title":"K8s 学习笔记（五）Service 详解","uri":"/posts/notes/devops/k8s/itheima/5-k8s-service-advanced/"},{"categories":["学习笔记","K8s"],"content":"2.3 NodePort NodePort的工作原理是将service的端口映射到Node的一个端口上，然后就可以通过NodeIp:NodePort来访问service了。 NodePort Service 资源清单 apiVersion: v1 kind: Service metadata: name: service-nodeport namespace: dev spec: selector: app: nginx-pod type: NodePort # service类型 ports: - port: 80 nodePort: 30002 # 指定绑定的node的端口(默认的取值范围是：30000-32767), 如果不指定，会默认分配 targetPort: 80 ","date":"2022-08-21","objectID":"/posts/notes/devops/k8s/itheima/5-k8s-service-advanced/:2:3","tags":["K8s","Kubernetes","pod","service","ingress"],"title":"K8s 学习笔记（五）Service 详解","uri":"/posts/notes/devops/k8s/itheima/5-k8s-service-advanced/"},{"categories":["学习笔记","K8s"],"content":"2.4 LoadBalancer LoadBalancer和NodePort很相似，目的都是向外部暴露一个端口，区别在于LoadBalancer会在集群的外部再来做一个负载均衡设备，而这个设备需要外部环境支持的，外部服务发送到这个设备上的请求，会被设备负载之后转发到集群中。 ","date":"2022-08-21","objectID":"/posts/notes/devops/k8s/itheima/5-k8s-service-advanced/:2:4","tags":["K8s","Kubernetes","pod","service","ingress"],"title":"K8s 学习笔记（五）Service 详解","uri":"/posts/notes/devops/k8s/itheima/5-k8s-service-advanced/"},{"categories":["学习笔记","K8s"],"content":"2.5 ExternalName 引入集群外部的服务，它通过externalName属性指定外部一个服务的地址，然后在集群内部访问此service就可以访问到外部的服务了。 ExternalName Service 资源清单 apiVersion: v1 kind: Service metadata: name: service-externalname namespace: dev spec: type: ExternalName # service类型 externalName: www.baidu.com #改成ip地址也可以 ","date":"2022-08-21","objectID":"/posts/notes/devops/k8s/itheima/5-k8s-service-advanced/:2:5","tags":["K8s","Kubernetes","pod","service","ingress"],"title":"K8s 学习笔记（五）Service 详解","uri":"/posts/notes/devops/k8s/itheima/5-k8s-service-advanced/"},{"categories":["学习笔记","K8s"],"content":"3. Ingress ","date":"2022-08-21","objectID":"/posts/notes/devops/k8s/itheima/5-k8s-service-advanced/:3:0","tags":["K8s","Kubernetes","pod","service","ingress"],"title":"K8s 学习笔记（五）Service 详解","uri":"/posts/notes/devops/k8s/itheima/5-k8s-service-advanced/"},{"categories":["学习笔记","K8s"],"content":"3.1 Ingress 介绍 service对集群之外暴露服务的主要方式有两种：NotePort和LoadBalancer，但是这两种方式，都有一定的缺点： NodePort方式的缺点是会占用很多集群机器的端口，那么当集群服务变多的时候，这个缺点就愈发明显 LB方式的缺点是每个service需要一个LB，浪费、麻烦，并且需要kubernetes之外设备的支持 kubernetes提供了Ingress资源对象，Ingress只需要一个NodePort或者一个LB就可以满足暴露多个Service的需求。工作机制大致如下图表示： Ingress相当于一个7层的负载均衡器，是kubernetes对反向代理的一个抽象，它的工作原理类似于Nginx，可以理解成在Ingress里建立诸多映射规则，Ingress Controller通过监听这些配置规则并转化成Nginx的反向代理配置 , 然后对外部提供服务。 ingress：kubernetes中的一个对象，作用是定义请求如何转发到service的规则 ingress controller：具体实现反向代理及负载均衡的程序，对ingress定义的规则进行解析，根据配置的规则来实现请求转发，实现方式有很多，比如Nginx, Contour, Haproxy等等 Ingress（以Nginx为例）的工作原理如下： 用户编写Ingress规则，说明哪个域名对应kubernetes集群中的哪个Service Ingress控制器动态感知Ingress服务规则的变化，然后生成一段对应的Nginx反向代理配置 Ingress控制器会将生成的Nginx配置写入到一个运行着的Nginx服务中，并动态更新 到此为止，其实真正在工作的就是一个Nginx了，内部配置了用户定义的请求转发规则 ","date":"2022-08-21","objectID":"/posts/notes/devops/k8s/itheima/5-k8s-service-advanced/:3:1","tags":["K8s","Kubernetes","pod","service","ingress"],"title":"K8s 学习笔记（五）Service 详解","uri":"/posts/notes/devops/k8s/itheima/5-k8s-service-advanced/"},{"categories":["学习笔记","K8s"],"content":"3.2 Ingress 的使用 gcr 镜像无法拉取，用 gcr.io_mirror 这个 mirror Ingress 资源清单 apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: ingress-http namespace: dev spec: rules: - host: nginx.itheima.com http: paths: - pathType: Prefix path: / backend: service: name: nginx-service port: number: 80 - host: tomcat.itheima.com http: paths: - pathType: Prefix path: / backend: service: name: tomcat-service port: number: 8080 ","date":"2022-08-21","objectID":"/posts/notes/devops/k8s/itheima/5-k8s-service-advanced/:3:2","tags":["K8s","Kubernetes","pod","service","ingress"],"title":"K8s 学习笔记（五）Service 详解","uri":"/posts/notes/devops/k8s/itheima/5-k8s-service-advanced/"},{"categories":["学习笔记","K8s"],"content":"1. Pod控制器介绍 Pod控制器是管理pod的中间层，使用Pod控制器之后，只需要告诉Pod控制器，想要多少个什么样的Pod就可以了，它会创建出满足条件的Pod并确保每一个Pod资源处于用户期望的目标状态。如果Pod资源在运行中出现故障，它会基于指定策略重新编排Pod。 在kubernetes中，有很多类型的pod控制器，每种都有自己的适合的场景，常见的有下面这些： ReplicationController：比较原始的pod控制器，已经被废弃，由ReplicaSet替代 ReplicaSet：保证副本数量一直维持在期望值，并支持pod数量扩缩容，镜像版本升级 Deployment：通过控制ReplicaSet来控制Pod，并支持滚动升级、回退版本 Horizontal Pod Autoscaler：可以根据集群负载自动水平调整Pod的数量，实现削峰填谷 DaemonSet：在集群中的指定Node上运行且仅运行一个副本，一般用于守护进程类的任务 Job：它创建出来的pod只要完成任务就立即退出，不需要重启或重建，用于执行一次性任务 Cronjob：它创建的Pod负责周期性任务控制，不需要持续后台运行 StatefulSet：管理有状态应用 ","date":"2022-08-20","objectID":"/posts/notes/devops/k8s/itheima/4-k8s-pod-controller-advanced/:1:0","tags":["K8s","Kubernetes","pod","controller"],"title":"K8s 学习笔记（四）Pod 控制器详解","uri":"/posts/notes/devops/k8s/itheima/4-k8s-pod-controller-advanced/"},{"categories":["学习笔记","K8s"],"content":"2. ReplicaSet(RS) ReplicaSet的主要作用是保证一定数量的pod正常运行，它会持续监听这些Pod的运行状态，一旦Pod发生故障，就会重启或重建。同时它还支持对pod数量的扩缩容和镜像版本的升降级。 ReplicaSet资源清单文件 apiVersion: apps/v1 # 版本号 kind: ReplicaSet # 类型 metadata: # 元数据 name: pc-replicaset # rs名称 namespace: dev # 所属命名空间 labels: #标签 controller: rs spec: # 详情描述 replicas: 3 # 副本数量 selector: # 选择器，通过它指定该控制器管理哪些pod matchLabels: # Labels匹配规则 app: nginx-pod matchExpressions: # Expressions匹配规则 - {key: app, operator: In, values: [nginx-pod]} template: # 模板，当副本数量不足时，会根据下面的模板创建pod副本，就是 pod 的配置 metadata: labels: app: nginx-pod spec: containers: - name: nginx image: nginx:1.17.1 ports: - containerPort: 80 扩缩容 # 编辑rs的副本数量，修改spec:replicas: 6即可 $ kubectl edit rs pc-replicaset -n dev replicaset.apps/pc-replicaset edited # 当然也可以直接使用命令实现 # 使用scale命令实现扩缩容， 后面--replicas=n直接指定目标数量即可 $ kubectl scale rs pc-replicaset --replicas=2 -n dev replicaset.apps/pc-replicaset scaled 升降级 # 编辑rs的容器镜像 - image: nginx:1.17.2 $ kubectl edit rs pc-replicaset -n dev replicaset.apps/pc-replicaset edited # 同样的道理，也可以使用命令完成这个工作 # kubectl set image rs rs名称 容器=镜像版本 -n namespace $ kubectl set image rs pc-replicaset nginx=nginx:1.17.1 -n dev replicaset.apps/pc-replicaset image updated 删除 ReplicaSet # 使用kubectl delete命令会删除此RS以及它管理的Pod # 在kubernetes删除RS前，会将RS的replicasclear调整为0，等待所有的Pod被删除后，在执行RS对象的删除 $ kubectl delete rs pc-replicaset -n dev replicaset.apps \"pc-replicaset\" deleted # 如果希望仅仅删除RS对象（保留Pod），可以使用kubectl delete命令时添加--cascade=false选项（不推荐）。 $ kubectl delete rs pc-replicaset -n dev --cascade=false replicaset.apps \"pc-replicaset\" deleted # 也可以使用yaml直接删除(推荐) $ kubectl delete -f pc-replicaset.yaml replicaset.apps \"pc-replicaset\" deleted ","date":"2022-08-20","objectID":"/posts/notes/devops/k8s/itheima/4-k8s-pod-controller-advanced/:2:0","tags":["K8s","Kubernetes","pod","controller"],"title":"K8s 学习笔记（四）Pod 控制器详解","uri":"/posts/notes/devops/k8s/itheima/4-k8s-pod-controller-advanced/"},{"categories":["学习笔记","K8s"],"content":"3. Deployment(Deploy) 为了更好的解决服务编排的问题，kubernetes在V1.2版本开始，引入了Deployment控制器。值得一提的是，这种控制器并不直接管理pod，而是通过管理ReplicaSet来简介管理Pod，即：Deployment管理ReplicaSet，ReplicaSet管理Pod。所以Deployment比ReplicaSet功能更加强大。 Deployment主要功能有下面几个： 支持ReplicaSet的所有功能 支持发布的停止、继续 支持滚动升级和回滚版本 版本回滚通过保留 rs 来实现，升级后，原 rs 依旧存在，只是 pod 数量变为 0 Deployment 资源清单文件 apiVersion: apps/v1 # 版本号 kind: Deployment # 类型 metadata: # 元数据 name: pc-deployment # rs名称 namespace: dev # 所属命名空间 labels: #标签 controller: deploy spec: # 详情描述 replicas: 3 # 副本数量 revisionHistoryLimit: 3 # 保留历史版本，默认 10，通过保留 rs 来实现 paused: false # 暂停部署，默认是false progressDeadlineSeconds: 600 # 部署超时时间（s），默认是600 strategy: # 策略 type: RollingUpdate # 滚动更新策略 rollingUpdate: # 滚动更新 maxSurge: 30% # 最大额外可以存在的副本数，可以为百分比，也可以为整数 maxUnavailable: 30% # 最大不可用状态的 Pod 的最大值，可以为百分比，也可以为整数 selector: # 选择器，通过它指定该控制器管理哪些pod matchLabels: # Labels匹配规则 app: nginx-pod matchExpressions: # Expressions匹配规则 - { key: app, operator: In, values: [ nginx-pod ] } template: # 模板，当副本数量不足时，会根据下面的模板创建pod副本 metadata: labels: app: nginx-pod spec: containers: - name: nginx image: nginx:1.17.1 ports: - containerPort: 80 扩缩容 同 ReplicaSet 类似 镜像更新 eployment支持两种更新策略:重建更新和滚动更新,可以通过strategy指定策略类型,支持两个属性: strategy：指定新的Pod替换旧的Pod的策略， 支持两个属性： type：指定策略类型，支持以下两种策略 (Recreate：在创建出新的Pod之前会先杀掉所有已存在的Pod RollingUpdate：滚动更新，就是杀死一部分，就启动一部分，在更新过程中，存在两个版本Pod) rollingUpdate：当type为RollingUpdate时生效，用于为RollingUpdate设置参数，支持两个属性： maxUnavailable：用来指定在升级过程中不可用Pod的最大数量，默认为25%。 maxSurge： 用来指定在升级过程中可以超过期望的Pod的最大数量，默认为25%。 版本回退 deployment支持版本升级过程中的暂停、继续功能以及版本回退等诸多功能。 kubectl rollout：版本升级相关功能，支持下面的选项： status 显示当前升级状态 history 显示升级历史记录 pause 暂停版本升级过程 resume 继续已经暂停的版本升级过程 restart 重启版本升级过程 undo 回滚到上一级版本（可以使用–to-revision回滚到指定版本） 金丝雀发布 比如有一批新的Pod资源创建完成后立即暂停更新过程，此时，仅存在一部分新版本的应用，主体部分还是旧的版本。然后，再筛选一小部分的用户请求路由到新版本的Pod应用，继续观察能否稳定地按期望的方式运行。确定没问题之后再继续完成余下的Pod资源滚动更新，否则立即回滚更新操作。这就是所谓的金丝雀发布。 # 更新deployment的版本，并配置暂停deployment $ kubectl set image deploy pc-deployment nginx=nginx:1.17.4 -n dev \u0026\u0026 kubectl rollout pause deployment pc-deployment -n dev deployment.apps/pc-deployment image updated deployment.apps/pc-deployment paused # 确保更新的pod没问题了，继续更新 $ kubectl rollout resume deploy pc-deployment -n dev deployment.apps/pc-deployment resumed ","date":"2022-08-20","objectID":"/posts/notes/devops/k8s/itheima/4-k8s-pod-controller-advanced/:3:0","tags":["K8s","Kubernetes","pod","controller"],"title":"K8s 学习笔记（四）Pod 控制器详解","uri":"/posts/notes/devops/k8s/itheima/4-k8s-pod-controller-advanced/"},{"categories":["学习笔记","K8s"],"content":"4. Horizontal Pod Autoscalar (HPA) HPA可以获取每个Pod利用率，然后和HPA中定义的指标进行对比，同时计算出需要伸缩的具体值，最后实现Pod的数量的调整。 实现原理：HPA与之前的Deployment一样，也属于一种Kubernetes资源对象，它通过追踪分析RC控制的所有目标Pod的负载变化情况，来确定是否需要针对性地调整目标Pod的副本数。 HPA 资源清单文件 apiVersion: autoscaling/v1 kind: HorizontalPodAutoscaler metadata: name: pc-hpa namespace: dev spec: minReplicas: 1 #最小pod数量 maxReplicas: 10 #最大pod数量 targetCPUUtilizationPercentage: 3 # CPU使用率指标，百分比 scaleTargetRef: # 指定要控制的 deployment 信息 apiVersion: apps/v1 kind: Deployment name: nginx 流程 创建 deploy 创建 HPA，绑定到 deploy 负载上升 pod 水平扩展 负载下架 pod 等待一段时间后再慢慢收缩 ","date":"2022-08-20","objectID":"/posts/notes/devops/k8s/itheima/4-k8s-pod-controller-advanced/:4:0","tags":["K8s","Kubernetes","pod","controller"],"title":"K8s 学习笔记（四）Pod 控制器详解","uri":"/posts/notes/devops/k8s/itheima/4-k8s-pod-controller-advanced/"},{"categories":["学习笔记","K8s"],"content":"5. DaemonSet (DS) DaemonSet类型的控制器可以保证在集群中的每一台（或指定）节点上都运行一个副本。一般适用于日志收集、节点监控等场景。 如果一个Pod提供的功能是节点级别的（每个节点都需要且只需要一个），那么这类Pod就适合使用DaemonSet类型的控制器创建。 DaemonSet控制器的特点： 每当向集群中添加一个节点时，指定的 Pod 副本也将添加到该节点上 当节点从集群中移除时，Pod 也就被垃圾回收了 DS 资源清单文件 apiVersion: apps/v1 # 版本号 kind: DaemonSet # 类型 metadata: # 元数据 name: pc-daemonset # rs名称 namespace: dev # 所属命名空间 labels: #标签 controller: daemonset spec: # 详情描述 revisionHistoryLimit: 3 # 保留历史版本 updateStrategy: # 更新策略 type: RollingUpdate # 滚动更新策略 rollingUpdate: # 滚动更新 maxUnavailable: 1 # 最大不可用状态的 Pod 的最大值，可以为百分比，也可以为整数 selector: # 选择器，通过它指定该控制器管理哪些pod matchLabels: # Labels匹配规则 app: nginx-pod matchExpressions: # Expressions匹配规则 - {key: app, operator: In, values: [nginx-pod]} template: # 模板，当副本数量不足时，会根据下面的模板创建pod副本 metadata: labels: app: nginx-pod spec: containers: - name: nginx image: nginx:1.17.1 ports: - containerPort: 80 ","date":"2022-08-20","objectID":"/posts/notes/devops/k8s/itheima/4-k8s-pod-controller-advanced/:5:0","tags":["K8s","Kubernetes","pod","controller"],"title":"K8s 学习笔记（四）Pod 控制器详解","uri":"/posts/notes/devops/k8s/itheima/4-k8s-pod-controller-advanced/"},{"categories":["学习笔记","K8s"],"content":"6. Job Job，主要用于负责批量处理(一次要处理指定数量任务)短暂的一次性(每个任务仅运行一次就结束)任务。Job特点如下： 当Job创建的pod执行成功结束时，Job将记录成功结束的pod数量 当成功结束的pod达到指定的数量时，Job将完成执行 Job 资源清单文件 apiVersion: batch/v1 # 版本号 kind: Job # 类型 metadata: # 元数据 name: pc-job # rs名称 namespace: dev # 所属命名空间 labels: #标签 controller: job spec: # 详情描述 completions: 1 # 指定job需要成功运行Pods的次数。默认值: 1 parallelism: 1 # 指定job在任一时刻应该并发运行Pods的数量。默认值: 1 activeDeadlineSeconds: 30 # 指定job可运行的时间期限，超过时间还未结束，系统将会尝试进行终止。 backoffLimit: 6 # 指定job失败后进行重试的次数。默认是6 manualSelector: true # 是否可以使用selector选择器选择pod，默认是false selector: # 选择器，通过它指定该控制器管理哪些pod matchLabels: # Labels匹配规则 app: counter-pod matchExpressions: # Expressions匹配规则 - {key: app, operator: In, values: [counter-pod]} template: # 模板，当副本数量不足时，会根据下面的模板创建pod副本 metadata: labels: app: counter-pod spec: restartPolicy: Never # 重启策略只能设置为Never或者OnFailure containers: - name: counter image: busybox:1.30 command: [\"bin/sh\",\"-c\",\"for i in 9 8 7 6 5 4 3 2 1; do echo $i;sleep 2;done\"] ","date":"2022-08-20","objectID":"/posts/notes/devops/k8s/itheima/4-k8s-pod-controller-advanced/:6:0","tags":["K8s","Kubernetes","pod","controller"],"title":"K8s 学习笔记（四）Pod 控制器详解","uri":"/posts/notes/devops/k8s/itheima/4-k8s-pod-controller-advanced/"},{"categories":["学习笔记","K8s"],"content":"7. CronJob (CJ) CronJob控制器以Job控制器资源为其管控对象，并借助它管理pod资源对象 CJ 资源清单文件 apiVersion: batch/v1 # 版本号 kind: CronJob # 类型 metadata: # 元数据 name: pc-cronjob # rs名称 namespace: dev # 所属命名空间 labels: #标签 controller: cronjob spec: # 详情描述 schedule: \"*/1 * * * *\" # cron格式的作业调度运行时间点,用于控制任务在什么时间执行 concurrencyPolicy: Allow # 并发执行策略，用于定义前一次作业运行尚未完成时是否以及如何运行后一次的作业，Allow, Forbid, Replace failedJobsHistoryLimit: 1 # 为失败的任务执行保留的历史记录数，默认为1 successfulJobsHistoryLimit: 3 # 为成功的任务执行保留的历史记录数，默认为3 startingDeadlineSeconds: 600 # 启动作业错误的超时时长 jobTemplate: # job控制器模板，用于为cronjob控制器生成job对象;下面其实就是job的定义 metadata: {} spec: completions: 1 parallelism: 1 activeDeadlineSeconds: 30 backoffLimit: 6 manualSelector: true selector: matchLabels: app: counter-pod matchExpressions: # 规则 - {key: app, operator: In, values: [counter-pod]} template: metadata: labels: app: counter-pod spec: restartPolicy: Never containers: - name: counter image: busybox:1.30 command: [\"bin/sh\",\"-c\",\"for i in 9 8 7 6 5 4 3 2 1; do echo $i;sleep 20;done\"] ","date":"2022-08-20","objectID":"/posts/notes/devops/k8s/itheima/4-k8s-pod-controller-advanced/:7:0","tags":["K8s","Kubernetes","pod","controller"],"title":"K8s 学习笔记（四）Pod 控制器详解","uri":"/posts/notes/devops/k8s/itheima/4-k8s-pod-controller-advanced/"},{"categories":["学习笔记","K8s"],"content":"1. Pod 介绍 ","date":"2022-08-20","objectID":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/:1:0","tags":["K8s","Kubernetes","pod"],"title":"K8s 学习笔记（三）Pod 详解","uri":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/"},{"categories":["学习笔记","K8s"],"content":"1.1 Pod 结构 每个Pod中都可以包含一个或者多个容器，这些容器可以分为两类： 用户程序所在的容器，数量可多可少 Pause容器，这是每个Pod都会有的一个根容器，它的作用有两个： 可以以它为依据，评估整个Pod的健康状态 可以在根容器上设置Ip地址，其它容器都此Ip（Pod IP），以实现Pod内部的网路通信。这里是Pod内部的通讯，Pod的之间的通讯采用虚拟二层网络技术来实现，我们当前环境用的是Flannel ","date":"2022-08-20","objectID":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/:1:1","tags":["K8s","Kubernetes","pod"],"title":"K8s 学习笔记（三）Pod 详解","uri":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/"},{"categories":["学习笔记","K8s"],"content":"1.2 Pod 定义 可通过kubectl explain命令来查看每种资源的可配置项 kubectl explain 资源类型：查看某种资源可以配置的一级属性 kubectl explain 资源类型.属性[.属性...]：查看属性的子属性 Pod 资源清单(YAML 配置): apiVersion: v1 #必选，版本号，例如v1 kind: Pod #必选，资源类型，例如 Pod metadata: #必选，元数据 name: string #必选，Pod名称 namespace: string #Pod所属的命名空间,默认为\"default\" labels: #自定义标签列表 - name: string spec: #必选，Pod中容器的详细定义 containers: #必选，Pod中容器列表 - name: string #必选，容器名称 image: string #必选，容器的镜像名称 imagePullPolicy: [ Always|Never|IfNotPresent ] #获取镜像的策略 command: [ string ] #容器的启动命令列表，如不指定，使用打包时使用的启动命令 args: [ string ] #容器的启动命令参数列表 workingDir: string #容器的工作目录 volumeMounts: #挂载到容器内部的存储卷配置 - name: string #引用pod定义的共享存储卷的名称，需用volumes[]部分定义的的卷名 mountPath: string #存储卷在容器内mount的绝对路径，应少于512字符 readOnly: boolean #是否为只读模式 ports: #需要暴露的端口库号列表 - name: string #端口的名称 containerPort: int #容器需要监听的端口号 hostPort: int #容器所在主机需要监听的端口号，默认与Container相同 protocol: string #端口协议，支持TCP和UDP，默认TCP env: #容器运行前需设置的环境变量列表 - name: string #环境变量名称 value: string #环境变量的值 resources: #资源限制和请求的设置 limits: #资源限制的设置 cpu: string #Cpu的限制，单位为core数，将用于docker run --cpu-shares参数 memory: string #内存限制，单位可以为Mib/Gib，将用于docker run --memory参数 requests: #资源请求的设置 cpu: string #Cpu请求，容器启动的初始可用数量 memory: string #内存请求,容器启动的初始可用数量 lifecycle: #生命周期钩子 postStart: #容器启动后立即执行此钩子,如果执行失败,会根据重启策略进行重启 preStop: #容器终止前执行此钩子,无论结果如何,容器都会终止 livenessProbe: #对Pod内各容器健康检查的设置，当探测无响应几次后将自动重启该容器 exec: #对Pod容器内检查方式设置为exec方式 command: [ string ] #exec方式需要制定的命令或脚本 httpGet: #对Pod内个容器健康检查方法设置为HttpGet，需要制定Path、port path: string port: number host: string scheme: string HttpHeaders: - name: string value: string tcpSocket: #对Pod内个容器健康检查方式设置为tcpSocket方式 port: number initialDelaySeconds: 0 #容器启动完成后首次探测的时间，单位为秒 timeoutSeconds: 0 #对容器健康检查探测等待响应的超时时间，单位秒，默认1秒 periodSeconds: 0 #对容器监控检查的定期探测时间设置，单位秒，默认10秒一次 successThreshold: 0 failureThreshold: 0 securityContext: privileged: false restartPolicy: [ Always | Never | OnFailure ] #Pod的重启策略 nodeName: \u003cstring\u003e #设置NodeName表示将该Pod调度到指定到名称的node节点上 nodeSelector: obeject #设置NodeSelector表示将该Pod调度到包含这个label的node上 imagePullSecrets: #Pull镜像时使用的secret名称，以key：secretkey格式指定 - name: string hostNetwork: false #是否使用主机网络模式，默认为false，如果设置为true，表示使用宿主机网络 volumes: #在该pod上定义共享存储卷列表 - name: string #共享存储卷名称 （volumes类型有很多种） emptyDir: { } #类型为emtyDir的存储卷，与Pod同生命周期的一个临时目录。为空值 hostPath: #类型为hostPath的存储卷，表示挂载Pod所在宿主机的目录 path: string #Pod所在宿主机的目录，将被用于同期中mount的目录 secret: #类型为secret的存储卷，挂载集群与定义的secret对象到容器内部 secretName: string items: - key: string path: string configMap: #类型为configMap的存储卷，挂载预定义的configMap对象到容器内部 name: string items: - key: string path: string 在kubernetes中基本所有资源的一级属性都是一样的，主要包含5部分： apiVersion \u003cstring\u003e：版本，由kubernetes内部定义，版本号必须可以用 kubectl api-versions 查询到 kind \u003cstring\u003e：类型，由kubernetes内部定义，版本号必须可以用 kubectl api-resources 查询到 metadata \u003cObject\u003e：元数据，主要是资源标识和说明，常用的有name、namespace、labels等 spec \u003cObject\u003e：描述，这是配置中最重要的一部分，里面是对各种资源配置的详细描述 status \u003cObject\u003e：状态信息，里面的内容不需要定义，由kubernetes自动生成 在上面的属性中，spec是接下来研究的重点，继续看下它的常见子属性: containers \u003c[]Object\u003e：容器列表，用于定义容器的详细信息 nodeName \u003cString\u003e：根据nodeName的值将pod调度到指定的Node节点上 nodeSelector \u003cmap[]\u003e：根据NodeSelector中定义的信息选择将该Pod调度到包含这些label的Node 上 hostNetwork \u003cboolean\u003e：是否使用主机网络模式，默认为false，如果设置为true，表示使用宿主机网络 volumes \u003c[]Object\u003e：存储卷，用于定义Pod上面挂在的存储信息 restartPolicy \u003cstring\u003e：重启策略，表示Pod在遇到故障的时候的处理策略 ","date":"2022-08-20","objectID":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/:1:2","tags":["K8s","Kubernetes","pod"],"title":"K8s 学习笔记（三）Pod 详解","uri":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/"},{"categories":["学习笔记","K8s"],"content":"2. Pod 配置 [root@master ~]# kubectl explain pod.spec.containers KIND: Pod VERSION: v1 RESOURCE: containers \u003c[]Object\u003e # 数组，代表可以有多个容器 FIELDS: name \u003cstring\u003e # 容器名称 image \u003cstring\u003e # 容器需要的镜像地址 imagePullPolicy \u003cstring\u003e # 镜像拉取策略 command \u003c[]string\u003e # 容器的启动命令列表，如不指定，使用打包时使用的启动命令 args \u003c[]string\u003e # 容器的启动命令需要的参数列表 env \u003c[]Object\u003e # 容器环境变量的配置 ports \u003c[]Object\u003e # 容器需要暴露的端口号列表 resources \u003cObject\u003e # 资源限制和资源请求的设置 ","date":"2022-08-20","objectID":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/:2:0","tags":["K8s","Kubernetes","pod"],"title":"K8s 学习笔记（三）Pod 详解","uri":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/"},{"categories":["学习笔记","K8s"],"content":"2.1 基本配置 apiVersion: v1 kind: Pod metadata: name: pod-base namespace: dev labels: user: heima spec: containers: - name: nginx image: nginx - name: busybox image: busybox ","date":"2022-08-20","objectID":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/:2:1","tags":["K8s","Kubernetes","pod"],"title":"K8s 学习笔记（三）Pod 详解","uri":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/"},{"categories":["学习笔记","K8s"],"content":"2.2 镜像拉取(imagePullPolicy) apiVersion: v1 kind: Pod metadata: name: pod-base namespace: dev labels: user: heima spec: containers: - name: nginx image: nginx imagePullPolicy: Always # 镜像拉取策略 - name: busybox image: busybox imagePullPolicy 三种拉取策略： Always：总是从远程仓库拉取镜像（一直远程下载），tag 为 latest 时默认 IfNotPresent：本地有则使用本地镜像，本地没有则从远程仓库拉取镜像（本地有就本地 本地没远程下载），tag 为具体版本时默认。 Never：只使用本地镜像，从不去远程仓库拉取，本地没有就报错 （一直使用本地） ","date":"2022-08-20","objectID":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/:2:2","tags":["K8s","Kubernetes","pod"],"title":"K8s 学习笔记（三）Pod 详解","uri":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/"},{"categories":["学习笔记","K8s"],"content":"2.3 启动命令(command 和 args) apiVersion: v1 kind: Pod metadata: name: pod-command namespace: dev spec: containers: - name: nginx image: nginx - name: busybox image: busybox # command 指定容器运行后执行的命令 command: [\"/bin/sh\", \"-c\", \"touch /tmp/hello.txt;while true;do /bin/echo $(date +%T) \u003e\u003e /tmp/hello.txt; sleep 3; done;\"] # args 指定参数 args: [] command 和 args 对应 Dockerfile 中的 ENTRYPOINT 指定 command 会覆盖 ENTRYPOINT；指定 args 会执行 ENTRYPOINT 并带上 args 参数 进入容器 cubectl exec \u003cpod-name\u003e [-n \u003cnamespace\u003e] -it -c \u003ccontaienr name\u003e \u003ccommand\u003e ","date":"2022-08-20","objectID":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/:2:3","tags":["K8s","Kubernetes","pod"],"title":"K8s 学习笔记（三）Pod 详解","uri":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/"},{"categories":["学习笔记","K8s"],"content":"2.4 环境变量(env) apiVersion: v1 kind: Pod metadata: name: pod-env namespace: dev spec: containers: - name: busybox image: busybox command: [\"/bin/sh\", \"-c\", \"while true;do /bin/echo $(date +%T); sleep 60; done;\"] env: - name: \"username\" value: \"admin\" - name: \"password\" value: \"123456\" 这种方式不是很推荐，推荐将这些配置单独存储在配置文件中。 ","date":"2022-08-20","objectID":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/:2:4","tags":["K8s","Kubernetes","pod"],"title":"K8s 学习笔记（三）Pod 详解","uri":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/"},{"categories":["学习笔记","K8s"],"content":"2.5 端口设置 支持的选项： [root@master ~]# kubectl explain pod.spec.containers.ports KIND: Pod VERSION: v1 RESOURCE: ports \u003c[]Object\u003e FIELDS: name \u003cstring\u003e # 端口名称，如果指定，必须保证name在pod中是唯一的 containerPort\u003cinteger\u003e # 容器要监听的端口(0\u003cx\u003c65536) hostPort \u003cinteger\u003e # 容器要在主机上公开的端口，如果设置，主机上只能运行容器的一个副本(一般省略) hostIP \u003cstring\u003e # 要将外部端口绑定到的主机IP(一般省略) protocol \u003cstring\u003e # 端口协议。必须是UDP、TCP或SCTP。默认为“TCP”。 apiVersion: v1 kind: Pod metadata: name: pod-ports namespace: dev spec: containers: - name: nginx image: nginx ports: # 暴露的端口列表 - name: nginx-port containerPort: 80 # 端口号 访问容器中的程序使用podIp:containerPort ","date":"2022-08-20","objectID":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/:2:5","tags":["K8s","Kubernetes","pod"],"title":"K8s 学习笔记（三）Pod 详解","uri":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/"},{"categories":["学习笔记","K8s"],"content":"2.6 资源配额 如果不对某个容器的资源做限制，那么它就可能吃掉大量资源，导致其它容器无法运行。 通过resources选项实现，他有两个子选项： limits：上限，用于限制运行时容器的最大占用资源，当容器占用资源超过limits时会被终止，并进行重启 requests ：下限，用于设置容器需要的最小资源，如果环境资源不够，容器将无法启动 apiVersion: v1 kind: Pod metadata: name: pod-resources namespace: dev spec: containers: - name: nginx image: nginx resources: limits: cpu: \"2\" memory: \"10Gi\" requests: cpu: \"1\" memory: \"10Mi\" 1Gi = 1.024 * 1G ","date":"2022-08-20","objectID":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/:2:6","tags":["K8s","Kubernetes","pod"],"title":"K8s 学习笔记（三）Pod 详解","uri":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/"},{"categories":["学习笔记","K8s"],"content":"3. Pod 生命周期 Pod 生命周期： pod创建过程 运行初始化容器（init container）过程 运行主容器（main container） 容器启动后钩子（post start）、容器终止前钩子（pre stop） 容器的存活性探测（liveness probe）、就绪性探测（readiness probe） pod终止过程 在整个生命周期中，Pod会出现5种状态（相位），分别如下： 挂起（Pending）：apiserver已经创建了pod资源对象，但它尚未被调度完成或者仍处于下载镜像的过程中 运行中（Running）：pod已经被调度至某节点，并且所有容器都已经被kubelet创建完成 成功（Succeeded）：pod中的所有容器都已经成功终止并且不会被重启 失败（Failed）：所有容器都已经终止，但至少有一个容器终止失败，即容器返回了非0值的退出状态 未知（Unknown）：apiserver无法正常获取到pod对象的状态信息，通常由网络通信失败所导致 ","date":"2022-08-20","objectID":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/:3:0","tags":["K8s","Kubernetes","pod"],"title":"K8s 学习笔记（三）Pod 详解","uri":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/"},{"categories":["学习笔记","K8s"],"content":"3.1 创建和终止 pod的创建过程 用户通过kubectl或其他api客户端提交需要创建的pod信息给apiServer apiServer开始生成pod对象的信息，并将信息存入etcd，然后返回确认信息至客户端 apiServer开始反映etcd中的pod对象的变化，其它组件使用watch机制来跟踪检查apiServer上的变动 scheduler发现有新的pod对象要创建，开始为Pod分配主机并将结果信息更新至apiServer node节点上的kubelet发现有pod调度过来，尝试调用docker启动容器，并将结果回送至apiServer apiServer将接收到的pod状态信息存入etcd中 pod的终止过程 用户向apiServer发送删除pod对象的命令 apiServcer中的pod对象信息会随着时间的推移而更新，在宽限期内（默认30s），pod被视为dead 将pod标记为terminating状态 kubelet在监控到pod对象转为terminating状态的同时启动pod关闭过程 端点控制器监控到pod对象的关闭行为时将其从所有匹配到此端点的service资源的端点列表中移除 如果当前pod对象定义了preStop钩子处理器，则在其标记为terminating后即会以同步的方式启动执行 pod对象中的容器进程收到停止信号 宽限期结束后，若pod中还存在仍在运行的进程，那么pod对象会收到立即终止的信号 kubelet请求apiServer将此pod资源的宽限期设置为0从而完成删除操作，此时pod对于用户已不可见 ","date":"2022-08-20","objectID":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/:3:1","tags":["K8s","Kubernetes","pod"],"title":"K8s 学习笔记（三）Pod 详解","uri":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/"},{"categories":["学习笔记","K8s"],"content":"3.2 运行初始化容器 初始化容器是在pod的主容器启动之前要运行的容器，主要是做一些主容器的前置工作，它具有两大特征： 初始化容器必须运行完成直至结束，若某初始化容器运行失败，那么kubernetes需要重启它直到成功完成 初始化容器必须按照定义的顺序执行，当且仅当前一个成功之后，后面的一个才能运行 初始化容器的应用场景： 提供主容器镜像中不具备的工具程序或自定义代码 初始化容器要先于应用容器串行启动并运行完成，因此可用于延后应用容器的启动直至其依赖的条件得到满足 Pod 配置文件案例 apiVersion: v1 kind: Pod metadata: name: pod-initcontainer namespace: dev spec: containers: - name: main-container image: nginx ports: - containerPort: 80 initContainers: - name: test-mysql image: busybox command: [\"sh\", \"-c\", \"until ping 192.168.31.201 -c 1; do echo waiting for mysql...; sleep 2; done;\"] - name: test-redis image: busybox command: [\"sh\", \"-c\", \"until ping 192.168.31.202 -c 1; do echo waiting for mysql...; sleep 2; done;\"] ","date":"2022-08-20","objectID":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/:3:2","tags":["K8s","Kubernetes","pod"],"title":"K8s 学习笔记（三）Pod 详解","uri":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/"},{"categories":["学习笔记","K8s"],"content":"3.3 钩子函数 kubernetes在主容器的启动之后和停止之前提供了两个钩子函数： post start：容器创建之后执行，如果失败了会重启容器 pre stop ：容器终止之前执行，执行完成之后容器将成功终止，在其完成之前会阻塞删除容器的操作 钩子处理器支持使用下面三种方式定义动作： Exec命令：在容器内执行一次命令 lifecycle: postStart: exec: command: - cat - /tmp/healthy TCPSocket：在当前容器尝试访问指定的socket lifecycle: postStart: tcpSocket: port: 8080 HTTPGet：在当前容器中向某url发起http请求 lifecycle: postStart: httpGet: path: / #URI地址 port: 80 #端口号 host: 192.168.109.100 #主机地址 scheme: HTTP #支持的协议，http或者https Pod配置文件举例 apiVersion: v1 kind: Pod metadata: name: pod-hook-exec namespace: dev spec: containers: - name: main-container image: nginx ports: - containerPort: 80 lifecycle: postStart: exec: command: [\"/bin/sh\", \"-c\", \"echo postStart... \u003e /usr/share/nginx/html/index.html\"] preStop: exec: command: [\"/usr/sbin/nginx\", \"-s\", \"quit\"] ","date":"2022-08-20","objectID":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/:3:3","tags":["K8s","Kubernetes","pod"],"title":"K8s 学习笔记（三）Pod 详解","uri":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/"},{"categories":["学习笔记","K8s"],"content":"3.4 容器探测 容器探测用于检测容器中的应用实例是否正常工作，是保障业务可用性的一种传统机制。如果经过探测，实例的状态不符合预期，那么kubernetes就会把该问题实例\" 摘除 “，不承担业务流量。kubernetes提供了两种探针来实现容器探测，分别是： liveness probes：存活性探针，用于检测应用实例当前是否处于正常运行状态，如果不是，k8s会重启容器 readiness probes：就绪性探针，用于检测应用实例当前是否可以接收请求，如果不能，k8s不会转发流量 livenessProbe 决定是否重启容器，readinessProbe 决定是否将请求转发给容器。 上面两种探针同样支持三种探测方式： Exec 命令 TCPSocket HTTPGet Pod配置文件举例 apiVersion: v1 kind: Pod metadata: name: pod-liveness-exec namespace: dev spec: containers: - name: nginx image: nginx ports: - containerPort: 80 livenessProbe: exec: command: - /bin/cat - /tmp/hello.txt livenessProbe 还有其他配置： [root@master ~]# kubectl explain pod.spec.containers.livenessProbe FIELDS: exec \u003cObject\u003e tcpSocket \u003cObject\u003e httpGet \u003cObject\u003e initialDelaySeconds \u003cinteger\u003e # 容器启动后等待多少秒执行第一次探测 timeoutSeconds \u003cinteger\u003e # 探测超时时间。默认1秒，最小1秒 periodSeconds \u003cinteger\u003e # 执行探测的频率。默认是10秒，最小1秒 failureThreshold \u003cinteger\u003e # 连续探测失败多少次才被认定为失败。默认是3。最小值是1 successThreshold \u003cinteger\u003e # 连续探测成功多少次才被认定为成功。默认是1 ","date":"2022-08-20","objectID":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/:3:4","tags":["K8s","Kubernetes","pod"],"title":"K8s 学习笔记（三）Pod 详解","uri":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/"},{"categories":["学习笔记","K8s"],"content":"3.5 重启策略 pod的重启策略有 3 种，分别如下： Always ：容器失效时，自动重启该容器，这也是默认值。 OnFailure ： 容器终止运行且退出码不为0时重启 Never ： 不论状态为何，都不重启该容器 重启延迟： 首次立即重启 接下来重启延迟为 10s、20s、40s、80s、160s和300s 最大延迟为 300s Pod配置文件举例 apiVersion: v1 kind: Pod metadata: name: pod-restartpolicy namespace: dev spec: containers: - name: nginx image: nginx ports: - containerPort: 80 livenessProbe: httpGet: port: 80 path: /hello scheme: HTTP restartPolicy: Never # 注意！是 pod 的属性，不是 containers 的 ","date":"2022-08-20","objectID":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/:3:5","tags":["K8s","Kubernetes","pod"],"title":"K8s 学习笔记（三）Pod 详解","uri":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/"},{"categories":["学习笔记","K8s"],"content":"4. Pod 调度 在默认情况下，一个Pod在哪个Node节点上运行，是由Scheduler组件采用相应的算法计算出来的，这个过程是不受人工控制的。 但是在实际使用中，这并不满足的需求，因为很多情况下，我们想控制某些Pod到达某些节点上，那么应该怎么做呢？这就要求了解kubernetes对Pod的调度规则，kubernetes提供了四大类调度方式： 自动调度：运行在哪个节点上完全由Scheduler经过一系列的算法计算得出 定向调度：NodeName、NodeSelector 亲和性调度：NodeAffinity、PodAffinity、PodAntiAffinity 污点（容忍）调度：Taints、Toleration ","date":"2022-08-20","objectID":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/:4:0","tags":["K8s","Kubernetes","pod"],"title":"K8s 学习笔记（三）Pod 详解","uri":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/"},{"categories":["学习笔记","K8s"],"content":"4.1 定向调度 利用在pod上声明nodeName或者nodeSelector，以此将Pod调度到期望的node节点上。 注意，这里的调度是强制的，这就意味着即使要调度的目标Node不存在，也会向上面进行调度，只不过pod运行失败而已。 4.1.1 NodeName NodeName用于强制约束将Pod调度到指定的Name的Node节点上。这种方式，其实是直接跳过Scheduler的调度逻辑，直接将Pod调度到指定名称的节点。 Pod配置文件举例 apiVersion: v1 kind: Pod metadata: name: pod-nodename namespace: dev spec: containers: - name: nginx image: nginx nodeName: u-2 # 节点名称，通过 kubectl get nodes 查看 4.1.2 NodeSelector NodeSelector用于将pod调度到添加了指定标签的node节点上。也是强制约束 Pod配置文件举例 apiVersion: v1 kind: Pod metadata: name: pod-nodeselector namespace: dev spec: containers: - name: nginx image: nginx nodeSelector: nodeenv: pro # 指定调度到具有 nodeenv=pro 标签的节点上 ","date":"2022-08-20","objectID":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/:4:1","tags":["K8s","Kubernetes","pod"],"title":"K8s 学习笔记（三）Pod 详解","uri":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/"},{"categories":["学习笔记","K8s"],"content":"4.2 亲和性调度 定向调度有一定的问题，那就是如果没有满足条件的Node，那么Pod将不会被运行，即使在集群中还有可用Node列表也不行，这就限制了它的使用场景。 亲和性调度（Affinity）：它在NodeSelector的基础之上的进行了扩展，可以通过配置的形式，实现优先选择满足条件的Node进行调度，如果没有，也可以调度到不满足条件的节点上，使调度更加灵活。 Affinity主要分为三类： nodeAffinity(node亲和性）: 以node为目标，解决pod可以调度到哪些node的问题 podAffinity(pod亲和性) : 以pod为目标，解决pod可以和哪些已存在的pod部署在同一个拓扑域中的问题 podAntiAffinity(pod反亲和性) : 以pod为目标，解决pod不能和哪些已存在pod部署在同一个拓扑域中的问题 亲和性(反亲和性)使用场景的说明： 亲和性：如果两个应用频繁交互，那就有必要利用亲和性让两个应用的尽可能的靠近，这样可以减少因网络通信而带来的性能损耗。 反亲和性：当应用的采用多副本部署时，有必要采用反亲和性让各个应用实例打散分布在各个node上，这样可以提高服务的高可用性。 4.2.1 NodeAffinity 主要字段 $ kubectl explain pod.spec.affinity.nodeAffinity requiredDuringSchedulingIgnoredDuringExecution # Node节点必须满足指定的所有规则才可以，相当于硬限制 nodeSelectorTerms # 节点选择列表 matchFields # 按节点字段列出的节点选择器要求列表 matchExpressions #按节点标签列出的节点选择器要求列表(推荐) key # 键 values # 值 operator # 关系符 支持Exists, DoesNotExist, In, NotIn, Gt, Lt preferredDuringSchedulingIgnoredDuringExecution # 优先调度到满足指定的规则的Node，相当于软限制 (倾向) preference # 一个节点选择器项，与相应的权重相关联 matchFields # 按节点字段列出的节点选择器要求列表 matchExpressions # 按节点标签列出的节点选择器要求列表(推荐) key # 键 values # 值 operator # 关系符 支持In, NotIn, Exists, DoesNotExist, Gt, Lt weight # 倾向权重，在范围1-100。 Pod配置文件举例 硬限制： apiVersion: v1 kind: Pod metadata: name: pod-nodeaffinity-required namespace: dev spec: containers: - name: nginx image: nginx affinity: # 亲和性设置 nodeAffinity: # 设置 node 亲和性 requiredDuringSchedulingIgnoredDuringExecution: # 硬限制 nodeSelectorTerms: # Selector 列表 - matchExpressions: # 匹配 nodeenv 值在 ['xxx', 'yyy'] 中的标签 - key: nodeenv operator: In values: - xxx - yyy 软限制： apiVersion: v1 kind: Pod metadata: name: pod-nodeaffinity-preferred namespace: dev spec: containers: - name: nginx image: nginx affinity: # 亲和性设置 nodeAffinity: # 设置 node 亲和性 preferredDuringSchedulingIgnoredDuringExecution: # 软限制 - weight: 1 preference: matchExpressions: # 匹配 nodeenv 值在 ['xxx', 'yyy'] 中的标签 - key: nodeenv operator: In values: - xxx - yyy 4.2.1 PodAffinity PodAffinity主要实现以运行的Pod为参照，实现让新创建的Pod跟参照pod在同一个区域的功能。 同样有硬限制和软限制 配置项： $ kubectl explain pod.spec.affinity.podAffinity requiredDuringSchedulingIgnoredDuringExecution # 硬限制 namespaces # 指定参照pod的namespace topologyKey # 指定调度作用域 labelSelector # 标签选择器 matchExpressions # 按节点标签列出的节点选择器要求列表(推荐) key # 键 values # 值 operator # 关系符 支持In, NotIn, Exists, DoesNotExist. matchLabels # 指多个matchExpressions映射的内容 preferredDuringSchedulingIgnoredDuringExecution # 软限制 podAffinityTerm # 选项 namespaces topologyKey labelSelector matchExpressions key # 键 values # 值 operator matchLabels weight # 倾向权重，在范围1-100 topologyKey：指定调度作用域 kubernetes.io/hostname，那就是以Node节点为区分范围 beta.kubernetes.io/os,则以Node节点的操作系统类型来区分 Pod配置文件举例 硬限制： apiVersion: v1 kind: Pod metadata: name: pod-podaffinity-required namespace: dev spec: containers: - name: nginx image: nginx affinity: # 亲和性设置 podAffinity: # 设置 pod 亲和性 requiredDuringSchedulingIgnoredDuringExecution: # 硬限制 - labelSelector: matchExpressions: - key: podenv operator: In values: - xxx - yyy topologyKey: kubernetes.io/hostname 4.2.1 PodAntiAffinity PodAntiAffinity主要实现以运行的Pod为参照，让新创建的Pod跟参照pod不在一个区域中的功能。 它的配置方式和选项跟PodAffinity是一样的 ","date":"2022-08-20","objectID":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/:4:2","tags":["K8s","Kubernetes","pod"],"title":"K8s 学习笔记（三）Pod 详解","uri":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/"},{"categories":["学习笔记","K8s"],"content":"4.3 污点和容忍 4.3.1 污点 我们也可以站在Node的角度上，通过在Node上添加污点属性，来决定是否允许Pod调度过来。 Node被设置上污点之后就和Pod之间存在了一种相斥的关系，进而拒绝Pod调度进来，甚至可以将已经存在的Pod驱逐出去。 污点的格式为：key=value:effect, key和value是污点的标签，effect描述污点的作用，支持如下三个选项： PreferNoSchedule：kubernetes将尽量避免把Pod调度到具有该污点的Node上，除非没有其他节点可调度 NoSchedule：kubernetes将不会把Pod调度到具有该污点的Node上，但不会影响当前Node上已存在的Pod NoExecute：kubernetes将不会把Pod调度到具有该污点的Node上，同时也会将Node上已存在的Pod驱离 使用kubeadm搭建的集群，默认就会给master节点添加一个污点标记(node-role.kubernetes.io/master:NoSchedule),所以pod就不会调度到master节点上. 离线的 node 会添加两个污点： node.kubernetes.io/unreachable:NoExecute、node.kubernetes.io/unreachable:NoSchedule 命令： # 设置污点 kubectl taint nodes \u003cnode-name\u003e \u003ckey=value:effect\u003e # 去除污点 kubectl taint nodes \u003cnode-name\u003e \u003ckey:effect-\u003e # 去除所有污点 kubectl taint nodes \u003cnode-name\u003e \u003ckey-\u003e 4.3.2 容忍 污点就是拒绝，容忍就是忽略，Node通过污点拒绝pod调度上去，Pod通过容忍忽略拒绝 Pod配置举例 添加容忍： apiVersion: v1 kind: Pod metadata: name: pod-toleration namespace: dev spec: containers: - name: nginx image: nginx tolerations: # 添加容忍 - key: tag # 要容忍的污点的 key, 空意味着匹配所有的键 operator: Equal # key 和 value 间操作符，支持 Equal 和 Exists（默认） value: heima # 容忍的污点的 value effect: NoExecute # 容忍的规则，必须和标记的污点的规则相同，空意味着匹配所有影响 # tolerationSeconds # 容忍时间, 当effect为NoExecute时生效，表示pod在Node上的停留时间 ","date":"2022-08-20","objectID":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/:4:3","tags":["K8s","Kubernetes","pod"],"title":"K8s 学习笔记（三）Pod 详解","uri":"/posts/notes/devops/k8s/itheima/3-k8s-pod-advanced/"},{"categories":["学习笔记","数据结构和算法"],"content":"1. 单链表和双链表 笔试 vs 面试 笔试：时间复杂度越低越好 面试：时间复杂度越低越好，空间复杂度也要低 链表题目技巧 额外数据结构记录（哈希表等） 快慢指针 算法题 206. 反转链表 反转双向链表 剑指 Offer II 027. 回文链表 方法1：额外栈存储遍历结果，再遍历一遍 方法2：在 1 的基础上栈只存一半数据，用快慢指针(慢指针走两步，快指针一次走一部) 方法3：在 2 的基础上，找到中点和尾节点，从两头向中间遍历 剑指 Offer II 077. 链表排序 面试题 02.04. 分割链表 在上题的基础上，更进一步分成三部分(小于、等于、大于)，时间复杂度 $O(N)$，空间复杂度$O(1)$ 方法： 用 6 个指针记录每段的头尾，最后把 3 段串起来 138. 复制带随机指针的链表 方法1：用哈希表{old_node: new_node} 方法2：遍历形成 old1 -\u003e new1 -\u003e old2 -\u003e new2 ... 的结构，然后遍历把新节点的 random 指针设好，然后分离新老链表 141. 环形链表 142. 环形链表 II 剑指 Offer 52. 两个链表的第一个公共节点 方法1： 两个链表遍历到头，如果最后一个节点不是同一个，不相交 长度大的先走长度差值，两个再一起走，一定会在交点相遇 统计长度用：A 走的时候 n++，B 走的时候 n--，可以节省一个变量 方法2：浪漫解法 方法3： A 逆序，A 原始头节点指向 B 的头节点 如果不成环，说明不相交 成环找出环入口即为答案，再还原两个链表 在上题的基础上，链表可能有环。时间复杂度 $O(N)$，空间复杂度 $O(1)$ 方法： 分别判断两个链表是否有环 如果都没有环，按上题处理 如果一个有环，一个没环，不可能相交 如果都有环： 如果环起点是同一个节点，那么说明他们在环起点上或之前相交，把环节点看出链表终止节点，按上述方法处理 如果环起点不是同一个，一个环起点继续走 如果走回到原位置，还没碰到另一个环起点，那么他们不相交 如果碰到了，那么任意一个环起点都是第一个交点 ","date":"2022-08-20","objectID":"/posts/notes/datastructure_algorithm/zuochengyun/2-linked-list/:1:0","tags":["数据结构","算法","链表"],"title":"数据结构和算法学习笔记（二）链表","uri":"/posts/notes/datastructure_algorithm/zuochengyun/2-linked-list/"},{"categories":["学习笔记","K8s"],"content":"1. Namespace Namespace是kubernetes系统中的一种非常重要资源，它的主要作用是用来实现多套环境的资源隔离或者多租户的资源隔离。 默认情况下，所有 pod 都可以互相访问 Namespace 把资源进行逻辑上的分组 可以通过 K8s 的授权机制，将不同 namespace 分配给不同租户，实现租户的资源隔离，也可以限定不同租户的资源 Kubernetes 会创建几个默认 namespace [root@master ~]# kubectl get namespace NAME STATUS AGE default Active 45h # 所有未指定Namespace的对象都会被分配在default命名空间 kube-node-lease Active 45h # 集群节点之间的心跳维护，v1.13开始引入 kube-public Active 45h # 此命名空间下的资源可以被所有人访问（包括未认证用户） kube-system Active 45h # 所有由Kubernetes系统创建的资源都处于这个命名空间 命令： kubectl \u003ccommand\u003e ns 配置文件： apiVersion: v1 kind: Namespace metadata: name: dev ","date":"2022-08-19","objectID":"/posts/notes/devops/k8s/itheima/2-k8s-getting-start/:1:0","tags":["K8s","Kubernetes","入门"],"title":"K8s 学习笔记（二）入门","uri":"/posts/notes/devops/k8s/itheima/2-k8s-getting-start/"},{"categories":["学习笔记","K8s"],"content":"2. Pod Pod是kubernetes集群进行管理的最小单元，程序要运行必须部署在容器中，而容器必须存在于Pod中。 Pod可以认为是容器的封装，一个Pod中可以存在一个或者多个容器。 命令： kubectl \u003ccommand\u003e pod 配置文件： apiVersion: v1 kind: Pod metadata: name: nginx namespace: dev spec: containers: - image: nginx:1.17.1 name: pod ports: - name: nginx-port containerPort: 80 protocol: TCP kubernetes没有提供单独运行Pod的命令，都是通过Pod控制器来实现的。 kubectl run \u003cpod名称\u003e [参数] ","date":"2022-08-19","objectID":"/posts/notes/devops/k8s/itheima/2-k8s-getting-start/:2:0","tags":["K8s","Kubernetes","入门"],"title":"K8s 学习笔记（二）入门","uri":"/posts/notes/devops/k8s/itheima/2-k8s-getting-start/"},{"categories":["学习笔记","K8s"],"content":"3. Label Label是kubernetes系统中的一个重要概念。它的作用就是在资源上添加标识，用来对它们进行区分和选择。 Label的特点： 一个Label会以key/value键值对的形式附加到各种对象上，如Node、Pod、Service等等 一个资源对象可以定义任意数量的Label ，同一个Label也可以被添加到任意数量的资源对象上去 Label通常在资源对象定义时确定，当然也可以在对象创建后动态添加或者删除 可以通过Label实现资源的多维度分组，以便灵活、方便地进行资源分配、调度、配置、部署等管理工作。 一些常用的Label 示例如下： 版本标签：“version”:“release”, “version”:“stable”…… 环境标签：“environment”:“dev”，“environment”:“test”，“environment”:“pro” 架构标签：“tier”:“frontend”，“tier”:“backend” 标签选择器(Label Selector)：-l key1=value1,key2=value2 命令： # 为资源打标签 kubectl label pod nginx-pod version=1.0 -n dev # 更新标签 kubectl label pod nginx-pod version=2.0 -n dev --overwrite # 筛选标签(标签选择器) kubectl get pod -n dev -l version=2.0 --show-labels # 删除标签 kubectl label pod nginx-pod version- -n dev 配置文件： # 创建时 pod 时指定 label apiVersion: v1 kind: Pod metadata: name: nginx namespace: dev labels: version: \"3.0\" env: \"test\" spec: containers: - image: nginx:1.17.1 name: pod ports: - name: nginx-port containerPort: 80 protocol: TCP ","date":"2022-08-19","objectID":"/posts/notes/devops/k8s/itheima/2-k8s-getting-start/:3:0","tags":["K8s","Kubernetes","入门"],"title":"K8s 学习笔记（二）入门","uri":"/posts/notes/devops/k8s/itheima/2-k8s-getting-start/"},{"categories":["学习笔记","K8s"],"content":"4. Deployment 在kubernetes中，Pod是最小的控制单元，但是kubernetes很少直接控制Pod，一般都是通过Pod控制器来完成的。 Pod控制器用于pod的管理，确保pod资源符合预期的状态，当pod的资源出现故障时，会尝试进行重启或重建pod。 在kubernetes中Pod控制器的种类有很多，本章节只介绍一种：Deployment。 命令： # 创建 Deployment kubectl create deploy nginx --image=nginx --port=80 --replicas=3 --namespace=dev # 删除 Deployment kubectl delete deploy nginx -n dev 配置文件： apiVersion: apps/v1 kind: Deployment metadata: name: nginx namespace: dev spec: replicas: 3 selector: matchLabels: run: nginx template: metadata: labels: run: nginx spec: containers: - image: nginx:1.17.1 name: nginx ports: - containerPort: 80 protocol: TCP ","date":"2022-08-19","objectID":"/posts/notes/devops/k8s/itheima/2-k8s-getting-start/:4:0","tags":["K8s","Kubernetes","入门"],"title":"K8s 学习笔记（二）入门","uri":"/posts/notes/devops/k8s/itheima/2-k8s-getting-start/"},{"categories":["学习笔记","K8s"],"content":"5. Service 虽然每个Pod都会分配一个单独的Pod IP，然而却存在如下两问题： Pod IP 会随着Pod的重建产生变化 Pod IP 仅仅是集群内可见的虚拟IP，外部无法访问 kubernetes设计了Service来解决这个问题。 Service可以看作是一组同类Pod对外的访问接口。借助Service，应用可以方便地实现服务发现和负载均衡。 命令: # 创建(暴露) Service kubectl expose deploy nginx --name=svc-nginx1 --type=ClusterIP --port=80 --target-port=80 -n dev # 查看 Service kubectl get svc svc-nginx1 -n dev -o wide # 上面创建的Service的type类型为ClusterIP，这个ip地址只用集群内部可访问 # 如果需要创建外部也可以访问的Service，需要修改type为NodePort kubectl expose deploy nginx --name=svc-nginx2 --type=NodePort --port=80 --target-port=80 -n dev # 删除 Service kubectl delete svc svc-nginx-1 -n dev 配置文件： apiVersion: v1 kind: Service metadata: name: svc-nginx namespace: dev spec: clusterIP: 10.109.179.231 ports: - port: 80 protocol: TCP targetPort: 80 selector: run: nginx type: ClusterIP ","date":"2022-08-19","objectID":"/posts/notes/devops/k8s/itheima/2-k8s-getting-start/:5:0","tags":["K8s","Kubernetes","入门"],"title":"K8s 学习笔记（二）入门","uri":"/posts/notes/devops/k8s/itheima/2-k8s-getting-start/"},{"categories":["学习笔记","K8s"],"content":"1. Kubernetes 介绍 ","date":"2022-08-19","objectID":"/posts/notes/devops/k8s/itheima/1-k8s-base/:1:0","tags":["K8s","Kubernetes","基础"],"title":"K8s 学习笔记（一）基础","uri":"/posts/notes/devops/k8s/itheima/1-k8s-base/"},{"categories":["学习笔记","K8s"],"content":"1.1 应用部署方式的演变 直接部署在物理机 -\u003e 虚拟化部署 -\u003e 容器化部署 容器化部署方式给带来很多的便利，但是也会出现一些问题，比如说： 一个容器故障停机了，怎么样让另外一个容器立刻启动去替补停机的容器 当并发访问量变大的时候，怎么样做到横向扩展容器数量 这些容器管理的问题统称为容器编排问题，为了解决这些容器编排问题，就产生了一些容器编排的软件： Swarm：Docker自己的容器编排工具 Mesos：Apache的一个资源统一管控的工具，需要和Marathon结合使用 Kubernetes：Google开源的的容器编排工具 ","date":"2022-08-19","objectID":"/posts/notes/devops/k8s/itheima/1-k8s-base/:1:1","tags":["K8s","Kubernetes","基础"],"title":"K8s 学习笔记（一）基础","uri":"/posts/notes/devops/k8s/itheima/1-k8s-base/"},{"categories":["学习笔记","K8s"],"content":"1.2 Kubernetes 简介 kubernetes的本质是一组服务器集群，它可以在集群的每个节点上运行特定的程序，来对节点中的容器进行管理。目的是实现资源管理的自动化，主要提供了如下的主要功能： 自我修复：一旦某一个容器崩溃，能够在1秒中左右迅速启动新的容器 弹性伸缩：可以根据需要，自动对集群中正在运行的容器数量进行调整 服务发现：服务可以通过自动发现的形式找到它所依赖的服务 负载均衡：如果一个服务起动了多个容器，能够自动实现请求的负载均衡 版本回退：如果发现新发布的程序版本有问题，可以立即回退到原来的版本 存储编排：可以根据容器自身的需求自动创建存储卷 ","date":"2022-08-19","objectID":"/posts/notes/devops/k8s/itheima/1-k8s-base/:1:2","tags":["K8s","Kubernetes","基础"],"title":"K8s 学习笔记（一）基础","uri":"/posts/notes/devops/k8s/itheima/1-k8s-base/"},{"categories":["学习笔记","K8s"],"content":"1.3 Kubernetes 组件 Master，集群的控制平面，负责集群管理： ApiServer：资源操作的唯一入口，接收用户输入的命令，提供认证、授权、API注册和发现等机制 Scheduler：集群资源调度，按照预定的调度策略将Pod调度到相应的node节点上 ControllerManager：维护集群的状态，比如程序部署安排、故障检测、自动扩展、滚动更新等 Etcd：存储集群中各种资源对象的信息 Node，集群的数据平面，负责为容器提供运行环境： Kubelet：维护容器的生命周期，即创建、更新、销毁容器 KubeProxy：集群内部的服务发现和负载均衡 Docker、Containerd：各种容器操作 举例，部署一个 nginx 服务： 首先要明确，一旦kubernetes环境启动之后，master和node都会将自身的信息存储到etcd数据库中 一个nginx服务的安装请求会首先被发送到master节点的apiServer组件 apiServer组件会调用scheduler组件来决定到底应该把这个服务安装到哪个node节点上在此时，它会从etcd中读取各个node节点的信息，然后按照一定的算法进行选择，并将结果告知apiServer apiServer调用controller-manager去调度Node节点安装nginx服务 kubelet接收到指令后，会通知docker，然后由docker来启动一个nginx的pod。pod是kubernetes的最小操作单元，容器必须跑在pod中至此 一个nginx服务就运行了，如果需要访问nginx，就需要通过kube-proxy来对pod产生访问的代理这样，外界用户就可以访问集群中的nginx服务了 ","date":"2022-08-19","objectID":"/posts/notes/devops/k8s/itheima/1-k8s-base/:1:3","tags":["K8s","Kubernetes","基础"],"title":"K8s 学习笔记（一）基础","uri":"/posts/notes/devops/k8s/itheima/1-k8s-base/"},{"categories":["学习笔记","K8s"],"content":"1.4 Kubernetes 概念 Master：集群控制节点，每个集群至少一个 Node：集群工作节点 Pod：K8s 最小控制单元，容器运行在 pod 中，一个 pod 可以运行多个容器 Controller： 控制器，实现对 pod 的管理，比如启动 pod、停止 pod、伸缩 pod Service：pod 对外服务的统一入口，下面维护着同一类的多个 pod Label：标签，对 pod 分类 NameSpace：命名空间，隔离 pod 的运行环境 ","date":"2022-08-19","objectID":"/posts/notes/devops/k8s/itheima/1-k8s-base/:1:4","tags":["K8s","Kubernetes","基础"],"title":"K8s 学习笔记（一）基础","uri":"/posts/notes/devops/k8s/itheima/1-k8s-base/"},{"categories":["学习笔记","K8s"],"content":"2. 集群环境搭建 ","date":"2022-08-19","objectID":"/posts/notes/devops/k8s/itheima/1-k8s-base/:2:0","tags":["K8s","Kubernetes","基础"],"title":"K8s 学习笔记（一）基础","uri":"/posts/notes/devops/k8s/itheima/1-k8s-base/"},{"categories":["学习笔记","K8s"],"content":"2.1 环境规划 2.1.1 集群类型 kubernetes集群大体上分为两类：一主多从和多主多从。 一主多从：一台Master节点和多台Node节点，搭建简单，但是有单机故障风险，适合用于测试环境 多主多从：多台Master节点和多台Node节点，搭建麻烦，安全性高，适合用于生产环境 2.1.2 安装方式 kubernetes有多种部署方式，目前主流的方式有kubeadm、minikube、二进制包 minikube：一个用于快速搭建单节点kubernetes的工具 kubeadm：一个用于快速搭建kubernetes集群的工具 二进制包 ：从官网下载每个组件的二进制包，依次去安装，此方式对于理解kubernetes组件更加有效 2.1.3 主机规划 本教程搭建 1 主 2 从集群 kube* version：1.23.10(1.24.x 移除了 dockershim， 跑不起来，通过 cri-dockerd 也不行，就用老版本了) docker version：20.10.17 ","date":"2022-08-19","objectID":"/posts/notes/devops/k8s/itheima/1-k8s-base/:2:1","tags":["K8s","Kubernetes","基础"],"title":"K8s 学习笔记（一）基础","uri":"/posts/notes/devops/k8s/itheima/1-k8s-base/"},{"categories":["学习笔记","K8s"],"content":"2.2 安装步骤 初始化环境 主机名解析(/etc/hosts) 时间同步(chronyd) 禁用 iptables, firewall, selinux, swap 网桥过滤和地址转发 安装 docker, kubeadm, kubectl, kubelet 安装、配置 ipvs init master, 添加 node 安装网络插件 flannel ","date":"2022-08-19","objectID":"/posts/notes/devops/k8s/itheima/1-k8s-base/:2:2","tags":["K8s","Kubernetes","基础"],"title":"K8s 学习笔记（一）基础","uri":"/posts/notes/devops/k8s/itheima/1-k8s-base/"},{"categories":["学习笔记","K8s"],"content":"3. 资源管理 ","date":"2022-08-19","objectID":"/posts/notes/devops/k8s/itheima/1-k8s-base/:3:0","tags":["K8s","Kubernetes","基础"],"title":"K8s 学习笔记（一）基础","uri":"/posts/notes/devops/k8s/itheima/1-k8s-base/"},{"categories":["学习笔记","K8s"],"content":"3.1 资源管理介绍 在kubernetes中，所有的内容都抽象为资源，用户需要通过操作资源来管理kubernetes。 kubernetes的本质上就是一个集群系统，用户可以在集群中部署各种服务，所谓的部署服务，其实就是在kubernetes集群中运行一个个的容器，并将指定的程序跑在容器中。 kubernetes的最小管理单元是pod而不是容器，所以只能将容器放在Pod中，而kubernetes一般也不会直接管理Pod，而是通过Pod控制器来管理Pod的。 Pod可以提供服务之后，就要考虑如何访问Pod中服务，kubernetes提供了Service资源实现这个功能。 如果Pod中程序的数据需要持久化，kubernetes还提供了各种存储系统。 学习kubernetes的核心，就是学习如何对集群上的Pod、Pod控制器、Service、存储等各种资源进行操作 ","date":"2022-08-19","objectID":"/posts/notes/devops/k8s/itheima/1-k8s-base/:3:1","tags":["K8s","Kubernetes","基础"],"title":"K8s 学习笔记（一）基础","uri":"/posts/notes/devops/k8s/itheima/1-k8s-base/"},{"categories":["学习笔记","K8s"],"content":"3.2 YAML 语言 YAML 语言教程 - 阮一峰的网络日志 ","date":"2022-08-19","objectID":"/posts/notes/devops/k8s/itheima/1-k8s-base/:3:2","tags":["K8s","Kubernetes","基础"],"title":"K8s 学习笔记（一）基础","uri":"/posts/notes/devops/k8s/itheima/1-k8s-base/"},{"categories":["学习笔记","K8s"],"content":"3.3 资源管理方式 命令式对象管理：直接使用命令去操作kubernetes资源 kubectl run nginx-pod --image=nginx:1.17.1 --port=80 命令式对象配置：通过命令配置和配置文件去操作kubernetes资源 kubectl create/patch -f nginx-pod.yaml 声明式对象配置：通过apply命令和配置文件去操作kubernetes资源 kubectl apply -f nginx-pod.yaml 类型 操作对象 适用环境 优点 缺点 命令式对象管理 对象 测试 简单 只能操作活动对象，无法审计、跟踪 命令式对象配置 文件 开发 可以审计、跟踪 项目大时，配置文件多，操作麻烦 声明式对象配置 目录 开发 支持目录操作 意外情况下难以调试 kubectl可以在node节点上运行吗? kubectl的运行是需要进行配置的，它的配置文件是$HOME/.kube，如果想要在node节点运行此命令，需要将master上的.kube文件复制到node节点上 三种方式应该怎么用? 创建/更新资源：使用声明式对象配置 kubectl apply -f XXX.yaml 删除资源：使用命令式对象配置 kubectl delete -f XXX.yaml 查询资源：使用命令式对象管理 kubectl get(describe) 资源名称 ","date":"2022-08-19","objectID":"/posts/notes/devops/k8s/itheima/1-k8s-base/:3:3","tags":["K8s","Kubernetes","基础"],"title":"K8s 学习笔记（一）基础","uri":"/posts/notes/devops/k8s/itheima/1-k8s-base/"},{"categories":["学习笔记","K8s"],"content":"3.3.1 命令式对象管理 kubectl [command] [type] [name] [flags] comand：指定要对资源执行的操作，例如create、get、delete type：指定资源类型，比如deployment、pod、service name：指定资源的名称，名称大小写敏感 flags：指定额外的可选参数 command： 命令分类 命令 翻译 命令作用 基本命令 create 创建 创建一个资源 edit 编辑 编辑一个资源 get 获取 获取一个资源 patch 更新 更新一个资源 delete 删除 删除一个资源 explain 解释 展示资源文档 运行和调试 run 运行 在集群中运行一个指定的镜像 expose 暴露 暴露资源为Service describe 描述 显示资源内部信息 logs 日志 输出容器在 pod 中的日志 attach 缠绕 进入运行中的容器 exec 执行 执行容器中的一个命令 cp 复制 在Pod内外复制文件 rollout 首次展示 管理资源的发布 scale 规模 扩(缩)容Pod的数量 autoscale 自动调整 自动调整Pod的数量 高级命令 apply rc 通过文件对资源进行配置 label 标签 更新资源上的标签 其他命令 cluster-info 集群信息 显示集群信息 version 版本 显示当前Server和Client的版本 type 资源分类 资源名称 缩写 资源作用 集群级别资源 nodes no 集群组成部分 namespaces ns 隔离Pod pod资源 pods po 装载容器 pod资源控制器 replicationcontrollers rc 控制pod资源 replicasets rs 控制pod资源 deployments deploy 控制pod资源 daemonsets ds 控制pod资源 jobs 控制pod资源 cronjobs cj 控制pod资源 horizontalpodautoscalers hpa 控制pod资源 statefulsets sts 控制pod资源 服务发现资源 services svc 统一pod对外接口 ingress ing 统一pod对外接口 存储资源 volumeattachments 存储 persistentvolumes pv 存储 persistentvolumeclaims pvc 存储 配置资源 configmaps cm 配置 secrets 配置 ","date":"2022-08-19","objectID":"/posts/notes/devops/k8s/itheima/1-k8s-base/:3:4","tags":["K8s","Kubernetes","基础"],"title":"K8s 学习笔记（一）基础","uri":"/posts/notes/devops/k8s/itheima/1-k8s-base/"},{"categories":["学习笔记","K8s"],"content":"3.3.2 命令式对象配置 使用命令配合配置文件一起来操作kubernetes资源。 命令式对象配置的方式操作资源，可以简单的认为：命令 + yaml配置文件（里面是命令需要的各种参数） ","date":"2022-08-19","objectID":"/posts/notes/devops/k8s/itheima/1-k8s-base/:3:5","tags":["K8s","Kubernetes","基础"],"title":"K8s 学习笔记（一）基础","uri":"/posts/notes/devops/k8s/itheima/1-k8s-base/"},{"categories":["学习笔记","K8s"],"content":"3.3.3 声明式对象配置 声明式对象配置跟命令式对象配置很相似，但是它只有一个命令apply。 其实声明式对象配置就是使用apply描述一个资源最终的状态（在yaml中定义状态） 使用apply操作资源： 如果资源不存在，就创建，相当于 kubectl create 如果资源已存在，就更新，相当于 kubectl patch ","date":"2022-08-19","objectID":"/posts/notes/devops/k8s/itheima/1-k8s-base/:3:6","tags":["K8s","Kubernetes","基础"],"title":"K8s 学习笔记（一）基础","uri":"/posts/notes/devops/k8s/itheima/1-k8s-base/"},{"categories":["学习笔记","docker"],"content":"1. Docker 配置扫描 docker-bench-security ","date":"2022-08-16","objectID":"/posts/notes/devops/docker/imooc/12-docker-security/:1:0","tags":["docker","安全"],"title":"Docker 学习笔记（十二）容器安全","uri":"/posts/notes/devops/docker/imooc/12-docker-security/"},{"categories":["学习笔记","docker"],"content":"2. 代码和镜像漏洞扫描 CVE：国际著名的安全漏洞库，也是对已知漏洞和安全缺陷的标准化名称的列表。 代码扫描 synk 镜像扫描 trivy ","date":"2022-08-16","objectID":"/posts/notes/devops/docker/imooc/12-docker-security/:2:0","tags":["docker","安全"],"title":"Docker 学习笔记（十二）容器安全","uri":"/posts/notes/devops/docker/imooc/12-docker-security/"},{"categories":["学习笔记","docker"],"content":"3. 容器运行监控 ","date":"2022-08-16","objectID":"/posts/notes/devops/docker/imooc/12-docker-security/:3:0","tags":["docker","安全"],"title":"Docker 学习笔记（十二）容器安全","uri":"/posts/notes/devops/docker/imooc/12-docker-security/"},{"categories":["学习笔记","docker"],"content":"1. GitHub Actions GitHub Actions 是一个持续集成和持续交付 (CI/CD) 平台，可用于自动执行构建、测试和部署管道。 您可以创建工作流程来构建和测试存储库的每个拉取请求，或将合并的拉取请求部署到生产环境。 GitHub 提供 Linux、Windows 和 macOS 虚拟机来运行工作流程 GitHub Actions 官方教程 ","date":"2022-08-16","objectID":"/posts/notes/devops/docker/imooc/11-docker-cicd-with-git/:1:0","tags":["docker","CI/CD","git","GitHub Actions"],"title":"Docker 学习笔记（十一）GitHub Actions - CI/CD","uri":"/posts/notes/devops/docker/imooc/11-docker-cicd-with-git/"},{"categories":["学习笔记","docker"],"content":"1. docker swarm 简介 ","date":"2022-08-15","objectID":"/posts/notes/devops/docker/imooc/8-docker-swarm/:1:0","tags":["docker","docker swarm"],"title":"Docker 学习笔记（八）docker swarm","uri":"/posts/notes/devops/docker/imooc/8-docker-swarm/"},{"categories":["学习笔记","docker"],"content":"1.1 不建议生产环境使用 docker-compose docker compose 是单机环境，物理机如果挂掉，上面的容器全部会挂掉，无法保证可靠性 无法跨机器做横向扩展 ","date":"2022-08-15","objectID":"/posts/notes/devops/docker/imooc/8-docker-swarm/:1:1","tags":["docker","docker swarm"],"title":"Docker 学习笔记（八）docker swarm","uri":"/posts/notes/devops/docker/imooc/8-docker-swarm/"},{"categories":["学习笔记","docker"],"content":"1.2 容器编排 swarm 多个 manager：一个 primary，多个 secondary ","date":"2022-08-15","objectID":"/posts/notes/devops/docker/imooc/8-docker-swarm/:1:2","tags":["docker","docker swarm"],"title":"Docker 学习笔记（八）docker swarm","uri":"/posts/notes/devops/docker/imooc/8-docker-swarm/"},{"categories":["学习笔记","docker"],"content":"2. swarm 单节点 创建 swarm：docker swarm init 查看 nodes：docker node ls docker swarm init 背后发生了什么? 主要是PKI和安全相关的自动化 创建swarm集群的根证书 manager节点的证书 其它节点加入集群需要的tokens 创建Raft数据库用于存储证书，配置，密码等数据 swarm 节点操作： service：类似 compose 里 service 的概念， 一个 service 对于多个 replica（多个容器） 创建 service：docker service create [OPTIONS] \u003cIMAGE\u003e [COMMAND] 横向扩展 service：docker service update \u003cSERVICE\u003e --replicas \u003cNUM\u003e、docker service scale SERVICE=REPLICAS [SERVICE=REPLICAS...] 一个 replica 挂掉后，service 会自动新建一个 删除 service：docker service rm \u003cSERVICE\u003e 查看 service: 查看 service：docker service ls 查看 tasks(各个 replica 包括其在哪个节点上)：docker service ps \u003cSERVICE\u003e [SERVICE...] ","date":"2022-08-15","objectID":"/posts/notes/devops/docker/imooc/8-docker-swarm/:2:0","tags":["docker","docker swarm"],"title":"Docker 学习笔记（八）docker swarm","uri":"/posts/notes/devops/docker/imooc/8-docker-swarm/"},{"categories":["学习笔记","docker"],"content":"3. swarm 三节点搭建 service 相关操作要在 manager 上 ","date":"2022-08-15","objectID":"/posts/notes/devops/docker/imooc/8-docker-swarm/:3:0","tags":["docker","docker swarm"],"title":"Docker 学习笔记（八）docker swarm","uri":"/posts/notes/devops/docker/imooc/8-docker-swarm/"},{"categories":["学习笔记","docker"],"content":"4. swarm 的 overlay 网络 创建 overlay 网络：docker network create -d overlay \u003cNAME\u003e 创建 service 指定 overlay 网络：docker service create --network \u003coverlay-network-name\u003e \u003cIMAGE\u003e [COMMAND] 外部如何访问部署运行在swarm集群内的服务，可以称之为入方向流量，在swarm里我们通过 ingress 来解决 部署在swarm集群里的服务，如何对外进行访问，这部分又分为两块: 第一，东西向流量 ，也就是不同swarm节点上的容器之间如何通信，swarm通过 overlay 网络来解决； 第二，南北向流量 ，也就是swarm集群里的容器如何对外访问，比如互联网，这个是 Linux bridge + iptables NAT 来解决的 在容器里执行 ip addr 可以看到设备 ip： 1: lo: \u003cLOOPBACK,UP,LOWER_UP\u003e mtu 65536 qdisc noqueue qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 21: eth0@if22: \u003cBROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN\u003e mtu 1450 qdisc noqueue link/ether 02:42:0a:00:01:03 brd ff:ff:ff:ff:ff:ff inet 10.0.1.3/24 brd 10.0.1.255 scope global eth0 valid_lft forever preferred_lft forever 23: eth1@if24: \u003cBROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN\u003e mtu 1500 qdisc noqueue link/ether 02:42:ac:12:00:03 brd ff:ff:ff:ff:ff:ff inet 172.18.0.3/16 brd 172.18.255.255 scope global eth1 valid_lft forever preferred_lft forever 在容器里执行 ip route 可以看到路由： default via 172.18.0.1 dev eth1 10.0.1.0/24 dev eth0 scope link src 10.0.1.3 172.18.0.0/16 dev eth1 scope link src 172.18.0.3 可以看出： 默认走 eth1(bridge 网络) 10.0.1.0/24 的流量会走 eth0(overlay 网络) ","date":"2022-08-15","objectID":"/posts/notes/devops/docker/imooc/8-docker-swarm/:4:0","tags":["docker","docker swarm"],"title":"Docker 学习笔记（八）docker swarm","uri":"/posts/notes/devops/docker/imooc/8-docker-swarm/"},{"categories":["学习笔记","docker"],"content":"5.swarm 的 ingress 网络 docker swarm 的ingress网络又叫 Ingress Routing Mesh，主要是为了实现把service的服务端口对外发布出去，让其能够被外部网络访问到。 ingress routing mesh是docker swarm网络里最复杂的一部分内容，包括多方面的内容： iptables的 Destination NAT流量转发 Linux bridge, network namespace 使用IPVS技术做负载均衡 包括容器间的通信（overlay）和入方向流量的端口转发 任意节点上都可以访问的映射的网络端口 负载均衡 ","date":"2022-08-15","objectID":"/posts/notes/devops/docker/imooc/8-docker-swarm/:5:0","tags":["docker","docker swarm"],"title":"Docker 学习笔记（八）docker swarm","uri":"/posts/notes/devops/docker/imooc/8-docker-swarm/"},{"categories":["学习笔记","docker"],"content":"6. 内部负载均衡和 VIP 在一个 overlay 网络中，访问 service 名称，DNS 会解析到 overlay 网络的 VIP(virtual ip)，由 VIP 做负载均衡 ","date":"2022-08-15","objectID":"/posts/notes/devops/docker/imooc/8-docker-swarm/:6:0","tags":["docker","docker swarm"],"title":"Docker 学习笔记（八）docker swarm","uri":"/posts/notes/devops/docker/imooc/8-docker-swarm/"},{"categories":["学习笔记","docker"],"content":"7. swarm stack 部署多 service 应用 编写 docker-compose.yml 文件 build image docker-compose build 通过 docker stack 部署：docker stack deploy --compose-file docker-compose.yml \u003cStack-Name\u003e ","date":"2022-08-15","objectID":"/posts/notes/devops/docker/imooc/8-docker-swarm/:7:0","tags":["docker","docker swarm"],"title":"Docker 学习笔记（八）docker swarm","uri":"/posts/notes/devops/docker/imooc/8-docker-swarm/"},{"categories":["学习笔记","docker"],"content":"8. 在 swarm 中使用 secret 使用 docker secret 保护敏感信息 通过 std 创建 secret：echo abc123 | docker secret create mysql_pass - 从文件创建 secret：docker secret create mysql_pass mysql_pass.txt 使用 secret： 创建 service 时指定 secret：--secret mysql_pass 该 secret 会挂载到容器的文件系统中：/run/secrets/mysql_pass ","date":"2022-08-15","objectID":"/posts/notes/devops/docker/imooc/8-docker-swarm/:8:0","tags":["docker","docker swarm"],"title":"Docker 学习笔记（八）docker swarm","uri":"/posts/notes/devops/docker/imooc/8-docker-swarm/"},{"categories":["学习笔记","docker"],"content":"9. swarm 使用 local volume docker service create --mount 在 docker-file 中配置 volume，通过 docker stack deploy 部署 ","date":"2022-08-15","objectID":"/posts/notes/devops/docker/imooc/8-docker-swarm/:9:0","tags":["docker","docker swarm"],"title":"Docker 学习笔记（八）docker swarm","uri":"/posts/notes/devops/docker/imooc/8-docker-swarm/"},{"categories":["学习笔记","docker"],"content":"1. podman 简介 ","date":"2022-08-15","objectID":"/posts/notes/devops/docker/imooc/9-docker-vs-podman/:1:0","tags":["docker","podman"],"title":"Docker 学习笔记（九）docker vs podman","uri":"/posts/notes/devops/docker/imooc/9-docker-vs-podman/"},{"categories":["学习笔记","docker"],"content":"1.1 什么是 podman Podman 是一个基于 Linux 系统的 daemon-less 的容器引擎。 可以用来开发，管理和运行 OCI 标准的容器. podman 可以运行在 root 或者非 root 用户模式。 podman 与 docker 命令完全兼容，只需将 docker 替换为 podman 即可 ","date":"2022-08-15","objectID":"/posts/notes/devops/docker/imooc/9-docker-vs-podman/:1:1","tags":["docker","podman"],"title":"Docker 学习笔记（九）docker vs podman","uri":"/posts/notes/devops/docker/imooc/9-docker-vs-podman/"},{"categories":["学习笔记","docker"],"content":"1.2 podman 和 docker 的区别 最主要的区别是podman是Daemonless的，而Docker在执行任务的时候，必须依赖于后台的docker daemon podman不需要使用root用户或者root权限，所以更安全。 podman可以创建pod，pod的概念和Kubernetes 里定义的pod类似 podman运行把镜像和容器存储在不同的地方，但是docker必须存储在docker engineer所在的本地 podman是传统的 fork-exec 模式，而docker是 client-server 架构 docker 架构： podman 架构 ","date":"2022-08-15","objectID":"/posts/notes/devops/docker/imooc/9-docker-vs-podman/:1:2","tags":["docker","podman"],"title":"Docker 学习笔记（九）docker vs podman","uri":"/posts/notes/devops/docker/imooc/9-docker-vs-podman/"},{"categories":["学习笔记","docker"],"content":"1. 使用 buildx 构建多架构支持的 Docker 镜像 Docker for Linux 不支持构建 arm 架构镜像，我们可以运行一个新的容器让其支持该特性，Docker 桌面版无需进行此项设置： docker run --rm --privileged tonistiigi/binfmt:latest --install all 由于 Docker 默认的 builder 实例不支持同时指定多个 –platform，我们必须首先创建一个新的 builder 实例：docker buildx create --name mybuilder --use 构建并 push 镜像：docker buildx build --push --platform linux/arm,linux/arm64,linux/amd64 -t myusername/hello . ","date":"2022-08-15","objectID":"/posts/notes/devops/docker/imooc/10-docker-arch/:1:0","tags":["docker","podman"],"title":"Docker 学习笔记（十）docker 的多架构支持","uri":"/posts/notes/devops/docker/imooc/10-docker-arch/"},{"categories":["学习笔记","docker"],"content":"1. 简介 docker-compose： 定义和运行多个 Docker 容器的应用 compose v2： Docker 官方用 GO 语言 重写 了 Docker Compose，并将其作为了 docker cli 的子命令，称为 Compose V2。docker-compose 命令替换为 docker compose，即可使用 Compose v2 ","date":"2022-08-14","objectID":"/posts/notes/devops/docker/imooc/7-docker-compose/:1:0","tags":["docker","docker-compose"],"title":"Docker 学习笔记（七）docker compose","uri":"/posts/notes/devops/docker/imooc/7-docker-compose/"},{"categories":["学习笔记","docker"],"content":"2. compose 文件结构和命令 基本语法结构： version: \"3.8\" # 新版 compose spec 废弃了 version 字段，不用指定 version services: # 容器 servicename: # 服务名字，这个名字也是内部 bridge网络可以使用的 DNS name image: # 可选，镜像的名字 build: # 可选，如果同时指定了 image 会使用 image 字段作为镜像名称 command: # 可选，如果设置，则会覆盖默认镜像里的 CMD命令 environment: # 可选，相当于 docker run里的 --env volumes: # 可选，相当于docker run里的 -v networks: # 可选，相当于 docker run里的 --network ports: # 可选，相当于 docker run里的 -p servicename2: volumes: # 可选，相当于 docker volume create networks: # 可选，相当于 docker network create 命令： 创建并启动：docker compose [-f composefile.yml] up [-d] [--build] 停止并删除：docker compose [-f composefile.yml] down 启动、停止：docker compose [-f composefile.yml] {start|stop} 重启：docker compose [-f composefile.yml] restart build or rebuild：docker compose [-f composefile.yml] build ","date":"2022-08-14","objectID":"/posts/notes/devops/docker/imooc/7-docker-compose/:2:0","tags":["docker","docker-compose"],"title":"Docker 学习笔记（七）docker compose","uri":"/posts/notes/devops/docker/imooc/7-docker-compose/"},{"categories":["学习笔记","docker"],"content":"3. compose 网络 不指定网络，会创建一个默认网络 创建网络不指定 driver 为默认 bridge ","date":"2022-08-14","objectID":"/posts/notes/devops/docker/imooc/7-docker-compose/:3:0","tags":["docker","docker-compose"],"title":"Docker 学习笔记（七）docker compose","uri":"/posts/notes/devops/docker/imooc/7-docker-compose/"},{"categories":["学习笔记","docker"],"content":"4. compose 水平扩展 配置 compose file services: frontend: image: awesome/webapp deploy: mode: replicated replicas: 6 或者 up 时指定 scale，会覆盖 compose file 中的配置：docker compose up -d --scale frontend=3 还会做简单的负载均衡，使用 service name 访问时，dns 会解析到不同的 replicas 中 ","date":"2022-08-14","objectID":"/posts/notes/devops/docker/imooc/7-docker-compose/:4:0","tags":["docker","docker-compose"],"title":"Docker 学习笔记（七）docker compose","uri":"/posts/notes/devops/docker/imooc/7-docker-compose/"},{"categories":["学习笔记","docker"],"content":"5. compose 环境变量 在 compose 文件中使用 ${VAR_NAME} 代表从外部读取变量值填入 compose 文件 传入变量的方式：创建 .env 文件，在文件中赋值会自动传入 验证 compose 文件：docker compose config 指定 env 文件名：docker compose --env-file \u003cfilename\u003e ... ","date":"2022-08-14","objectID":"/posts/notes/devops/docker/imooc/7-docker-compose/:5:0","tags":["docker","docker-compose"],"title":"Docker 学习笔记（七）docker compose","uri":"/posts/notes/devops/docker/imooc/7-docker-compose/"},{"categories":["学习笔记","docker"],"content":"6. 服务依赖和健康检查 depends_on 指定依赖，被依赖的服务启动后，才会启动该服务 只依赖启动顺序不靠谱，可能被依赖的服务启动了但是发生错误了，因此需要健康检查 Dockerfile 也可以定义健康检查：HEALTHCHECK 指令，根据 --interval 间隔不断检查，docker container ls 可以在 STATUS 字段看到 health 状态(starting、healthy, unhealthy) 在 compose 文件中定义 health check： healthcheck: test: [\"CMD\", \"curl\", \"-f\", \"http://localhost\"] interval: 1m30s timeout: 10s retries: 3 start_period: 40s 只有 depends_on 是 [healthy|started] 才启动： depends_on: db: condition: service_healthy redis: condition: service_started ","date":"2022-08-14","objectID":"/posts/notes/devops/docker/imooc/7-docker-compose/:6:0","tags":["docker","docker-compose"],"title":"Docker 学习笔记（七）docker compose","uri":"/posts/notes/devops/docker/imooc/7-docker-compose/"},{"categories":["学习笔记","数据结构和算法"],"content":"1. 复杂度和简单排序算法 ","date":"2022-08-14","objectID":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/:1:0","tags":["数据结构","算法","时间复杂度","空间复杂度","排序算法","位运算","二分查找","选择排序","冒泡排序","插入排序","归并排序","快速排序","堆排序","桶排序","荷兰国旗问题"],"title":"数据结构和算法学习笔记（一）排序算法","uri":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/"},{"categories":["学习笔记","数据结构和算法"],"content":"1.1 时间复杂度 时间复杂度：算法总操作数的表达式中，只要高阶项，不要高阶项的系数，剩下的部分假设为 $f(n)$，则时间复杂度为 $O(f(n))$ $O(f(n))$ 按照算法可能遇到的最差的情况估计 如果两个算法复杂度相同，很难区分哪个更好，可以通过测试的方式，确定选择 ","date":"2022-08-14","objectID":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/:1:1","tags":["数据结构","算法","时间复杂度","空间复杂度","排序算法","位运算","二分查找","选择排序","冒泡排序","插入排序","归并排序","快速排序","堆排序","桶排序","荷兰国旗问题"],"title":"数据结构和算法学习笔记（一）排序算法","uri":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/"},{"categories":["学习笔记","数据结构和算法"],"content":"1.2 位运算 1.2.1 ^ 异或运算：也可以理解成无进位相加 性质： 0 ^ N = N N ^ N = 0 满足交换律、结合律：从无进位相加来考虑，每个二进制位的值之和每个数上同位的值的个数(奇偶)有关 因此，交换变量的值： a = a ^ b # a = a ^ b, b = b b = a ^ b # b = a ^ b ^ b = a, a = a ^ b a = a ^ b # a = a ^ b ^ a = b, b = a a、b 的值可以一样，但不能是同一块内存空间，否则会抹成0，如 a, b 是 list 中相同的 index Question： 136. 只出现一次的数字，要求：时间复杂度$O(n)$，空间复杂度$O(1)$ 260. 只出现一次的数字 III，要求：时间复杂度$O(n)$，空间复杂度$O(1)$ 提取一个数二进制位中最右侧的 1(其他位都置为 0): a \u0026 (~a + 1) ","date":"2022-08-14","objectID":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/:1:2","tags":["数据结构","算法","时间复杂度","空间复杂度","排序算法","位运算","二分查找","选择排序","冒泡排序","插入排序","归并排序","快速排序","堆排序","桶排序","荷兰国旗问题"],"title":"数据结构和算法学习笔记（一）排序算法","uri":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/"},{"categories":["学习笔记","数据结构和算法"],"content":"1.3 排序算法 1.3.1 选择排序 def selection_sort(arr: List[int]): if not arr or len(arr) \u003c= 1: return for i in range(len(arr)): min_index = i for j in range(i, len(arr)): if arr[j] \u003c arr[min_index]: min_index = j arr[i], arr[min_index] = arr[min_index], arr[i] 时间复杂度：$O(n^2)$ 1.3.2 冒泡排序 def bubble_sort(arr: List[int]): if not arr or len(arr) \u003c= 1: return for i in range(len(arr) - 1, -1, -1): for j in range(i): if arr[j] \u003e arr[j + 1]: arr[j], arr[j + 1] = arr[j + 1], arr[j] 时间复杂度：$O(n^2)$ 1.3.3 插入排序 def selection_sort(arr: List[int]): if not arr or len(arr) \u003c= 1: return for i in range(len(arr)): cur_num = arr[i] while i \u003e 0 and arr[i - 1] \u003e cur_num: arr[i] = arr[i - 1] i -= 1 arr[i] = cur_num 时间复杂度：$O(n^2)$；最好的情况（数组已经有序）下，时间复杂度$O(n)$ ","date":"2022-08-14","objectID":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/:1:3","tags":["数据结构","算法","时间复杂度","空间复杂度","排序算法","位运算","二分查找","选择排序","冒泡排序","插入排序","归并排序","快速排序","堆排序","桶排序","荷兰国旗问题"],"title":"数据结构和算法学习笔记（一）排序算法","uri":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/"},{"categories":["学习笔记","数据结构和算法"],"content":"1.4 二分查找 1.4.1 有序数组中，找某个数是否存在 时间复杂度：$O(log_2 N)$、$O(logN)$ 1.4.2 有序数组中，找 \u003e= 某个数最左侧的位置 找到后还得继续往左找，一个变量记录上次位置，直到找到底 1.4.3 无序数组中，局部最小值 162. 寻找峰值 假如索引 0，1 呈下降趋势，索引 n-1，n-2 也呈下降趋势，那么 0 和 n-1 中间必定有局部最小值 中点索引 mid，如果 mid 值小于左边和右边，找到了，返回，否则 假如 mid，mid-1 呈下降趋势，那么 0 和 mid 中间必定有局部最小值；右边同理 二分继续 ","date":"2022-08-14","objectID":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/:1:4","tags":["数据结构","算法","时间复杂度","空间复杂度","排序算法","位运算","二分查找","选择排序","冒泡排序","插入排序","归并排序","快速排序","堆排序","桶排序","荷兰国旗问题"],"title":"数据结构和算法学习笔记（一）排序算法","uri":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/"},{"categories":["学习笔记","数据结构和算法"],"content":"1.5 对数器的概念和使用 对数器是通过用大量测试数据来验证算法是否正确的一种方式。 流程： 有一个你想要测的方法a； 实现一个绝对正确但是复杂度不好的方法b； 实现一个随机样本产生器； 实现对比算法a和b的方法； 把方法a和方法b比对多次来验证方法a是否正确； 如果有一个样本使得比对出错，打印样本分析是哪个方法出错； 当样本数量很多时比对测试依然正确，可以确定方法a已经正确。 注意： 随机产生的样本应该是小数据集，但是要进行多次(10w+)的对比。小数据集是因为方便对比分析，多次比对是要覆盖所有的随机情况。 算法b要保持正确性。 ","date":"2022-08-14","objectID":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/:1:5","tags":["数据结构","算法","时间复杂度","空间复杂度","排序算法","位运算","二分查找","选择排序","冒泡排序","插入排序","归并排序","快速排序","堆排序","桶排序","荷兰国旗问题"],"title":"数据结构和算法学习笔记（一）排序算法","uri":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/"},{"categories":["学习笔记","数据结构和算法"],"content":"1.6 递归行为及其时间复杂度估计 master 公式，如果调用子问题规模相等，可以用该公式求时间复杂度： $$T(N) = a * T(N / b) + O(N ^ d)$$ $T(N)$：母问题的数据量为 $N$ $T(N / b)$：子问题的规模是 $N / b$ $a$：子问题调用次数 $O(N ^ d)$：除了子问题调用，剩下的过程的时间复杂度 求解时间复杂度： 如果 $log_b a \u003e d$: $O(N ^ (log_b a))$ 如果 $log_b a == d$: $O((N ^ d) * log N)$ 如果 $log_b a \u003c d$: $O(N ^ d)$ ","date":"2022-08-14","objectID":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/:1:6","tags":["数据结构","算法","时间复杂度","空间复杂度","排序算法","位运算","二分查找","选择排序","冒泡排序","插入排序","归并排序","快速排序","堆排序","桶排序","荷兰国旗问题"],"title":"数据结构和算法学习笔记（一）排序算法","uri":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/"},{"categories":["学习笔记","数据结构和算法"],"content":"2.O(NlogN) 的排序 ","date":"2022-08-14","objectID":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/:2:0","tags":["数据结构","算法","时间复杂度","空间复杂度","排序算法","位运算","二分查找","选择排序","冒泡排序","插入排序","归并排序","快速排序","堆排序","桶排序","荷兰国旗问题"],"title":"数据结构和算法学习笔记（一）排序算法","uri":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/"},{"categories":["学习笔记","数据结构和算法"],"content":"2.1 归并排序 代码： def merge_sort(arr: List[int]) -\u003e None: if not arr or len(arr) \u003c= 1: return process(arr, 0, len(arr) - 1) def process(arr: List[int], left: int, right: int) -\u003e None: if left == right: return mid = left + (right - left) // 2 process(arr, left, mid) process(arr, mid + 1, right) merge(arr, left, mid, right) def merge(arr: List[int], left: int, mid: int, right: int) -\u003e None: tmp = [] p = left q = mid + 1 while p \u003c= mid and q \u003c= right: if arr[p] \u003c arr[q]: tmp.append(arr[p]) p += 1 else: tmp.append(arr[q]) q += 1 tmp.extend(arr[p:mid + 1]) tmp.extend(arr[q:right + 1]) arr[left:right + 1] = tmp 时间复杂度(可由 master 公式求解)：$O(NlogN)$ 空间复杂度：$O(N)$ 算法题： 计算数组的小和 剑指 Offer 51. 数组中的逆序对 315. 计算右侧小于当前元素的个数 ","date":"2022-08-14","objectID":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/:2:1","tags":["数据结构","算法","时间复杂度","空间复杂度","排序算法","位运算","二分查找","选择排序","冒泡排序","插入排序","归并排序","快速排序","堆排序","桶排序","荷兰国旗问题"],"title":"数据结构和算法学习笔记（一）排序算法","uri":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/"},{"categories":["学习笔记","数据结构和算法"],"content":"2.2 快速排序 提出问题： 问题一，给定一个数组 arr， 和一个数 num，请把小于等于 num 的数放在数组左边，大于 num 的数放在右边。要求额外空间复杂度 $O(1)$，时间复杂度 $O(N)$。 问题二，给定一个数组 arr， 和一个数 num，请把小于 num 的数放在数组左边，等于 num 的数放在数组的中间，大于 num 的数放在右边。要求额外空间复杂度 $O(1)$，时间复杂度 $O(N)$ 解决方案： 问题一，双指针：一个遍历数组，一个指向小于等于 num 的子序列右边 问题二，三指针：一个遍历数组，一个指向小于 num 的子序列右边，一个指向大于 num 子序列左边 引申快速排序： 问题一：快速排序 1.0，在问题一基础上做递归，最后一个数做 num，问题一完成后，把最后一个数换到大于 num 子序列前面，即一次递归排好一个数 问题二：快速排序 2.0，在问题二基础上做递归，最后一个数做 num，问题二完成后，把最后一个数换到大于 num 子序列前面，小于 num 子序列和大于 num 子序列指针中间的区域就有一批数排好了，即一次递归排好一批数 时间复杂度： 快速排序 1.0：$O(N ^ 2)$。最差情况：数组已经有序，每次只有左序列，没有右序列，遍历次数为：n -1 + n - 2 + n - 3 … = $O(N ^ 2)$ 快速排序 2.0：$O(N ^ 2)$。最差情况：数组已经有序，且不重复，每次只有左序列，没有右序列，遍历次数为：n -1 + n - 2 + n - 3 … = $O(N ^ 2)$ 快速排序 3.0： 由于划分值(1.0 和 2.0 都选当前总序列最后一个数)可能很偏，导致时间复杂度上升 如果划分值很打到中间位置，那么左右两个子问题的规模是一样的，由 master 公式 求解，时间复杂度将是 $O(NlogN)$ 快速排序 3.0：随机选一个数，放到最后作为划分值，时间复杂度变成概论事件，求所有情况的数学期望，得时间复杂度为 $O(NlogN)$ 时间复杂度 $O(NlogN)$，最差情况(每次都选到最差的那个)下 $O(N ^ 2)$ 空间复杂度：$O(logN)$(递归栈类似二叉树)，最差情况(每次都选到最差的那个)下 $O(N)$ 快速排序 3.0 代码： def quick_sort(arr: List[int]) -\u003e None: if not arr or len(arr) \u003c= 1: return process(arr, 0, len(arr) - 1) def process(arr: List[int], left: int, right: int) -\u003e None: if left \u003c right: random_ix = random.randint(left, right) arr[random_ix], arr[right] = arr[right], arr[random_ix] # 随机选一个数交换最后一个数，作为 partition 的基准 left_end, right_start = partition(arr, left, right) process(arr, left, left_end) process(arr, right_start, right) def partition(arr: List[int], left: int, right: int) -\u003e tuple[int, int]: lt_end_next = left # 左区域的右边一个位置 gt_start_prev = right - 1 # 右区域的左边一个位置 i = left while i \u003c= gt_start_prev: if arr[i] \u003c arr[right]: arr[lt_end_next], arr[i] = arr[i], arr[lt_end_next] lt_end_next += 1 i += 1 elif arr[i] \u003e arr[right]: arr[gt_start_prev], arr[i] = arr[i], arr[gt_start_prev] gt_start_prev -= 1 else: i += 1 arr[gt_start_prev + 1], arr[right] = arr[right], arr[gt_start_prev + 1] gt_start_prev += 1 return lt_end_next - 1, gt_start_prev + 1 算法题： 75. 颜色分类 ","date":"2022-08-14","objectID":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/:2:2","tags":["数据结构","算法","时间复杂度","空间复杂度","排序算法","位运算","二分查找","选择排序","冒泡排序","插入排序","归并排序","快速排序","堆排序","桶排序","荷兰国旗问题"],"title":"数据结构和算法学习笔记（一）排序算法","uri":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/"},{"categories":["学习笔记","数据结构和算法"],"content":"3. 堆排序和桶排序 ","date":"2022-08-14","objectID":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/:3:0","tags":["数据结构","算法","时间复杂度","空间复杂度","排序算法","位运算","二分查找","选择排序","冒泡排序","插入排序","归并排序","快速排序","堆排序","桶排序","荷兰国旗问题"],"title":"数据结构和算法学习笔记（一）排序算法","uri":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/"},{"categories":["学习笔记","数据结构和算法"],"content":"3.1 堆和堆排序 3.1.1 堆(Heap) 基本概念： 满二叉树：是一个绝对的三角形，也就是说它的最后一层全部是叶子节点 完全二叉树：他的最后一层可能不是完整的，但绝对是右方的连续部分缺失，左边一定是连续存在的 完全二叉树可由数组描述，数组中 i 位置节点的相关节点： 左子节点：2 * i + 1 右字节点：2 * i + 2 父节点：(i - 1) // 2 堆是一种特殊的完全二叉树，通常是一个可以被看做一棵完全二叉树的数组对象： 最大堆：父节点的值大于等于每一个子节点的值 最小堆：父节点的值小于等于每一个子节点的值 python 实现： from numbers import Real class MaxHeap: def __init__(self, datas: list[Real] | None = None): self._heap = [] # 维护堆的数组 self._heap_size = 0 # 堆的大小 if datas: self.build(datas) def insert(self, value: Real) -\u003e None: \"\"\" 插入 \"\"\" self._heap.append(value) self._heap_size += 1 self._shift_up(self._heap_size - 1) def pop(self) -\u003e Real | None: \"\"\" 返回并移除堆顶元素 \"\"\" if self.is_empty(): return None rtn = self._heap[0] self._heap[0] = self._heap[self._heap_size - 1] self._heap_size -= 1 self._shift_down(0) return rtn def remove(self, index: int) -\u003e Real: \"\"\" 返回并移除指定元素 \"\"\" if index \u003c 0 or index \u003e= self._heap_size: raise IndexError rtn = self._heap[index] self._heap[index] = self._heap[self._heap_size - 1] self._heap_size -= 1 modified = self._shift_up(index) if not modified: self._shift_down(index) return rtn def replace(self, value: Real, index: int = 0) -\u003e None: \"\"\" 返回并替换指定元素元素 \"\"\" if index \u003c 0 or index \u003e= self._heap_size: raise IndexError rtn = self._heap[index] self._heap[index] = value modified = self._shift_down(index) if not modified: self._shift_up(index) return rtn def is_empty(self) -\u003e bool: \"\"\" 检查是否为空 \"\"\" return self._heap_size == 0 def peek(self): \"\"\" 返回堆顶元素 \"\"\" if self.is_empty(): return None return self._heap[0] def all(self) -\u003e list[Real]: \"\"\" 返回所有元素 \"\"\" return self._heap[:self._heap_size] def build(self, datas: list[Real]): \"\"\" 由数组创建堆，覆盖当前的堆 \"\"\" self._heap = datas self._heap_size = len(datas) for i in range(self._heap_size - 1, -1, -1): self._shift_down(i) def _shift_up(self, index: int) -\u003e bool: \"\"\" 向上调整堆 时间复杂度：O(logN) :param index: :return: 是否修改了堆 \"\"\" if index \u003c 0 or index \u003e= self._heap_size: raise IndexError modified = False parent = max((index - 1) // 2, 0) while self._heap[index] \u003e self._heap[parent]: modified = True self._heap[index], self._heap[parent] = self._heap[parent], self._heap[index] index = parent parent = max((index - 1) // 2, 0) return modified def _shift_down(self, index: int) -\u003e bool: \"\"\" 向下调整堆 时间复杂度：O(logN) :param index: :return: 是否修改了堆 \"\"\" if index \u003c 0 or index \u003e= self._heap_size: raise IndexError modified = False left = index * 2 + 1 while left \u003c self._heap_size: if left + 1 \u003c self._heap_size and self._heap[left + 1] \u003e self._heap[left]: largest = left + 1 else: largest = left largest = largest if self._heap[largest] \u003e self._heap[index] else index if largest == index: break self._heap[largest], self._heap[index] = self._heap[index], self._heap[largest] modified = True index = largest left = index * 2 + 1 return modified 3.1.2 堆排序 python 实现： def heap_sort(arr: list[int]) -\u003e None: length = len(arr) if not arr or length \u003c= 1: return # for i in range(length): # shift_up(arr, i) for i in range(length - 1, -1, -1): # 这种方法会使建堆过程复杂度由 O(NlogN) 降为 O(N) shift_down(arr, i, length) for i in range(length - 1, 0, -1): arr[0], arr[i] = arr[i], arr[0] shift_down(arr, 0, i) def shift_down(arr: list[int], index: int, size: int) -\u003e None: left = index * 2 + 1 while left \u003c size: if left + 1 \u003c size and arr[left + 1] \u003e arr[left]: largest = left + 1 else: largest = left if arr[largest] \u003e arr[index]: arr[index], arr[largest] = arr[largest], arr[index] index = largest left = index * 2 + 1 else: break # def shift_up(arr: list[int], index: int) -\u003e None: # parent = max((index - 1) // 2, 0) # while arr[index] \u003e arr[parent]: # arr[parent], arr[index] = arr[index], arr[parent] # index = parent # parent = max((index - 1) // 2, 0) 时间复杂度：$O(NlogN)$ 空间复杂度：$O(1)$ 优先级队列结构就是堆结构 建堆的时候用 shift_up 时间复杂度为 $O(NlogN)$，而先把整个数组作为堆，再从最后位置开始 shift_up，时间复杂度可将为 $O(N)$(错位相减法求时间复杂度) 算法题： 已知一个几乎有序的数组，几乎有序是指，如果把数组排好顺序的话，每个元素移动的距离可以不超过k， 并且k相对于数组来说比较小。请选择一个合适的排序算法针对这个数据进行排序。 import heapq def solution(arr, k): length = len(arr) k = min(length, k) tmp = [] ans = [] i = 0 while i \u003c k: heapq.heappu","date":"2022-08-14","objectID":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/:3:1","tags":["数据结构","算法","时间复杂度","空间复杂度","排序算法","位运算","二分查找","选择排序","冒泡排序","插入排序","归并排序","快速排序","堆排序","桶排序","荷兰国旗问题"],"title":"数据结构和算法学习笔记（一）排序算法","uri":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/"},{"categories":["学习笔记","数据结构和算法"],"content":"3.2 桶排序 将数组分到有限数量的桶子里，每个桶子再分别别排序 桶排序不是比较排序： 计数排序：员工年龄排序，准备 201 长度的数组，按下标计数每个年龄员工的个数，在遍历桶恢复原数组 基数排序：一种非比较型整数排序算法，其原理是将整数按位数切割成不同的数字，然后按每个位数分别比较 基数排序，python 实现，仅适用于所有元素大于等于 0 的数组： def max_bits(arr: list[int]) -\u003e int: \"\"\" 获取数组中最大数的位数，如 max_bits([1,12,123,1234]) -\u003e 4 \"\"\" max_num = arr[0] for n in arr: if n \u003e max_num: max_num = n res = 0 while max_num != 0: max_num //= 10 res += 1 return res def process(arr: list[int], digit: int) -\u003e None: \"\"\" 做桶排序，只适用于元素大于等于 0 的数组 :param arr: :param digit: 列表中最大数字的长度 :return: \"\"\" radix = 10 # 根据基数，确定 count 列表长度 bucket = [0] * len(arr) # 桶，不做实际的很多个桶，以 count 列表记录偏移量，从右到左遍历 arr 即可完成如桶和出桶操作 for d in range(1, digit + 1): # 最大几位数，就做几次入桶出桶 count = [0] * radix # 初始化 count 列表 for n in arr: # 记录当前位上，个数字()的出现次数 nd = get_digit_num(n, d) count[nd] += 1 for i in range(1, radix): # 把出现次数，转化位偏移量，即小于等于 i 的有多少个 count[i] += count[i - 1] for i in range(len(arr) - 1, -1, -1): # 根据偏移量，把 arr 里的元素存入桶里，同时相当于做了出桶操作（由于桶是按照当前位的大小排序好的，小的在前面，大的在后面） nd = get_digit_num(arr[i], d) count[nd] -= 1 bucket[count[nd]] = arr[i] arr[:] = bucket # 桶覆盖原数组，相当于实际出桶 def get_digit_num(num: int, digit: int): \"\"\" 获取对应位上的值， 如 get_digit_num(456, 2) -\u003e 5 :param num: 原始数字 :param digit: 从右往左数第几位 :return: 对应位上的值，0 - 9 \"\"\" return (num // 10 ** (digit - 1)) % 10 ","date":"2022-08-14","objectID":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/:3:2","tags":["数据结构","算法","时间复杂度","空间复杂度","排序算法","位运算","二分查找","选择排序","冒泡排序","插入排序","归并排序","快速排序","堆排序","桶排序","荷兰国旗问题"],"title":"数据结构和算法学习笔记（一）排序算法","uri":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/"},{"categories":["学习笔记","数据结构和算法"],"content":"4. 排序算法总结 ","date":"2022-08-14","objectID":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/:4:0","tags":["数据结构","算法","时间复杂度","空间复杂度","排序算法","位运算","二分查找","选择排序","冒泡排序","插入排序","归并排序","快速排序","堆排序","桶排序","荷兰国旗问题"],"title":"数据结构和算法学习笔记（一）排序算法","uri":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/"},{"categories":["学习笔记","数据结构和算法"],"content":"4.1 排序算法的稳定性 稳定的： 冒泡排序：相等时不交换 插入排序：相等时不交换 归并排序：相等时先考虑左侧 桶排序：先入桶的先出桶，是稳定的 不稳定的： 选择排序：选择后，交换的时候破坏稳定性 快速排序：partition 交换的时候破坏稳定性 堆排序：很轻易就破坏稳定性，建堆的时候就破坏稳定性了 ","date":"2022-08-14","objectID":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/:4:1","tags":["数据结构","算法","时间复杂度","空间复杂度","排序算法","位运算","二分查找","选择排序","冒泡排序","插入排序","归并排序","快速排序","堆排序","桶排序","荷兰国旗问题"],"title":"数据结构和算法学习笔记（一）排序算法","uri":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/"},{"categories":["学习笔记","数据结构和算法"],"content":"4.2 总结 排序算法 时间复杂度 空间复杂度 稳定性 选择排序 $O(N ^ 2)$ O(1) F 冒泡排序 $O(N ^ 2)$ O(1) T 插入排序 $O(N ^ 2)$ O(1) T 归并排序 $O(NlogN)$ O(N) T 快速排序 $O(NlogN)$ O(logN) F 堆排序 $O(NlogN)$ O(1) F 归并排序是稳定的 归并排序和快速排序虽然都是 $O(NlogN)$，但通过实验，常数项更小从常数时间来讲快速排序更快，能用快排用快排 空间十分紧张用堆排序 基于比较的排序，时间复杂度不低于$O(NlogN)$ 时间复杂度 $O(NlogN)$ 的排序算法还要稳定，空间复杂度不低于 $O(N)$ 为了绝对的速度选快排、为了省空间选堆排、为了稳定性选归并 ","date":"2022-08-14","objectID":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/:4:2","tags":["数据结构","算法","时间复杂度","空间复杂度","排序算法","位运算","二分查找","选择排序","冒泡排序","插入排序","归并排序","快速排序","堆排序","桶排序","荷兰国旗问题"],"title":"数据结构和算法学习笔记（一）排序算法","uri":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/"},{"categories":["学习笔记","数据结构和算法"],"content":"4.3 常见的坑 归并排序的额外空间复杂度可以变成 $O(1)$，但非常难，感兴趣搜“归并排序内部缓存法” “原地归并排序”都是垃圾，会让归并的时间复杂度变成 $O(N ^2)$ 快速排序可以做到稳定性，但会让空间复杂度变为 $O(N)$，但非常难，搜“01 stable sort” 所有的改进都不重要，目前没有找到时间复杂度$O(NlogN)$，额外空间复杂度$O(1)$，又稳定的排序算法 有一道题目，奇数放在数组左边，偶数放在数组右边，还要求原始的相对次序不变，时间复杂度 $O(N)$，额外空间复杂度 $O(1)$，碰到这个问题，可以怼面试官 和快排类型，是一种 01 问题，和快排类似，如果 partition 能做到就可以，但 partition 交换会打乱次序 能做到，但很难，搜 “01 stable sort” ","date":"2022-08-14","objectID":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/:4:3","tags":["数据结构","算法","时间复杂度","空间复杂度","排序算法","位运算","二分查找","选择排序","冒泡排序","插入排序","归并排序","快速排序","堆排序","桶排序","荷兰国旗问题"],"title":"数据结构和算法学习笔记（一）排序算法","uri":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/"},{"categories":["学习笔记","数据结构和算法"],"content":"4.4 工程上对排序的改进 充分利用 $O(NlogN)$ 和 $O(N ^ 2)$ 各自的优势 如快排实际应用，在递归到小样本量时（如 length \u003c= 60），用插入排序，因为插入排序常数项小，且在数组几乎有序时效率高，这种情况下，比继续 partition 更有优势 稳定性考虑 ","date":"2022-08-14","objectID":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/:4:4","tags":["数据结构","算法","时间复杂度","空间复杂度","排序算法","位运算","二分查找","选择排序","冒泡排序","插入排序","归并排序","快速排序","堆排序","桶排序","荷兰国旗问题"],"title":"数据结构和算法学习笔记（一）排序算法","uri":"/posts/notes/datastructure_algorithm/zuochengyun/1-sort-algorithms/"},{"categories":["学习笔记","docker"],"content":"1. 网络基础知识 ","date":"2022-08-13","objectID":"/posts/notes/devops/docker/imooc/6-network/:1:0","tags":["docker","network"],"title":"Docker 学习笔记（六）网络","uri":"/posts/notes/devops/docker/imooc/6-network/"},{"categories":["学习笔记","docker"],"content":"1.1 URL URL：Uniform Resource Locator（统一资源定位符），网络中每一个资源对应的唯一地址 ","date":"2022-08-13","objectID":"/posts/notes/devops/docker/imooc/6-network/:1:1","tags":["docker","network"],"title":"Docker 学习笔记（六）网络","uri":"/posts/notes/devops/docker/imooc/6-network/"},{"categories":["学习笔记","docker"],"content":"1.2 IP 地址 IP地址是IP协议提供的一种统一的地址格式，它为互联网上的每一个网络和每一台主机分配一个逻辑地址，以此来屏蔽物理地址(MAC地址)。 是32位二进制数据，通常以十进制表示，并以“.”分隔。IP地址是一种逻辑地址，用来标识网络中一个个主机，在本地局域网上是惟一的。 ","date":"2022-08-13","objectID":"/posts/notes/devops/docker/imooc/6-network/:1:2","tags":["docker","network"],"title":"Docker 学习笔记（六）网络","uri":"/posts/notes/devops/docker/imooc/6-network/"},{"categories":["学习笔记","docker"],"content":"1.3 IP 协议 它是能使连接到网上的所有计算机网络实现相互通信的一套规则，规定了计算机在因特网上进行通信时应当遵守的规则。任何厂家生产的计算机系统，只要遵守IP协议就可以与因特网互连互通。 ","date":"2022-08-13","objectID":"/posts/notes/devops/docker/imooc/6-network/:1:3","tags":["docker","network"],"title":"Docker 学习笔记（六）网络","uri":"/posts/notes/devops/docker/imooc/6-network/"},{"categories":["学习笔记","docker"],"content":"1.4 子网掩码 互联网是由许多小型网络构成的，每个网络上都有许多主机，这样便构成了一个有层次的结构。IP地址在设计时就考虑到地址分配的层次特点，将每个IP地址都分割成网络号和主机号两部分，以便于IP地址的寻址操作。 如果不指定，就不知道哪些位是网络号、哪些是主机号，这就需要通过子网掩码来实现。 子网掩码只有一个作用，就是将某个IP地址划分成网络地址和主机地址两部分。 子网掩码的长度也是32位，左边是网络位，用二进制数字“1”表示；右边是主机位，用二进制数字“0”表示。 假设IP地址为“192.168.1.1”子网掩码为“255.255.255.0”。其中，“1”有24个，代表与此相对应的IP地址左边24位是网络号；“0”有8个，代表与此相对应的IP地址右边8位是主机号。 例如： 子网掩码是“255.255.255.0”的网络：最后面一个数字可以在0~255范围内任意变化，因此可以提供256个IP地址。但是实际可用的IP地址数量是256-2，即254个，因为主机号不能全是“0”或全是“1”(二进制角度)。 子网掩码是“255.255.0.0”的网络：后面两个数字可以在0~255范围内任意变化，可以提供255²个IP地址。但是实际可用的IP地址数量是255²-2，即65023个。 ip 地址后面加斜线 ‘'，斜线后面的数字表示子网掩码中 ‘1’ 的数量，如： xx.xx.xx.2/24： ip 地址为 xx.xx.xx.2，子网掩码为：255.255.255.0 xx.xx.xx.0/24：网段：xx.xx.xx.0，子网掩码：255.255.255.0 ","date":"2022-08-13","objectID":"/posts/notes/devops/docker/imooc/6-network/:1:4","tags":["docker","network"],"title":"Docker 学习笔记（六）网络","uri":"/posts/notes/devops/docker/imooc/6-network/"},{"categories":["学习笔记","docker"],"content":"1.5 网关 网关实质上是一个网络通向其他网络的IP地址。 比如有网络A和网络B，网络A的IP地址范围为“192.168.1.1~192.168.1.254”，子网掩码为255.255.255.0；网络B的IP地址范围为“192.168.2.1~192.168.2.254”，子网掩码为255.255.255.0。TCP/IP协议会根据子网掩码（255.255.255.0）判定两个网络中的主机处在不同的网络里。而要实现这两个网络之间的通信，则必须通过网关。 如果网络A中的主机发现数据包的目标主机不在本地网络中，就把数据包转发给它自己的网关，再由网关转发给网络B的网关，网络B的网关再转发给网络B的某个主机。 网关的IP地址是具有路由功能的设备的IP地址，具有路由功能的设备有路由器、启用了路由协议的服务器（实质上相当于一台路由器）、代理服务器（也相当于一台路由器）。 ","date":"2022-08-13","objectID":"/posts/notes/devops/docker/imooc/6-network/:1:5","tags":["docker","network"],"title":"Docker 学习笔记（六）网络","uri":"/posts/notes/devops/docker/imooc/6-network/"},{"categories":["学习笔记","docker"],"content":"1.6 DNS 服务器 域名与 IP 地址的转换工作成为域名解析，DNS就是进行域名解析的服务器 。 ","date":"2022-08-13","objectID":"/posts/notes/devops/docker/imooc/6-network/:1:6","tags":["docker","network"],"title":"Docker 学习笔记（六）网络","uri":"/posts/notes/devops/docker/imooc/6-network/"},{"categories":["学习笔记","docker"],"content":"2. 网络常用命令 IP 地址查看：ifconfig 或 ip addr 连通性测试： ping telnet \u003cip or domain\u003e \u003cport\u003e：测试端口的连通性 tracepath \u003cip or domain\u003e：路径探测跟踪 ","date":"2022-08-13","objectID":"/posts/notes/devops/docker/imooc/6-network/:2:0","tags":["docker","network"],"title":"Docker 学习笔记（六）网络","uri":"/posts/notes/devops/docker/imooc/6-network/"},{"categories":["学习笔记","docker"],"content":"3. Bridge 网络 默认创建的容器会连接到 docker0 linux bridge 上 访问外网时，会进行 NAT 转换，转换为宿主机的 IP 地址，对于外网服务，并不知道是由 docker 发出的，而是认为是宿主机发出的 NAT： NAT 主要为了解决 IPV4 地址数量不足的问题 IPV4 地址不足以使每个设备拥有一个 IP，因此有了 Public 和 Private 两种 IP 地址，我们的设备使用私有 IP，公网 IP 由网络提供商管理。 NAT就是，我们的设备出口流量时转为公网ip，收到返回后再转回私有ip 创建 Bridge 网络：docker network create -d bridge \u003cname\u003e 创建容器时指定 network：--network \u003cdocker-network-name\u003e 为容器[添加|移除]网络连接：docker network {connect|disconnect} \u003cdocker-network-name\u003e \u003ccontainer-ID-or-Name\u003e 在容器中访问其他容器时，可通过 ip，也可通过container name(通过 docker network 提供的 dns 功能实现)，默认的 bridge(ip addr: docker0，docker network ls：bridge) 不提供这个功能，只能通过 ip 访问，因此建议使用自己创建的 bridge NAT 反过来(公网-\u003e私网)不行，docker 外网无法直接容器内部，因此需要进行端口映射：-p \u003c宿主机port\u003e:\u003c容器port\u003e EXPOSE 指令：声明容器运行时提供服务的端口，这只是一个声明，在容器运行时并不会因为这个声明应用就会开启这个端口的服务。在运行时使用随机端口映射时，也就是 docker run -P 时，会自动随机映射 EXPOSE 的端口。 ","date":"2022-08-13","objectID":"/posts/notes/devops/docker/imooc/6-network/:3:0","tags":["docker","network"],"title":"Docker 学习笔记（六）网络","uri":"/posts/notes/devops/docker/imooc/6-network/"},{"categories":["学习笔记","docker"],"content":"4. Host 网络 容器和宿主机使用同一个网络 docker network ls 可以查到一个 name 为 host 的网络，创建容器时使用 --network host 来使用 host 网络 docker network ls 还可以看到一个 name 为 none 的网络，意为 docker 仅创建容器，不要管网络了，由我们自己处理 走 Bridge 会有 NAT 的性能损耗，使用 Host 理论上性能更好 ","date":"2022-08-13","objectID":"/posts/notes/devops/docker/imooc/6-network/:4:0","tags":["docker","network"],"title":"Docker 学习笔记（六）网络","uri":"/posts/notes/devops/docker/imooc/6-network/"},{"categories":["学习笔记","docker"],"content":"5. 网络命名空间 Linux的Namespace（命名空间）技术是一种隔离技术，常用的Namespace有 user namespace, process namespace, network namespace等 在Docker容器中，不同的容器通过Network namespace进行了隔离，也就是不同的容器有各自的IP地址，路由表等，互不影响。 ","date":"2022-08-13","objectID":"/posts/notes/devops/docker/imooc/6-network/:5:0","tags":["docker","network"],"title":"Docker 学习笔记（六）网络","uri":"/posts/notes/devops/docker/imooc/6-network/"},{"categories":["学习笔记","docker"],"content":"1. Docker 命令行基本操作 docker + 管理的对象（比如容器，镜像） + 具体操作（比如创建，启动，停止，删除） docker image pull nginx： 拉取一个叫nginx的docker image镜像 docker container stop web： 停止一个叫web的docker container容器 ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/2-container-basic/:1:0","tags":["docker","容器"],"title":"Docker 学习笔记（二）容器快速上手","uri":"/posts/notes/devops/docker/imooc/2-container-basic/"},{"categories":["学习笔记","docker"],"content":"2. Image vs Container image 镜像 Docker image是一个 read-only 文件 这个文件包含文件系统，源码，库文件，依赖，工具等一些运行application所需要的文件 可以理解成一个模板 docker image具有分层的概念 container 容器 “一个运行中的docker image” 实质是复制image并在image最上层加上一层 read-write 的层 （称之为 container layer ,容器层） 基于同一个image可以创建多个container ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/2-container-basic/:2:0","tags":["docker","容器"],"title":"Docker 学习笔记（二）容器快速上手","uri":"/posts/notes/devops/docker/imooc/2-container-basic/"},{"categories":["学习笔记","docker"],"content":"3. 容器的基本操作 操作 命令(全)(新版本) 命令(简)(旧版本) 容器的创建 docker container run docker run 容器的列出(up) docker container ls docker ps 容器的列出(up和exit) docker container ls -a docker ps -a 容器的停止 docker container stop docker stop 容器的删除(不能删除运行中的容器，除非添加参数 -f) docker container rm docker rm ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/2-container-basic/:3:0","tags":["docker","容器"],"title":"Docker 学习笔记（二）容器快速上手","uri":"/posts/notes/devops/docker/imooc/2-container-basic/"},{"categories":["学习笔记","docker"],"content":"4. 批量操作 docker container stop cd3 269 34b 751：输入多个 id docker container stop $(docker container ps -aq)：$ 符号传递 stdout(-q 只显示 id) docker system prune -af： 快速对系统进行清理，删除停止的容器，不用的image，等等 ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/2-container-basic/:4:0","tags":["docker","容器"],"title":"Docker 学习笔记（二）容器快速上手","uri":"/posts/notes/devops/docker/imooc/2-container-basic/"},{"categories":["学习笔记","docker"],"content":"5. 容器的 attached 和 detached 模式 attached 模式在前台运行 detached 模式在后台运行，docker container run -d xxx 开启 detached 模式转 attached：docker attach \u003cID or Name\u003e detached 模式查看日志：docker container logs [-f] \u003cID or Name\u003e(-f：动态跟踪打印) ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/2-container-basic/:5:0","tags":["docker","容器"],"title":"Docker 学习笔记（二）容器快速上手","uri":"/posts/notes/devops/docker/imooc/2-container-basic/"},{"categories":["学习笔记","docker"],"content":"6. 连接容器的 shell docker container run -it \u003cID or Name\u003e [sh | bash ...] 创建一个容器并进入交互式模式 docker container exec -it \u003cID or Name\u003e [sh | bash ...] 在一个已经运行的容器里执行一个额外的command ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/2-container-basic/:6:0","tags":["docker","容器"],"title":"Docker 学习笔记（二）容器快速上手","uri":"/posts/notes/devops/docker/imooc/2-container-basic/"},{"categories":["学习笔记","docker"],"content":"7. 容器 vs 虚拟机 容器不是虚拟机： 容器其实是进程Containers are just processes 容器中的进程被限制了对CPU内存等资源的访问 当进程停止后，容器就退出了 ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/2-container-basic/:7:0","tags":["docker","容器"],"title":"Docker 学习笔记（二）容器快速上手","uri":"/posts/notes/devops/docker/imooc/2-container-basic/"},{"categories":["学习笔记","docker"],"content":"8. docker container run 背后发生了什么？ $ docker container run -d --publish 80:80 --name webhost nginx: 在本地查找是否有nginx这个image镜像，但是没有发现 去远程的image registry查找nginx镜像（默认的registry是Docker Hub) 下载最新版本的nginx镜像 （nginx:latest 默认) 基于nginx镜像来创建一个新的容器，并且准备运行 docker engine分配给这个容器一个虚拟IP地址 在宿主机上打开80端口并把容器的80端口转发到宿主机上 启动容器，运行指定的命令（这里是一个shell脚本去启动nginx） ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/2-container-basic/:8:0","tags":["docker","容器"],"title":"Docker 学习笔记（二）容器快速上手","uri":"/posts/notes/devops/docker/imooc/2-container-basic/"},{"categories":["学习笔记","docker"],"content":"1. 镜像的获取 三种方式： pull from registry (online) 从registry拉取 public（公有） private（私有） build from Dockerfile (online) 从Dockerfile构建 load from file (offline) 文件导入 （离线） ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/3-image/:1:0","tags":["docker","镜像"],"title":"Docker 学习笔记（三）镜像的创建管理和发布","uri":"/posts/notes/devops/docker/imooc/3-image/"},{"categories":["学习笔记","docker"],"content":"2. Registry DockerHub Quay ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/3-image/:2:0","tags":["docker","镜像"],"title":"Docker 学习笔记（三）镜像的创建管理和发布","uri":"/posts/notes/devops/docker/imooc/3-image/"},{"categories":["学习笔记","docker"],"content":"3. 镜像的基本操作 拉取镜像：docker image pull name[:tag]，docker image pull quay.io/bitnami/nginx 查看镜像：docker image ls 镜像详情：docker image inspect \u003cID or Name\u003e 删除镜像：docker image rm \u003cID or Name\u003e ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/3-image/:3:0","tags":["docker","镜像"],"title":"Docker 学习笔记（三）镜像的创建管理和发布","uri":"/posts/notes/devops/docker/imooc/3-image/"},{"categories":["学习笔记","docker"],"content":"4. 镜像的导出和导入 (offline) 导出：docker image save \u003cID or Name\u003e -o \u003cpath_to_file\u003e 导入：docker image load -i \u003cpath_to_file\u003e ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/3-image/:4:0","tags":["docker","镜像"],"title":"Docker 学习笔记（三）镜像的创建管理和发布","uri":"/posts/notes/devops/docker/imooc/3-image/"},{"categories":["学习笔记","docker"],"content":"5. Dockerfile 介绍 Dockerfile 基本结构： FROM ubuntu:20.04 RUN apt-get update \u0026\u0026 \\ DEBIAN_FRONTEND=noninteractive apt-get install --no-install-recommends -y python3.9 python3-pip python3.9-dev ADD hello.py / CMD [\"python3\", \"/hello.py\"] FROM：基础镜像 RUN：执行命令 ADD：添加文件 CMD：启动容器执行的命令 ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/3-image/:5:0","tags":["docker","镜像"],"title":"Docker 学习笔记（三）镜像的创建管理和发布","uri":"/posts/notes/devops/docker/imooc/3-image/"},{"categories":["学习笔记","docker"],"content":"6. 镜像的构建和分享 构建：docker image build -t \u003cname\u003e[:tag] \u003cpath_to_dockerfile\u003e 通过存在的 image 添加 tag：docker image tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG] 登录：docker login push：docker image push \u003cName\u003e[:tag](要把 image name 构建成 docker-hub-account-name/image-name[:tag] 才能 push 到自己的仓库) ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/3-image/:6:0","tags":["docker","镜像"],"title":"Docker 学习笔记（三）镜像的创建管理和发布","uri":"/posts/notes/devops/docker/imooc/3-image/"},{"categories":["学习笔记","docker"],"content":"7. 通过 commit 创建镜像 对容器的操作会保存到容器中，可以通过 docker container commit CONTAINER [REPOSITORY[:TAG]] 来创建镜像，相当于保存当前容器 ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/3-image/:7:0","tags":["docker","镜像"],"title":"Docker 学习笔记（三）镜像的创建管理和发布","uri":"/posts/notes/devops/docker/imooc/3-image/"},{"categories":["学习笔记","docker"],"content":"8. scratch 镜像 查看镜像分层：docker image history \u003cimage\u003e ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/3-image/:8:0","tags":["docker","镜像"],"title":"Docker 学习笔记（三）镜像的创建管理和发布","uri":"/posts/notes/devops/docker/imooc/3-image/"},{"categories":["学习笔记","docker"],"content":"1. 镜像的选择(FROM) 官方镜像优于非官方的镜像，如果没有官方镜像，则尽量选择Dockerfile开源的 固定版本tag而不是每次都使用latest 尽量选择体积小的镜像(-alpine) ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/4-dockerfile/:1:0","tags":["docker","dockerfile"],"title":"Docker 学习笔记（四）Dockerfile","uri":"/posts/notes/devops/docker/imooc/4-dockerfile/"},{"categories":["学习笔记","docker"],"content":"2. 通过 RUN 执行指令 RUN 主要用于在Image里执行指令，比如安装软件，下载文件等 不要写多个 RUN，每一行的 RUN 命令都会产生一层 image layer , 导致镜像的臃肿，应该通过 \u0026\u0026 拼接多个指令 ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/4-dockerfile/:2:0","tags":["docker","dockerfile"],"title":"Docker 学习笔记（四）Dockerfile","uri":"/posts/notes/devops/docker/imooc/4-dockerfile/"},{"categories":["学习笔记","docker"],"content":"3. 文件复制和目录操作 ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/4-dockerfile/:3:0","tags":["docker","dockerfile"],"title":"Docker 学习笔记（四）Dockerfile","uri":"/posts/notes/devops/docker/imooc/4-dockerfile/"},{"categories":["学习笔记","docker"],"content":"3.1 COPY vs ADD COPY 和 ADD 都能复制，如果目标目录不存在会自动创建，权限也会复制过去 ADD 复制压缩文件时会自动解压 选择：所有的文件复制均使用 COPY 指令，仅在需要自动解压缩的场合使用 ADD ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/4-dockerfile/:3:1","tags":["docker","dockerfile"],"title":"Docker 学习笔记（四）Dockerfile","uri":"/posts/notes/devops/docker/imooc/4-dockerfile/"},{"categories":["学习笔记","docker"],"content":"3.2 WORKDIR WORKDIR：切换工作目录，类似 cd 命令，如果目录不存在则自动创建 ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/4-dockerfile/:3:2","tags":["docker","dockerfile"],"title":"Docker 学习笔记（四）Dockerfile","uri":"/posts/notes/devops/docker/imooc/4-dockerfile/"},{"categories":["学习笔记","docker"],"content":"4. 构建参数和环境变量(ARG vs ENV) 语法：{ENV|ARG} KEY=VALUE ARG 和 ENV 是经常容易被混淆的两个Dockerfile的语法，都可以用来设置一个“变量”。在 Dockerfile 中通过 ${KEY} 引用。 区别： ARG：参数，可以在镜像build的时候动态修改value, 通过 --build-arg ENV：环境变量，设置的变量可以在Image中保持，并在容器中的环境变量里 ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/4-dockerfile/:4:0","tags":["docker","dockerfile"],"title":"Docker 学习笔记（四）Dockerfile","uri":"/posts/notes/devops/docker/imooc/4-dockerfile/"},{"categories":["学习笔记","docker"],"content":"5. 容器启动命令 ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/4-dockerfile/:5:0","tags":["docker","dockerfile"],"title":"Docker 学习笔记（四）Dockerfile","uri":"/posts/notes/devops/docker/imooc/4-dockerfile/"},{"categories":["学习笔记","docker"],"content":"5.1 CMD 容器启动时默认执行的命令 如果docker container run启动容器时指定了其它命令，则CMD命令会被忽略 如果定义了多个CMD，只有最后一个会被执行。 CMD [] 会覆盖掉之前的 CMD docker container run --rm：退出后自动删除 container ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/4-dockerfile/:5:1","tags":["docker","dockerfile"],"title":"Docker 学习笔记（四）Dockerfile","uri":"/posts/notes/devops/docker/imooc/4-dockerfile/"},{"categories":["学习笔记","docker"],"content":"5.2 ENTRYPOINT ENTRYPOINT 也可以设置容器启动时要执行的命令，但是和CMD是有区别的: CMD 设置的命令，可以在docker container run 时传入其它命令，覆盖掉 CMD 的命令，但是 ENTRYPOINT 所设置的命令是一定会被执行的，docker container run 传入的命令和参数会全部作为参数传入 ENTRYPOINT 指定的命令 ENTRYPOINT 和 CMD 可以联合使用，ENTRYPOINT 设置执行的命令，CMD传递参数 ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/4-dockerfile/:5:2","tags":["docker","dockerfile"],"title":"Docker 学习笔记（四）Dockerfile","uri":"/posts/notes/devops/docker/imooc/4-dockerfile/"},{"categories":["学习笔记","docker"],"content":"5.3 Shell 格式和 Exec 格式 Shell 格式：CMD echo \"hello docker\" Exec 格式：CMD [\"echo\", \"hello docker\"] ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/4-dockerfile/:5:3","tags":["docker","dockerfile"],"title":"Docker 学习笔记（四）Dockerfile","uri":"/posts/notes/devops/docker/imooc/4-dockerfile/"},{"categories":["学习笔记","docker"],"content":"6. Dockerfile 最佳实践 ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/4-dockerfile/:6:0","tags":["docker","dockerfile"],"title":"Docker 学习笔记（四）Dockerfile","uri":"/posts/notes/devops/docker/imooc/4-dockerfile/"},{"categories":["学习笔记","docker"],"content":"6.1 合理使用缓存 某一层发生变化(包括 COPY 的文件内容的变化)，之后的所有层都不会使用缓存。因此经常改变的层要尽量放到后面 ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/4-dockerfile/:6:1","tags":["docker","dockerfile"],"title":"Docker 学习笔记（四）Dockerfile","uri":"/posts/notes/devops/docker/imooc/4-dockerfile/"},{"categories":["学习笔记","docker"],"content":"6.2 合理使用 .dockerignore 6.2.1 Docker build context Docker是client-server架构，理论上Client和Server可以不在一台机器上 在构建docker镜像的时候，需要把所需要的文件由CLI（client）发给Server，这些文件实际上就是build context docker image build . 里面的 . 表示当前目录为 build context 6.2.2 .dockerignore 使用 .dockerignore 忽略无关的文件，可减少 build context 的大小 ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/4-dockerfile/:6:2","tags":["docker","dockerfile"],"title":"Docker 学习笔记（四）Dockerfile","uri":"/posts/notes/devops/docker/imooc/4-dockerfile/"},{"categories":["学习笔记","docker"],"content":"6.3 多阶段构建 多阶段构建：在同一个 Dockerfile 中写多个构建步骤，可以使编译环境和运行环境分离，减少 image 大小 关键语法： 在前置步骤中以 FROM xxx AS \u003cname\u003e 的形式，给当前构建步骤命名 在后续步骤中以 --from=\u003cname\u003e，从前置步骤中引用文件 如： FROM gcc:9.4 AS builder COPY hello.c /src/hello.c WORKDIR /src RUN gcc --static -o hello hello.c FROM alpine:3.13.5 COPY --from=builder /src/hello /src/hello ENTRYPOINT [ \"/src/hello\" ] CMD [] ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/4-dockerfile/:6:3","tags":["docker","dockerfile"],"title":"Docker 学习笔记（四）Dockerfile","uri":"/posts/notes/devops/docker/imooc/4-dockerfile/"},{"categories":["学习笔记","docker"],"content":"6.4 尽量不要用 root 用户 6.4.1 docker root 用户的危险性 docker的root权限一直是其遭受诟病的地方，docker的root权限有那么危险 如： 我们有一个用户，叫demo，它本身不具有sudo的权限，所以就有很多文件无法进行读写操作，比如/root目录它是无法查看的 但是这个用户有执行docker的权限，也就是它在docker这个group里 我们就可以通过Docker做很多越权的事情了，比如，我们可以把这个无法查看的/root目录映射到docker container里，你就可以自由进行查看了 更甚至我们可以给我们自己加sudo权限，docker run -it -v /etc/sudoers:/root/sudoers busybox sh 6.4.2 使用非 root 用户(USER) USER test 使用 USER 指令指定用户 USER 指令和 WORKDIR 相似，都是改变环境状态并影响以后的层，USER 则是改变之后层的执行 RUN, CMD 以及 ENTRYPOINT 这类命令的身份 USER 只是帮助你切换到指定用户而已，这个用户必须是事先建立好的，否则无法切换：RUN groupadd -r \u003cgroup-name\u003e \u0026\u0026 useradd -r -g \u003cgroup-name\u003e \u003cuser-name\u003e ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/4-dockerfile/:6:4","tags":["docker","dockerfile"],"title":"Docker 学习笔记（四）Dockerfile","uri":"/posts/notes/devops/docker/imooc/4-dockerfile/"},{"categories":["学习笔记","docker"],"content":"Docker主要提供了两种方式做数据的持久化 Data Volume, 由Docker管理，(/var/lib/docker/volumes/), 持久化数据的最好方式 Bind Mount，由用户指定存储的数据具体mount在系统什么位置 ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/5-volume/:0:0","tags":["docker","volume"],"title":"Docker 学习笔记（五）存储","uri":"/posts/notes/devops/docker/imooc/5-volume/"},{"categories":["学习笔记","docker"],"content":"1. Data Volume 仅在 Dockerfile 中定义 VOLUME ['path'] 时，Docker会自动创建一个随机名字的volume，去存储我们在Dockerfile定义的volume docker container run -d -v \u003cvolumn_name\u003e:\u003cdir_in_container\u003e my-cron：启动容器时指定 volume，可以指向容器内任意路径 Volume 相关命令：docker volume [ls|inspect|rm|prune...] ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/5-volume/:1:0","tags":["docker","volume"],"title":"Docker 学习笔记（五）存储","uri":"/posts/notes/devops/docker/imooc/5-volume/"},{"categories":["学习笔记","docker"],"content":"2. Bind Mount 如果使用 -v 或 -volume 来绑定挂载 Docker 主机上还不存在的文件或目录，则 -v 将为您创建它。它总是作为目录创建的。 如果使用 --mount 绑定挂载 Docker 主机上还不存在的文件或目录，Docker 不会自动为您创建它，而是产生一个错误。 --mount：由多个键-值对组成，以逗号分隔，每个键-值对由一个 = 元组组成。--mount 语法比 -v 或 --volume 更冗长，但是键的顺序并不重要，标记的值也更容易理解。 挂载的类型（type），可以是 bind、volume 或者 tmpfs。 挂载的源（source），对于绑定挂载，这是 Docker 守护进程主机上的文件或目录的路径。可以用 source 或者 src 来指定。 目标（destination），将容器中文件或目录挂载的路径作为其值。可以用 destination、dst 或者 target 来指定。 readonly 选项（如果存在），则会将绑定挂载以只读形式挂载到容器中。 bind-propagation 选项（如果存在），则更改绑定传播。 可能的值是 rprivate、 private、 rshared、 shared、 rslave 或 slave 之一。 ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/5-volume/:2:0","tags":["docker","volume"],"title":"Docker 学习笔记（五）存储","uri":"/posts/notes/devops/docker/imooc/5-volume/"},{"categories":["学习笔记","docker"],"content":"3. 使用 docker 做开发环境 bind 项目路径到 docker container，然后可以在 container 中做操作 设置 pycharm 的 interpreter 为 docker，然后可以运行 celery 等在 linux 中才能跑的库 ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/5-volume/:3:0","tags":["docker","volume"],"title":"Docker 学习笔记（五）存储","uri":"/posts/notes/devops/docker/imooc/5-volume/"},{"categories":["学习笔记","docker"],"content":"4. 多个机器的容器共享数据 Docker的volume支持多种driver。默认创建的volume driver都是local sshfs的driver，如何让docker使用不在同一台机器上的文件系统做volume 安装 plugin: docker plugin install --grant-all-permissions vieux/sshfs 创建 volume，该 volume 实际上 ssh 远程机器上的文件系统： docker volume create --driver vieux/sshfs \\ -o sshcmd=vagrant@192.168.200.12:/home/vagrant \\ -o password=vagrant \\ sshvolume ","date":"2022-08-12","objectID":"/posts/notes/devops/docker/imooc/5-volume/:4:0","tags":["docker","volume"],"title":"Docker 学习笔记（五）存储","uri":"/posts/notes/devops/docker/imooc/5-volume/"},{"categories":["学习笔记","python"],"content":"1. 事件循环 并发编程3要素：事件循环 + 回调（协程中为驱动生成器） + IO 多路复用 asyncio 是 python 用于解决异步 IO 编程的一整套解决方案 python 的异步编程框架：tornado、gevent、twisted(scrapy、django channels) 同步阻塞的函数不要放在协程里，否则在 loop 中会阻塞 loop.create_task() 等于 asyncio.ensure_future()，返回 Task 对象，可用于获取协程返回值，在已运行的 loop 中还可以使用 asyncio.create_task() Task 对象上可设置回调 task.add_done_callback(callback_func)，其中 callback_func 有一个 future 参数 def callback_func(future)，或使用 functools.partial 来传递更多参数 python 3.10 中 asyncio.get_event_loop() warning deprecated，使用 asyncio.new_event_loop() 或 asyncio.get_running_loop() 代替 wait vs gather：gather 更加 high-level；gather 返回一个 Future 对象，可用于分组，可以 cancle() ","date":"2022-08-11","objectID":"/posts/notes/languages/python/imooc/13-asyncio/:1:0","tags":["python","python3","asyncio"],"title":"Python 高级编程（十三）asyncio","uri":"/posts/notes/languages/python/imooc/13-asyncio/"},{"categories":["学习笔记","python"],"content":"2. task 取消和子协程调用原理 loop 会被放到 future 中（因此可以在 future 中stop loop，这也是 loop.run_until_complete() 的实现方式：给 future 加上 done_callback，然后 loop.run_forever()），future 也会被放到 loop 中 子协程调用原理：18.5.3.1.3. Example: Chain coroutines ","date":"2022-08-11","objectID":"/posts/notes/languages/python/imooc/13-asyncio/:2:0","tags":["python","python3","asyncio"],"title":"Python 高级编程（十三）asyncio","uri":"/posts/notes/languages/python/imooc/13-asyncio/"},{"categories":["学习笔记","python"],"content":"3. loop 的 call_soon、call_at、call_later、call_soon_threadsafe loop.call_soon()：安排在下一次事件循环的迭代中调用 callback loop.call_later()：安排 callback 在给定的 delay 秒（可以是 int 或者 float）后被调用。 loop.call_at()：安排 callback 在给定的绝对时间戳的 时间 （一个 int 或者 float）被调用，使用与 loop.time() 同样的时间参考。 loop.call_soon_threadsafe()：asyncio 可以在多线程下运行，是一个异步io解决方案(协程、线程、进程)，不光是解决协程问题 ","date":"2022-08-11","objectID":"/posts/notes/languages/python/imooc/13-asyncio/:3:0","tags":["python","python3","asyncio"],"title":"Python 高级编程（十三）asyncio","uri":"/posts/notes/languages/python/imooc/13-asyncio/"},{"categories":["学习笔记","python"],"content":"4. ThreadPoolExecutor + asyncio 协程中是不能有阻塞 IO的，但如果非得在协程中集成阻塞 IO，那么可以用多线程解决 loop = asyncio.get_event_loop() executor = concurrent.futures.ThreadPoolExecutor(1) tasks = [] for i in range(20): url = 'http://baidu.com' task = loop.run_in_executor(executor, get_url, url) # 返回 future 对象 tasks.append(task) loop.run_until_complete(asyncio.wait(tasks)) ","date":"2022-08-11","objectID":"/posts/notes/languages/python/imooc/13-asyncio/:4:0","tags":["python","python3","asyncio"],"title":"Python 高级编程（十三）asyncio","uri":"/posts/notes/languages/python/imooc/13-asyncio/"},{"categories":["学习笔记","python"],"content":"4. asyncio 模拟 http 请求 async def get_url(url): url = urllib.parse.urlparse(url) host = url.netloc path = url.path if url.path != '' else '/' reader, writer = await asyncio.open_connection(host, 80) writer.write('GET {} HTTP/1.1\\r\\nHost:{}\\r\\nConnection:Close\\r\\n\\r\\n'.format(path, host).encode('utf8')) all_lines = [] async for raw_line in reader: # StreamReader 实现了 async def __anext__()，因此可以用 async for line = raw_line.decode() all_lines.append(line) html = '\\n'.join(all_lines) return html async def main(): tasks = [] for i in range(20): tasks.append(asyncio.ensure_future(get_url('http://baidu.com'))) for task in asyncio.as_completed(tasks): # 获取结果 result = await task print(result) if __name__ == '__main__': start = time.time() loop = asyncio.new_event_loop() loop.run_until_complete(main()) print(time.time() - start) ","date":"2022-08-11","objectID":"/posts/notes/languages/python/imooc/13-asyncio/:5:0","tags":["python","python3","asyncio"],"title":"Python 高级编程（十三）asyncio","uri":"/posts/notes/languages/python/imooc/13-asyncio/"},{"categories":["学习笔记","python"],"content":"6. future 和 task future 是一个结果容器 task 是 future 的子类，是协程和 future 之间的桥梁，为了 asyncio 和线程池、进程池接口一致 ","date":"2022-08-11","objectID":"/posts/notes/languages/python/imooc/13-asyncio/:6:0","tags":["python","python3","asyncio"],"title":"Python 高级编程（十三）asyncio","uri":"/posts/notes/languages/python/imooc/13-asyncio/"},{"categories":["学习笔记","python"],"content":"7. asyncio 的同步和通信 asyncio.Lock() asyncio.Queue() ","date":"2022-08-11","objectID":"/posts/notes/languages/python/imooc/13-asyncio/:7:0","tags":["python","python3","asyncio"],"title":"Python 高级编程（十三）asyncio","uri":"/posts/notes/languages/python/imooc/13-asyncio/"},{"categories":["学习笔记","python"],"content":"1. 并发、并行、同步、异步、阻塞、非阻塞 并发：一个时间段内在同一个 cpu 上有多个程序在运行，但任意时刻只有一个程序在运行 并行：任意时刻多个程序同时运行在多个 cpu 上 同步：代码调用 IO 操作时，必须等待 IO 操作完成才返回 异步：代码调用 IO 操作时，不必等待 IO 操作完成才返回 阻塞：调用函数时，当前线程被挂起 非阻塞：调用函数时，单曲线程不会被挂起，而是立即返回 ","date":"2022-08-10","objectID":"/posts/notes/languages/python/imooc/12-coroutine/:1:0","tags":["python","python3","协程"],"title":"Python 高级编程（十二）协程","uri":"/posts/notes/languages/python/imooc/12-coroutine/"},{"categories":["学习笔记","python"],"content":"2. C10K 问题和 IO 多路复用 ","date":"2022-08-10","objectID":"/posts/notes/languages/python/imooc/12-coroutine/:2:0","tags":["python","python3","协程"],"title":"Python 高级编程（十二）协程","uri":"/posts/notes/languages/python/imooc/12-coroutine/"},{"categories":["学习笔记","python"],"content":"2.1 C10K问题 很难用线程解决，很难开启 10K 个线程 ","date":"2022-08-10","objectID":"/posts/notes/languages/python/imooc/12-coroutine/:2:1","tags":["python","python3","协程"],"title":"Python 高级编程（十二）协程","uri":"/posts/notes/languages/python/imooc/12-coroutine/"},{"categories":["学习笔记","python"],"content":"2.2 Linux 五种 IO 模型 Linux IO 模型 ","date":"2022-08-10","objectID":"/posts/notes/languages/python/imooc/12-coroutine/:2:2","tags":["python","python3","协程"],"title":"Python 高级编程（十二）协程","uri":"/posts/notes/languages/python/imooc/12-coroutine/"},{"categories":["学习笔记","python"],"content":"2.3 select + 回调 + 事件循环模拟 http 请求 import selectors import socket import time import urllib.parse selector = selectors.DefaultSelector() # 根据不同平台自动选择最好的 io 多路复用方式 urls = ['http://www.baidu.com'] * 20 stop = False class Fetcher: def __init__(self): self.host = None self.path = None self.client = None self.cur_url = None self.data = b'' def get_url(self, url): self.cur_url = url url = urllib.parse.urlparse(url) self.host = url.netloc self.path = url.path if url.path != '' else '/' # 建立 socket 连接 self.client = socket.socket(socket.AF_INET, socket.SOCK_STREAM) self.client.setblocking(False) try: self.client.connect((self.host, 80)) except BlockingIOError as e: pass # 把 socket 注册到 selector 上 selector.register(self.client.fileno(), selectors.EVENT_WRITE, self.connected) # 回调模式，当这个 socket 上可写时，调用 def connected(self, key): selector.unregister(key.fd) self.client.send( 'GET {} HTTP/1.1\\r\\nHost:{}\\r\\nConnection:Close\\r\\n\\r\\n'.format(self.path, self.host).encode('utf8')) selector.register(self.client.fileno(), selectors.EVENT_READ, self.readable) def readable(self, key): # 准备好一段读一段，该函数可能有多次 EVENT_READ 多次被调用 d = self.client.recv(1024) if d: self.data += d else: selector.unregister(key.fd) data = self.data.decode('utf8') html = data.split('\\r\\n\\r\\n')[1] print(html) self.client.close() urls.remove(self.cur_url) if not urls: global stop stop = True def loop(): # 事件循环，不停的请求 socket 的状态，并调用对应的回调函数 # twisted、gevent、asyncio 本质上来讲都是这种模式：回调 + 事件循环 + select\\poll\\epoll # 1. select 本身不支持 register 模式(回调)的 # 2. socket 状态变化以后的回调是由我们的程序完成的 while not stop: ready = selector.select() for key, mask in ready: call_back = key.data call_back(key) def get_url(url): url = urllib.parse.urlparse(url) host = url.netloc path = url.path if url.path != '' else '/' client = socket.socket(socket.AF_INET, socket.SOCK_STREAM) client.setblocking(False) try: client.connect((url.netloc, 80)) except BlockingIOError as e: pass while True: try: client.send('GET {} HTTP/1.1\\r\\nHost:{}\\r\\nConnection:Close\\r\\n\\r\\n'.format(path, host).encode('utf8')) except OSError as e: pass else: break data = b'' while True: try: d = client.recv(1024) except BlockingIOError as e: continue if d: data += d else: break data = data.decode('utf8') html = data.split('\\r\\n\\r\\n')[1] print(html) client.close() if __name__ == '__main__': # 异步 start = time.time() for url in urls: fetcher = Fetcher() fetcher.get_url(url) loop() print('select:', time.time() - start) # 同步 urls = ['http://www.baidu.com'] * 20 start = time.time() for url in urls: get_url(url) print('for :', time.time() - start) ","date":"2022-08-10","objectID":"/posts/notes/languages/python/imooc/12-coroutine/:2:3","tags":["python","python3","协程"],"title":"Python 高级编程（十二）协程","uri":"/posts/notes/languages/python/imooc/12-coroutine/"},{"categories":["学习笔记","python"],"content":"2.4 回调之痛 问题： 异常不由主函数捕获，需要在 loop 中处理，难以处理 嵌套回调，层数多了难以理解和维护，如果某一层出异常，难以处理 变量在回调间共享难以维护 总结： 可读性差 共享状态管理困难 异常处理困难 ","date":"2022-08-10","objectID":"/posts/notes/languages/python/imooc/12-coroutine/:2:4","tags":["python","python3","协程"],"title":"Python 高级编程（十二）协程","uri":"/posts/notes/languages/python/imooc/12-coroutine/"},{"categories":["学习笔记","python"],"content":"3. 协程 ","date":"2022-08-10","objectID":"/posts/notes/languages/python/imooc/12-coroutine/:3:0","tags":["python","python3","协程"],"title":"Python 高级编程（十二）协程","uri":"/posts/notes/languages/python/imooc/12-coroutine/"},{"categories":["学习笔记","python"],"content":"3.1 C10M 问题 随互联网发展，C10K 都不够用了 ","date":"2022-08-10","objectID":"/posts/notes/languages/python/imooc/12-coroutine/:3:1","tags":["python","python3","协程"],"title":"Python 高级编程（十二）协程","uri":"/posts/notes/languages/python/imooc/12-coroutine/"},{"categories":["学习笔记","python"],"content":"3.2 协程 要实现线程内切换，需要可暂停的函数，并且可以在适当的时候恢复以继续执行 协程：可暂停的函数，可以向暂停的地方传入值 ","date":"2022-08-10","objectID":"/posts/notes/languages/python/imooc/12-coroutine/:3:2","tags":["python","python3","协程"],"title":"Python 高级编程（十二）协程","uri":"/posts/notes/languages/python/imooc/12-coroutine/"},{"categories":["学习笔记","python"],"content":"3.3 生成器高级特性 启动生成器的方法： gen.send(None) next(gen) 其他方法： gen.close()：关闭生成器 gen.throw()：向上次暂停的地方传入异常 return 值： 运行到 return 语句会抛出 StopIteration 异常，e.value 就是返回值 ","date":"2022-08-10","objectID":"/posts/notes/languages/python/imooc/12-coroutine/:3:3","tags":["python","python3","协程"],"title":"Python 高级编程（十二）协程","uri":"/posts/notes/languages/python/imooc/12-coroutine/"},{"categories":["学习笔记","python"],"content":"3.4 yield from itertools.chan() 可以连接多个 Iterable 对象 yield from [sub-generator | iterable] 会在调用方和子生成器之间建立一个双向通道： next() 会从子生成器 yield 出一个值 send() 会发送到子生成器 throw() 会发送到子生成器 子生成器的 return 值会返回到 yield from 所在行，赋值给左边（把子生成器抛出的 StopIteration 异常中的 value 复制给左边）。 ","date":"2022-08-10","objectID":"/posts/notes/languages/python/imooc/12-coroutine/:3:4","tags":["python","python3","协程"],"title":"Python 高级编程（十二）协程","uri":"/posts/notes/languages/python/imooc/12-coroutine/"},{"categories":["学习笔记","python"],"content":"3.5 async 和 await python 为了语义明确，就引入了 async 和 await 关键词用于定义原生协程 ","date":"2022-08-10","objectID":"/posts/notes/languages/python/imooc/12-coroutine/:3:5","tags":["python","python3","协程"],"title":"Python 高级编程（十二）协程","uri":"/posts/notes/languages/python/imooc/12-coroutine/"},{"categories":["学习笔记","python"],"content":"1. python 中的迭代协议 迭代器是访问集合内元素的一种方式，一般用来遍历数据。迭代器提供了一种惰性访问数据的方式。 下标访问依赖：__getitem__() 方法 可迭代对象(Iterable)：实现 __iter__() 方法 迭代器(Iterator)：实现 __iter__() 和 __next__() 方法 from collections.abc import Iterator class Company: \"\"\" 可迭代对象 Iterable \"\"\" def __init__(self, employee_list): self.employee_list = employee_list def __iter__(self): \"\"\" 返回迭代器 \"\"\" return MyIterator(self.employee_list) class MyIterator(Iterator): \"\"\" 迭代器 Iterator \"\"\" def __init__(self, iter_list): self.iter_list = iter_list self.index = 0 def __next__(self): try: val = self.iter_list[self.index] except IndexError: raise StopIteration self.index += 1 return val ","date":"2022-08-09","objectID":"/posts/notes/languages/python/imooc/9-iterator-generator/:1:0","tags":["python","python3","迭代器","生成器"],"title":"Python 高级编程（九）迭代器和生成器","uri":"/posts/notes/languages/python/imooc/9-iterator-generator/"},{"categories":["学习笔记","python"],"content":"2. 生成器 生成器函数：函数里有 yield，就是生成器函数，不再是一个普通函数了 生成器对象：生成器函数返回，在 python 编译字节码的时候就产生了 生成器为惰性求值（延迟求值）提供了可能 ","date":"2022-08-09","objectID":"/posts/notes/languages/python/imooc/9-iterator-generator/:2:0","tags":["python","python3","迭代器","生成器"],"title":"Python 高级编程（九）迭代器和生成器","uri":"/posts/notes/languages/python/imooc/9-iterator-generator/"},{"categories":["学习笔记","elasticsearch"],"content":"1. 数据格式 将 Elasticsearch 里存储文档数据和关系型数据库 MySQL 存储数据的概念进行一个类比: Types 的概念已经被逐渐弱化，Elasticsearch 6.X 中，一个 index 下已经只能包含一个 type，Elasticsearch 7.X 中, Type 的概念已经被删除了 ","date":"2022-08-08","objectID":"/posts/notes/databases/elasticsearch/atguigu_elasticsearch_lesson/elasticsearch-basic-usage/:1:0","tags":["elasticsearch","数据库","基础"],"title":"Elasticsearch 入门","uri":"/posts/notes/databases/elasticsearch/atguigu_elasticsearch_lesson/elasticsearch-basic-usage/"},{"categories":["学习笔记","elasticsearch"],"content":"2. HTTP 操作 ","date":"2022-08-08","objectID":"/posts/notes/databases/elasticsearch/atguigu_elasticsearch_lesson/elasticsearch-basic-usage/:2:0","tags":["elasticsearch","数据库","基础"],"title":"Elasticsearch 入门","uri":"/posts/notes/databases/elasticsearch/atguigu_elasticsearch_lesson/elasticsearch-basic-usage/"},{"categories":["学习笔记","elasticsearch"],"content":"2.1 索引操作 2.1.1 创建索引 对比关系型数据库，创建索引就等同于创建数据库。 PUT请求创建索引： PUT http://127.0.0.1:9200/\u003c索引名称\u003e 响应： { \"acknowledged\": true, // 创建成功 \"shards_acknowledged\": true, // 分片成功 \"index\": \"shopping\" // 索引名称 } 由于幂等性，如果重复添加索引，会返回错误信息 2.1.2 查看单个索引 GET http://127.0.0.1:9200/\u003c索引名称\u003e 2.1.3 查看所有索引 GET 127.0.0.1:9200/_cat/indices?v _cat 表示查看的意思，indices 表示索引 2.1.4 删除索引 DELETE http://127.0.0.1:9200/\u003c索引名称\u003e ","date":"2022-08-08","objectID":"/posts/notes/databases/elasticsearch/atguigu_elasticsearch_lesson/elasticsearch-basic-usage/:2:1","tags":["elasticsearch","数据库","基础"],"title":"Elasticsearch 入门","uri":"/posts/notes/databases/elasticsearch/atguigu_elasticsearch_lesson/elasticsearch-basic-usage/"},{"categories":["学习笔记","elasticsearch"],"content":"2.2 文档操作 2.2.1 创建文档 POST http://127.0.0.1:9200/\u003c索引名称\u003e/_doc 此处发送请求的方式必须为 POST，不能是 PUT，否则会发生错误。由于 PUT 是幂等的，每次提交返回因果应该一致，但创建返回的 id 每次不一样 自定义 id： POST | PUT http://127.0.0.1:9200/\u003c索引名称\u003e/_doc/\u003c自定义id\u003e 此处可以用 PUT，因为固定 id 了，满足了幂等性 2.2.2 查看文档 主键查询： GET http://127.0.0.1:9200/\u003c索引名称\u003e/_doc/\u003cid\u003e 全查询： GET http://127.0.0.1:9200/\u003c索引名称\u003e/_search 条件查询： GET http://127.0.0.1:9200/\u003c索引名称\u003e/_search?q=\u003c查询条件\u003e 或在 body 中添加： { \"query\": { \"match\": { \"category\": \"小米\" } } } 分页 body： { \"from\": 0, \"size\": 2 } 指定查询字段 body： { \"_source\": [\"title\"] } 排序 body: { \"sort\": { \"price\": { \"order\": \"desc\" } } } 2.2.3 修改文档 覆盖性修改： POST | PUT http://127.0.0.1:9200/\u003c索引名称\u003e/_doc/\u003cid\u003e 修改字段： POST http://127.0.0.1:9200/\u003c索引名称\u003e/_update/\u003cid\u003e body for _update: { \"doc\": { \"\u003cfield\u003e\": \"\u003cvalue\u003e\" } } 2.2.4 删除文档 DELETE http://127.0.0.1:9200/\u003c索引名称\u003e/_doc/\u003cid\u003e ","date":"2022-08-08","objectID":"/posts/notes/databases/elasticsearch/atguigu_elasticsearch_lesson/elasticsearch-basic-usage/:2:2","tags":["elasticsearch","数据库","基础"],"title":"Elasticsearch 入门","uri":"/posts/notes/databases/elasticsearch/atguigu_elasticsearch_lesson/elasticsearch-basic-usage/"},{"categories":["学习笔记","elasticsearch"],"content":"2.3 映射操作 创建数据库表需要设置字段名称，类型，长度，约束等；索引库也一样，需要知道这个类型下有哪些字段，每个字段有哪些约束信息，这就叫做映射(mapping)。 2.3.1 创建映射 POST http://127.0.0.1:9200/\u003c索引名称\u003e/_mapping 2.3.2 查看映射 GET http://127.0.0.1:9200/\u003c索引名称\u003e/_mapping ","date":"2022-08-08","objectID":"/posts/notes/databases/elasticsearch/atguigu_elasticsearch_lesson/elasticsearch-basic-usage/:2:3","tags":["elasticsearch","数据库","基础"],"title":"Elasticsearch 入门","uri":"/posts/notes/databases/elasticsearch/atguigu_elasticsearch_lesson/elasticsearch-basic-usage/"},{"categories":["学习笔记","elasticsearch"],"content":"3. Python API 操作 import functools import json import elasticsearch import elasticsearch.helpers import elasticsearch_dsl from elasticsearch_dsl import Q from pydantic import BaseModel class UserModel(BaseModel): name: str age: int sex: str def print_returned_value(func): @functools.wraps(func) def wrapper(*args, **kwargs): rtn = func(*args, **kwargs) print(rtn) return rtn return wrapper def print_elasticsearch_exception(func): @functools.wraps(func) def wrapper(*args, **kwargs): try: rtn = func(*args, **kwargs) except elasticsearch.ElasticsearchException as e: print(str(e)) else: return rtn return wrapper class ElasticSearchTest: def __init__(self): self.client = elasticsearch.Elasticsearch('http://localhost:9200') @print_returned_value @print_elasticsearch_exception def create_index(self): \"\"\" 创建索引 \"\"\" resp = self.client.indices.create('user') return resp @print_returned_value @print_elasticsearch_exception def get_index(self): \"\"\" 查询索引 \"\"\" resp = self.client.indices.get('user') return resp @print_returned_value @print_elasticsearch_exception def delete_index(self): \"\"\" 删除索引 \"\"\" resp = self.client.indices.delete('user') return resp @print_returned_value @print_elasticsearch_exception def create_doc(self): \"\"\" 插入数据 \"\"\" user = UserModel( name='zhangsan', age=30, sex='男', ) resp = self.client.create(index='user', id=1001, body=user.json()) return resp @print_returned_value @print_elasticsearch_exception def update_doc(self): \"\"\" 更新数据 \"\"\" body = { 'doc': { 'sex': '女' } } resp = self.client.update(index='user', id=1001, body=json.dumps(body)) return resp @print_returned_value @print_elasticsearch_exception def get_doc(self): \"\"\" 查询数据 \"\"\" resp = self.client.get(index='user', id=1001) return resp @print_returned_value @print_elasticsearch_exception def delete_doc(self): \"\"\" 删除数据 \"\"\" resp = self.client.delete(index='user', id=1001) return resp @print_returned_value @print_elasticsearch_exception def bulk_create_doc(self): \"\"\" 批量创建数据 \"\"\" users = [ UserModel(name='zhangsan', age=30, sex='男').dict(), UserModel(name='lisi', age=30, sex='女').dict(), UserModel(name='wangwu', age=40, sex='男').dict(), UserModel(name='wangwu1', age=40, sex='女').dict(), UserModel(name='wangwu2', age=50, sex='男').dict(), UserModel(name='wangwu3', age=50, sex='男').dict(), ] actions = [] for i in range(len(users)): actions.append( {'_op_type': 'create', '_index': 'user', '_id': 1001 + i, '_source': users[i]} ) resp = elasticsearch.helpers.bulk(self.client, actions) return resp @print_returned_value @print_elasticsearch_exception def bulk_delete_doc(self): \"\"\" 批量删除数据 \"\"\" actions = [] for i in range(6): actions.append( {'_op_type': 'delete', '_index': 'user', '_id': 1001 + i} ) resp = elasticsearch.helpers.bulk(self.client, actions) return resp @print_returned_value @print_elasticsearch_exception def search_all_doc(self): \"\"\" 查询所有 \"\"\" s = elasticsearch_dsl.Search(using=self.client, index='user') resp = s.execute() return resp.hits @print_returned_value @print_elasticsearch_exception def search_filtered_doc(self): \"\"\" 条件查询 \"\"\" s = elasticsearch_dsl.Search(using=self.client, index='user').filter('term', age=30) resp = s.execute() return resp.hits @print_returned_value @print_elasticsearch_exception def search_paginated_doc(self): \"\"\" 分页查询 elasticsearch_dsl 依赖 slicing 分页 \"\"\" s = elasticsearch_dsl.Search(using=self.client, index='user')[2:4] resp = s.execute() return resp.hits @print_returned_value @print_elasticsearch_exception def search_ordered_doc(self): \"\"\" 排序查询 `-` 代表 DESC \"\"\" s = elasticsearch_dsl.Search(using=self.client, index='user').sort('-age') resp = s.execute() return resp.hits @print_returned_value @print_elasticsearch_exception def search_field_doc(self): \"\"\" 指定或排除字段查询 \"\"\" includes = [] excludes = ['age'] s = elasticsearch_dsl.Search(using=self.client, index='user') \\ .source(includes=includes, excludes=excludes) resp = s.execute() return resp.hits @print_elasticsearch_exception def search_multi_filter_doc(self): \"\"\" 组合条件 Q 组合(| \u0026 ~)会自动生成 bool : should ","date":"2022-08-08","objectID":"/posts/notes/databases/elasticsearch/atguigu_elasticsearch_lesson/elasticsearch-basic-usage/:3:0","tags":["elasticsearch","数据库","基础"],"title":"Elasticsearch 入门","uri":"/posts/notes/databases/elasticsearch/atguigu_elasticsearch_lesson/elasticsearch-basic-usage/"},{"categories":["学习笔记","redis"],"content":"1. 过期策略 ","date":"2022-08-07","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/7-redis-principle-4-memory-policy/:1:0","tags":["redis","数据库","缓存","实现原理","内存回收"],"title":"高级篇（六）Redis 原理篇（四）内存策略","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/7-redis-principle-4-memory-policy/"},{"categories":["学习笔记","redis"],"content":"1.1 Redis db Redis本身是一个典型的key-value内存存储数据库，因此所有的key、value都保存在之前学习过的Dict结构中。不过在其database结构体（0-15每个db就是一个该结构体实例）中，有两个Dict：一个用来记录key-value；另一个用来记录key-TTL。 key 过期后不会立即删除，而是采用惰性删除或周期删除。 ","date":"2022-08-07","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/7-redis-principle-4-memory-policy/:1:1","tags":["redis","数据库","缓存","实现原理","内存回收"],"title":"高级篇（六）Redis 原理篇（四）内存策略","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/7-redis-principle-4-memory-policy/"},{"categories":["学习笔记","redis"],"content":"1.2 惰性删除 并不是在TTL到期后就立刻删除，而是在访问一个key的时候，检查该key的存活时间，如果已经过期才执行删除。 ","date":"2022-08-07","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/7-redis-principle-4-memory-policy/:1:2","tags":["redis","数据库","缓存","实现原理","内存回收"],"title":"高级篇（六）Redis 原理篇（四）内存策略","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/7-redis-principle-4-memory-policy/"},{"categories":["学习笔记","redis"],"content":"1.3 周期删除 通过一个定时任务，周期性的抽样部分过期的key，然后执行删除。 执行周期有两种： SLOW 模式：Redis服务初始化函数initServer()中设置定时任务，按照server.hz的频率来执行过期key清理 FAST 模式：Redis的每个事件循环前会调用beforeSleep()函数，执行过期key清理 SLOW模式规则： 执行频率受server.hz影响，默认为10，即每秒执行10次，每个执行周期100ms。 执行清理耗时不超过一次执行周期的25%.默认slow模式耗时不超过25ms 逐个遍历db，逐个遍历db中的bucket，抽取20个key判断是否过期 如果没达到时间上限（25ms）并且过期key比例大于10%，再进行一次抽样，否则结束 FAST模式规则（过期key比例小于10%不执行）： 执行频率受beforeSleep()调用频率影响，但两次FAST模式间隔不低于2ms 执行清理耗时不超过1ms 逐个遍历db，逐个遍历db中的bucket，抽取20个key判断是否过期，如果没达到时间上限（1ms）并且过期key比例大于10%，再进行一次抽样，否则结束 ","date":"2022-08-07","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/7-redis-principle-4-memory-policy/:1:3","tags":["redis","数据库","缓存","实现原理","内存回收"],"title":"高级篇（六）Redis 原理篇（四）内存策略","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/7-redis-principle-4-memory-policy/"},{"categories":["学习笔记","redis"],"content":"2. 淘汰策略 内存淘汰：就是当Redis内存使用达到设置的上限时，主动挑选部分key删除以释放更多内存的流程。 Redis会在处理客户端命令的方法processCommand()中尝试做内存淘汰。 Redis支持8种不同策略来选择要删除的key： noeviction： 不淘汰任何key，但是内存满时不允许写入新数据，默认就是这种策略。 volatile-ttl： 对设置了TTL的key，比较key的剩余TTL值，TTL越小越先被淘汰 allkeys-random：对全体key ，随机进行淘汰。也就是直接从db-\u003edict中随机挑选 volatile-random：对设置了TTL的key ，随机进行淘汰。也就是从db-\u003eexpires中随机挑选。 allkeys-lru： 对全体key，基于LRU算法进行淘汰 volatile-lru： 对设置了TTL的key，基于LRU算法进行淘汰 allkeys-lfu： 对全体key，基于LFU算法进行淘汰 volatile-lfu： 对设置了TTL的key，基于LFI算法进行淘汰 LRU（Least Recently Used），最少最近使用（不是最近最少使用，不要搞错了）。用当前时间减去最后一次访问时间，这个值越大则淘汰优先级越高。 LFU（Least Frequently Used），最少频率使用。会统计每个key的访问频率，值越小淘汰优先级越高。 RedisObject 记录 LRU 或 LFU 数据： LFU的访问次数之所以叫做逻辑访问次数，是因为并不是每次key被访问都计数，而是通过运算： 生成0~1之间的随机数R 计算 (旧次数 * lfu_log_factor + 1)，记录为P 如果 R \u003c P ，则计数器 + 1，且最大不超过255 访问次数会随时间衰减，距离上一次访问时间每隔 lfu_decay_time 分钟，计数器 -1 ","date":"2022-08-07","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/7-redis-principle-4-memory-policy/:2:0","tags":["redis","数据库","缓存","实现原理","内存回收"],"title":"高级篇（六）Redis 原理篇（四）内存策略","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/7-redis-principle-4-memory-policy/"},{"categories":["学习笔记","redis"],"content":"1. RESP 协议 Redis是一个CS架构的软件，通信一般分两步（不包括pipeline和PubSub）： 客户端（client）向服务端（server）发送一条命令 服务端解析并执行命令，返回响应结果给客户端 客户端发送命令的格式、服务端响应结果的格式必须有一个规范，这个规范就是通信协议。 在Redis中采用的是RESP（Redis Serialization Protocol）协议： Redis 1.2版本引入了RESP协议 Redis 2.0版本中成为与Redis服务端通信的标准，称为RESP2 Redis 6.0版本中，从RESP2升级到了RESP3协议，增加了更多数据类型并且支持6.0的新特性–客户端缓存 目前，默认使用的依然是RESP2协议，也是我们要学习的协议版本（以下简称RESP）。 在RESP中，通过首字节的字符来区分不同数据类型，常用的数据类型包括5种： 单行字符串：首字节是 ‘+’ ，后面跟上单行字符串，以CRLF（ “\\r\\n” ）结尾（二进制不安全：字符串本身不能带 CRLF）。例如返回\"OK\"： “+OK\\r\\n” 错误（Errors）：首字节是 ‘-’ ，与单行字符串格式一样，只是字符串是异常信息。例如：\"-Error message\\r\\n\" 数值：首字节是 ‘:’ ，后面跟上数字格式的字符串，以CRLF结尾。例如：\":10\\r\\n\" 多行字符串：首字节是 ‘$’，后面跟字节数，CRLF 开始和结束，表示二进制安全的字符串，最大支持512MB： 如果大小为0，则代表空字符串：\"$0\\r\\n\\r\\n\" 如果大小为-1，则代表不存在：\"$-1\\r\\n\" 数组：首字节是 ‘*’，后面跟上数组元素个数，再跟上元素，CRLF结尾，元素数据类型不限。 ","date":"2022-08-07","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/5-redis-principle-3-resp-protocol/:1:0","tags":["redis","数据库","缓存","实现原理","通信协议"],"title":"高级篇（五）Redis 原理篇（三）通信协议","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/5-redis-principle-3-resp-protocol/"},{"categories":["学习笔记","redis"],"content":"2. 基于 python socket 模拟客户端 import socket class RedisClient: def __init__(self): self.sock = socket.socket() self.socket_writer = self.sock.makefile(mode='wb') # makefile() 返回 file object 来操作 socket self.socket_reader = self.sock.makefile(mode='rb') def send_request(self, *args): \"\"\" 发送命令 :param args: :return: \"\"\" self.socket_writer.write(('*' + str(len(args)) + '\\r\\n').encode()) for command in args: self.socket_writer.write(('$' + str(len(command.encode())) + '\\r\\n' + command + '\\r\\n').encode()) self.socket_writer.flush() def handle_response(self): \"\"\" 处理响应 :return: \"\"\" prefix = self.socket_reader.read(1) if prefix == b'+': return self.socket_reader.readline().decode() if prefix == b'-': raise RuntimeError(self.socket_reader.readline().decode()) if prefix == b':': return int(self.socket_reader.readline().decode()) if prefix == b'$': length = int(self.socket_reader.readline().decode()) if length == -1: return None if length == 0: return '' data = self.socket_reader.read(length).decode() self.socket_reader.read(2) # 读取剩下的 \\r\\n return data if prefix == b'*': return self.read_bulk_string() raise RuntimeError('错误的数据格式') def read_bulk_string(self): \"\"\" 读数组响应 :return: \"\"\" resp = [] # 获取数组大小 length = int(self.socket_reader.readline().decode()) if length \u003c= 0: return None # 遍历读取元素 for i in range(length): resp.append(self.handle_response()) return resp def main(self): try: # 1. 建立连接 self.sock.connect(('192.168.31.57', 6379)) # 2. 发出请求 self.send_request('set', 'name', '虎哥') # 3. 解析响应 obj = self.handle_response() print(obj) # 2. 发出请求 self.send_request('get', 'name') # 3. 解析响应 obj = self.handle_response() print(obj) # 2. 发出请求 self.send_request('set', 'name', 'bob') # 3. 解析响应 obj = self.handle_response() print(obj) # 2. 发出请求 self.send_request('get', 'name') # 3. 解析响应 obj = self.handle_response() print(obj) finally: # 4. 释放连接 self.sock.close() if __name__ == '__main__': c = RedisClient() c.main() # stdout \u003e OK \u003e \u003e 虎哥 \u003e OK \u003e \u003e bob ","date":"2022-08-07","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/5-redis-principle-3-resp-protocol/:2:0","tags":["redis","数据库","缓存","实现原理","通信协议"],"title":"高级篇（五）Redis 原理篇（三）通信协议","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/5-redis-principle-3-resp-protocol/"},{"categories":["学习笔记","redis"],"content":"1. Linux IO 模型 ","date":"2022-08-06","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/4-redis-principle-2-network/:1:0","tags":["redis","数据库","缓存","实现原理","网络模型"],"title":"高级篇（四）Redis 原理篇（二）网络模型","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/4-redis-principle-2-network/"},{"categories":["学习笔记","redis"],"content":"1.1 用户空间和内核空间 内核本身上来说也是一个应用，所以他本身也需要一些内存，cpu等设备资源，用户应用本身也在消耗这些资源，如果不加任何限制，用户去操作随意的去操作我们的资源，就有可能导致一些冲突，甚至有可能导致我们的系统出现无法运行的问题，因此我们需要把用户和内核隔离开 进程的寻址空间划分成两部分：内核空间、用户空间 什么是寻址空间呢？我们的应用程序也好，还是内核空间也好，都是没有办法直接去物理内存的，而是通过分配一些虚拟内存映射到物理内存中，我们的内核和应用程序去访问虚拟内存的时候，就需要一个虚拟地址，这个地址是一个无符号的整数，比如一个32位的操作系统，他的带宽就是32，他的虚拟地址就是2的32次方，也就是说他寻址的范围就是0~2的32次方， 这片寻址空间对应的就是2的32个字节，就是4GB，这个4GB，会有3个GB分给用户空间，会有1GB给内核系统 在linux中，权限分成两个等级，0和3，用户空间只能执行受限的命令（Ring3），而且不能直接调用系统资源，必须通过内核提供的接口来访问内核空间可以执行特权命令（Ring0），调用一切系统资源，所以一般情况下，用户的操作是运行在用户空间，而内核运行的数据是在内核空间的，而有的情况下，一个应用程序需要去调用一些特权资源，去调用一些内核空间的操作，所以此时他俩需要在用户态和内核态之间进行切换。 Linux系统为了提高IO效率，会在用户空间和内核空间都加入缓冲区： 写数据时，要把用户缓冲数据拷贝到内核缓冲区，然后写入设备 读数据时，要从设备读取数据到内核缓冲区，然后拷贝到用户缓冲区 ","date":"2022-08-06","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/4-redis-principle-2-network/:1:1","tags":["redis","数据库","缓存","实现原理","网络模型"],"title":"高级篇（四）Redis 原理篇（二）网络模型","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/4-redis-principle-2-network/"},{"categories":["学习笔记","redis"],"content":"1.2 五种 IO 模型 在《UNIX网络编程》一书中，总结归纳了5种IO模型： 阻塞IO（Blocking IO） 非阻塞IO（Nonblocking IO） IO多路复用（IO Multiplexing） 信号驱动IO（Signal Driven IO） 异步IO（Asynchronous IO） 应用程序想要去读取数据，他是无法直接去读取磁盘、网卡等的，有两个等待阶段： 先到内核里边去等待内核操作硬件拿到数据 再把这个数据写给用户的缓存区 1.2.1 阻塞 IO 用户去读取数据时，会去先发起 recvform 一个命令，去尝试从内核上加载数据，如果内核没有数据，那么用户就会等待，此时内核会去从硬件上读取数据，内核读取数据之后，会把数据拷贝到用户态，并且返回ok，整个过程，都是阻塞等待的，这就是阻塞IO。 阻塞IO模型中，用户进程在两个阶段都是阻塞状态。 1.2.2 非阻塞 IO 非阻塞IO的recvfrom操作会立即返回结果而不是阻塞用户进程。 非阻塞IO模型中，用户进程在第一个阶段是非阻塞，第二个阶段是阻塞状态。虽然是非阻塞，但性能并没有得到提高。而且忙等机制会导致CPU空转，CPU使用率暴增。 1.2.3 IO 多路复用 用户进程如何知道内核中数据是否就绪呢？ 文件描述符（File Descriptor）：简称FD，是一个从0 开始的无符号整数，用来关联Linux中的一个文件。在Linux中，一切皆文件，例如常规文件、视频、硬件设备等，当然也包括网络套接字（Socket）。 IO 多路复用：利用一个线程监听多个FD，并在某个FD可读、可写时得到通知，从而避免无效的等待，充分利用CPU资源。 监听FD的方式、通知的方式又有多种实现，常见的有： select poll epoll elect 和 pool 相当于是当被监听的数据准备好之后，他会把你监听的所有FD整个数据都发给你，你需要到所有FD中去找，哪些是处理好了的，需要通过遍历的方式，所以性能也并不是那么好。 epoll，则相当于内核准备好了之后，他会把准备好的数据，直接发给你，咱们就省去了遍历的动作。 1.2.3.1 select 模式 select是Linux最早的I/O多路复用实现方案。 select 模式存在的问题： 需要将整个fd_set从用户空间拷贝到内核空间，select结束还要再次拷贝回用户空间 select无法得知具体是哪个fd就绪，需要遍历整个fd_set fd_set监听的fd数量不能超过1024，对高并发来讲完全不够用 1.2.3.2 poll 模式 poll 模式对 select 模式做了简单改进，但性能提升不明显。 与select对比： select模式中的fd_set大小固定为1024，而pollfd在内核中采用数组，理论上无上限 监听FD越多，每次遍历消耗时间也越久，性能反而会下降 1.2.3.3 epoll 模式 epoll 模式是对 select 和 poll 的巨大改进。 1.2.3.4 三种模式总结 select模式存在的三个问题： 能监听的FD最大不超过1024 每次select都需要把所有要监听的FD都拷贝到内核空间 每次都要遍历所有FD来判断就绪状态 poll模式的问题： poll利用链表解决了select中监听FD上限的问题，但依然要遍历所有FD，如果监听较多，性能会下降 epoll模式中如何解决这些问题的？ 基于epoll实例中的红黑树保存要监听的FD，理论上无上限，而且增删改查效率都非常高 每个FD只需要执行一次epoll_ctl添加到红黑树，以后每次epol_wait无需传递任何参数，无需重复拷贝FD到内核空间 利用ep_poll_callback机制来监听FD状态，无需遍历所有FD，因此性能不会随监听的FD数量增多而下降 1.2.3.5 事件通知机制 当FD有数据可读时，我们调用epoll_wait（或者select、poll）可以得到通知。但是事件通知的模式有两种： LevelTriggered：简称LT，也叫做水平触发。只要某个FD中有数据可读，每次调用epoll_wait都会得到通知，可以重复通知。Epoll 默认模式 EdgeTriggered：简称ET，也叫做边沿触发。只有在某个FD有状态变化时，调用epoll_wait才会被通知，只通知一次。 总结： LT：事件通知频率较高，会有重复通知，影响性能 ET：仅通知一次，效率高。 可以基于非阻塞IO循环读取解决数据读取不完整问题 select和poll仅支持LT模式，epoll可以自由选择LT和ET两种模式 1.2.3.6 基于 epoll 的 web 服务的基本流程 1.2.4 信号驱动 IO 信号驱动IO是与内核建立SIGIO的信号关联并设置回调，当内核有FD就绪时，会发出SIGIO信号通知用户，期间用户应用可以执行其它业务，无需阻塞等待。 当有大量IO操作时，信号较多，SIGIO处理函数不能及时处理可能导致信号队列溢出，而且内核空间与用户空间的频繁信号交互性能也较低。 1.2.5 异步 IO 这种方式，不仅仅是用户态在试图读取数据后，不阻塞，而且当内核的数据准备完成后，也不会阻塞。 1.2.6 五种 IO 模型对比 同步还是异步关键看内核空间和用户空间的拷贝过程，也就是阶段二是同步还是异步。 ","date":"2022-08-06","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/4-redis-principle-2-network/:1:2","tags":["redis","数据库","缓存","实现原理","网络模型"],"title":"高级篇（四）Redis 原理篇（二）网络模型","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/4-redis-principle-2-network/"},{"categories":["学习笔记","redis"],"content":"2. Redis 网络模型 ","date":"2022-08-06","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/4-redis-principle-2-network/:2:0","tags":["redis","数据库","缓存","实现原理","网络模型"],"title":"高级篇（四）Redis 原理篇（二）网络模型","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/4-redis-principle-2-network/"},{"categories":["学习笔记","redis"],"content":"2.1 Redis是单线程的吗？为什么使用单线程 Redis到底是单线程还是多线程？ 如果仅仅聊Redis的核心业务部分（命令处理），答案是单线程 如果是聊整个Redis，那么答案就是多线程 在Redis版本迭代过程中，在两个重要的时间节点上引入了多线程的支持： Redis v4.0：引入多线程异步处理一些耗时较旧的任务，例如异步删除命令unlink Redis v6.0：在核心网络模型中引入 多线程，进一步提高对于多核CPU的利用率 对于Redis的核心网络模型，在Redis 6.0之前确实都是单线程。是利用epoll（Linux系统）这样的IO多路复用技术在事件循环中不断处理客户端情况。 为什么Redis要选择单线程？ 抛开持久化不谈，Redis是纯 内存操作，执行速度非常快，它的性能瓶颈是网络延迟而不是执行速度，因此多线程并不会带来巨大的性能提升。 多线程会导致过多的上下文切换，带来不必要的开销 引入多线程会面临线程安全问题，必然要引入线程锁这样的安全手段，实现复杂度增高，而且性能也会大打折扣 ","date":"2022-08-06","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/4-redis-principle-2-network/:2:1","tags":["redis","数据库","缓存","实现原理","网络模型"],"title":"高级篇（四）Redis 原理篇（二）网络模型","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/4-redis-principle-2-network/"},{"categories":["学习笔记","redis"],"content":"2.2 单线程和多线程模型 单线程： 多线程： 搞不懂了就看看视频教程 ","date":"2022-08-06","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/4-redis-principle-2-network/:2:2","tags":["redis","数据库","缓存","实现原理","网络模型"],"title":"高级篇（四）Redis 原理篇（二）网络模型","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/4-redis-principle-2-network/"},{"categories":["学习笔记","redis"],"content":"1. 基本数据结构 ","date":"2022-08-05","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/3-redis-principle-1-data-structure/:1:0","tags":["redis","数据库","缓存","实现原理","数据结构"],"title":"高级篇（三）Redis 原理篇（一）数据结构","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/3-redis-principle-1-data-structure/"},{"categories":["学习笔记","redis"],"content":"1.1 动态字符串 SDS Redis 没有直接使用 C 语言中的字符串，因为 C 语言字符串存在很多问题： 获取字符串长度的需要通过运算 非二进制安全 不可修改 Redis构建了一种新的字符串结构，称为简单动态字符串（Simple Dynamic String），简称SDS。 SDS 具备动态扩容能力，如果我们要给SDS追加一段字符串，首先会申请新内存空间，称为内存预分配，再把值写入： 如果新字符串小于 1M，则新空间为扩展后字符串长度的两倍 + 1 如果新字符串大于 1M，则新空间为扩展后字符串长度 + 1M + 1 SDS 优点： 获取字符串长度时间复杂度为 O(1) 支持动态扩容 减少内存分配次数 二进制安全 ","date":"2022-08-05","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/3-redis-principle-1-data-structure/:1:1","tags":["redis","数据库","缓存","实现原理","数据结构"],"title":"高级篇（三）Redis 原理篇（一）数据结构","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/3-redis-principle-1-data-structure/"},{"categories":["学习笔记","redis"],"content":"1.2 intset IntSet 是 Redis 中 set 集合的一种实现方式，基于整数数组来实现，并且具备长度可变、有序等特征。 结构如下： 其中的 encoding 包含三种模式，表示存储的整数大小不同： contents[] 存指向实际数组其实位置的指针，数据编码由 encoding 决定 为了方便查找，Redis 会将 intset 中所有的整数按照升序依次保存在contents数组中 我们向encoding: INTSET_ENC_INT16的 IntSet 添加一个数字：50000，这个数字超出了int16_t的范围，intset会自动升级编码方式到合适的大小，流程如下： 升级编码为INTSET_ENC_INT32, 每个整数占4字节，并按照新的编码方式及元素个数扩容数组 倒序依次将数组中的元素拷贝到扩容后的正确位置（后面的先往后放，如果正序，前面的扩容，后面就被覆盖了） 将待添加的元素放入数组末尾或开头（新的更大bit的元素只能大于或小于现有所有元素） 最后，将inset的encoding属性改为INTSET_ENC_INT32，将length属性改为4 总结： IntSet 中的元素唯一、有序 升级机制，节省内存空间 底层采用二分查找来查询，数据量不大的时候效率还行 ","date":"2022-08-05","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/3-redis-principle-1-data-structure/:1:2","tags":["redis","数据库","缓存","实现原理","数据结构"],"title":"高级篇（三）Redis 原理篇（一）数据结构","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/3-redis-principle-1-data-structure/"},{"categories":["学习笔记","redis"],"content":"1.3 Dict Redis 键与值的映射关系正是通过 Dict 来实现的。 Dict由三部分组成，分别是：哈希表（DictHashTable）、哈希节点（DictEntry）、字典（Dict） 当我们向 Dict 添加键值对时，Redis首先根据key计算出hash值（h），然后利用 h \u0026 sizemask（相当于 h % size）来计算元素应该存储到数组中的哪个索引位置。 Dict 在每次新增键值对时都会检查负载因子（LoadFactor = used/size） ，满足以下两种情况时会触发哈希表扩容： 哈希表的 LoadFactor \u003e= 1，并且服务器没有执行 BGSAVE 或者 BGREWRITEAOF 等后台进程 哈希表的 LoadFactor \u003e 5 Dict 每次删除元素时，当 LoadFactor 小于 0.1 时，Dict 收缩。 Dict的rehash 不管是扩容还是收缩，必定会创建新的哈希表，导致哈希表的 size 和 sizemask 变化，而key的查询与 sizemask 有关。因此必须对哈希表中的每一个 key 重新计算索引，插入新的哈希表，这个过程称为 rehash。过程是这样的： 计算新 hash 表的 realSize，值取决于当前要做的是扩容还是收缩： 如果是扩容，则新 size 为第一个大于等于 dict.ht[0].used + 1 的 2^n 如果是收缩，则新 size 为第一个大于等于 dict.ht[0].used 的 2^n（不得小于4） 按照新的 realSize 申请内存空间，创建 dictht，并赋值给 dict.ht[1] 设置 dict.rehashidx = 0，标示开始 rehash 将 dict.ht[0]中的每一个 dictEntry 都 rehash 到 dict.ht[1] 在 rehash 过程中，新增操作，则直接写入 ht[1]，查询、修改和删除则会在 dict.ht[0] 和 dict.ht[1] 依次查找并执行。这样可以确保 ht[0] 的数据只减不增，随着rehash最终为空 将 dict.ht[1]赋值给 dict.ht[0]，给 dict.ht[1] 初始化为空哈希表，释放原来的 dict.ht[0] 的内存 将 rehashidx 赋值为 -1，代表rehash结束 总结： Dict的结构： 类似java的HashTable，底层是数组加链表来解决哈希冲突 Dict包含两个哈希表，ht[0]平常用，ht[1]用来rehash Dict的伸缩： 当LoadFactor大于5或者LoadFactor大于1并且没有子进程任务时，Dict扩容 当LoadFactor小于0.1时，Dict收缩 扩容大小为第一个大于等于used + 1的2^n 收缩大小为第一个大于等于used 的2^n Dict采用渐进式rehash，每次访问Dict时执行一次rehash rehash时ht[0]只减不增，新增操作只在ht[1]执行，其它操作在两个哈希表 ","date":"2022-08-05","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/3-redis-principle-1-data-structure/:1:3","tags":["redis","数据库","缓存","实现原理","数据结构"],"title":"高级篇（三）Redis 原理篇（一）数据结构","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/3-redis-principle-1-data-structure/"},{"categories":["学习笔记","redis"],"content":"1.4 ZipList 整体结构 ZipList 是一种特殊的“双端链表” ，由一系列特殊编码的连续内存块组成。可以在任意一端进行压入/弹出操作, 并且该操作的时间复杂度为 O(1)。 属性 类型 长度 用途 zlbytes uint32_t 4 字节 记录整个压缩列表占用的内存字节数 zltail uint32_t 4 字节 记录压缩列表表尾节点距离压缩列表的起始地址有多少字节，通过这个偏移量，可以确定表尾节点的地址。 zllen uint16_t 2 字节 记录了压缩列表包含的节点数量。 最大值为UINT16_MAX （65534），如果超过这个值，此处会记录为65535，但节点的真实数量需要遍历整个压缩列表才能计算得出。 entry 列表节点 不定 压缩列表包含的各个节点，节点的长度由节点保存的内容决定。 zlend uint8_t 1 字节 特殊值 0xFF （十进制 255 ），用于标记压缩列表的末端。 ZipListEntry previous_entry_length：前一节点的长度，占1个或5个字节。 如果前一节点的长度小于254字节，则采用1个字节来保存这个长度值 如果前一节点的长度大于254字节，则采用5个字节来保存这个长度值，第一个字节为0xfe，后四个字节才是真实长度数据 encoding：编码属性，记录content的数据类型（字符串还是整数）以及长度，占用1个、2个或5个字节 contents：负责保存节点的数据，可以是字符串或整数 ZipList中所有存储长度的数值均采用小端字节序，即低位字节在前，高位字节在后。例如：数值0x1234，采用小端字节序后实际存储值为：0x3412 Encoding ZipListEntry中的encoding编码分为字符串和整数两种： 字符串：如果encoding是以“00”、“01”或者“10”开头，则证明content是字符串 编码 编码长度 字符串大小 |00pppppp| 1 bytes \u003c= 63 bytes |01pppppp|qqqqqqqq| 2 bytes \u003c= 16383 bytes |10000000|qqqqqqqq|rrrrrrrr|ssssssss|tttttttt| 5 bytes \u003c= 4294967295 bytes 整数：如果encoding是以“11”开始，则证明content是整数，且encodin g固定只占用1个字节 编码 编码长度 整数类型 11000000 1 int16_t（2 bytes） 11010000 1 int32_t（4 bytes） 11100000 1 int64_t（8 bytes） 11110000 1 24位有符整数(3 bytes) 11111110 1 8位有符整数(1 bytes) 1111xxxx 1 直接在xxxx位置保存数值，范围从0001~1101(1 - 13)(因为0000、1110在上面占用了，0xff 是 ziplist 结束标识)，减1后结果为实际值(0 - 12) ZipList的连锁更新问题 假设我们有N个连续的、长度为250~253字节之间的entry，左边新增、删除都可能导致连锁更新的发生。 总结： 压缩列表的可以看做一种连续内存空间的\"双向链表\" 列表的节点之间不是通过指针连接，而是记录上一节点和本节点长度来寻址，内存占用较低 如果列表数据过多，导致链表过长，可能影响查询性能 增或删较大数据时有可能发生连续更新问题 ","date":"2022-08-05","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/3-redis-principle-1-data-structure/:1:4","tags":["redis","数据库","缓存","实现原理","数据结构"],"title":"高级篇（三）Redis 原理篇（一）数据结构","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/3-redis-principle-1-data-structure/"},{"categories":["学习笔记","redis"],"content":"1.5 QuickList 它是一个双端链表，只不过链表中的每个节点都是一个 ZipList。 为了避免QuickList中的每个ZipList中entry过多，Redis提供了一个配置项：list-max-ziplist-size来限制。 由于读首尾比较多，QuickList 还可以对中间节点的 ZipList 进行压缩，通过 list-compress-depth 配置。 总结 QuickList的特点： 是一个节点为ZipList的双端链表 节点采用ZipList，解决了传统链表的内存占用问题 控制了ZipList大小，解决连续内存空间申请效率问题 中间节点可以压缩，进一步节省了内存 ","date":"2022-08-05","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/3-redis-principle-1-data-structure/:1:5","tags":["redis","数据库","缓存","实现原理","数据结构"],"title":"高级篇（三）Redis 原理篇（一）数据结构","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/3-redis-principle-1-data-structure/"},{"categories":["学习笔记","redis"],"content":"1.6 SkipList SkipList（跳表）本质是链表，但与传统链表相比有几点差异： 元素按照升序排列存储 节点可能包含多个指针，指针跨度不同。 总结 SkipList的特点： 跳跃表是一个双向链表，每个节点都包含score和ele值 节点按照score值排序，score值一样则按照ele字典排序 每个节点都可以包含多层指针，层数是1到32之间的随机数 不同层指针到下一个节点的跨度不同，层级越高，跨度越大 增删改查效率与红黑树基本一致，实现却更简单 ","date":"2022-08-05","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/3-redis-principle-1-data-structure/:1:6","tags":["redis","数据库","缓存","实现原理","数据结构"],"title":"高级篇（三）Redis 原理篇（一）数据结构","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/3-redis-principle-1-data-structure/"},{"categories":["学习笔记","redis"],"content":"1.7 RedisObject Redis中的任意数据类型的键和值都会被封装为一个RedisObject。 String 类型每个对象都有一个头，占用内存，尽量用集合类型代替 11种编码 编号 编码方式 说明 0 OBJ_ENCODING_RAW raw编码动态字符串 1 OBJ_ENCODING_INT long类型的整数的字符串 2 OBJ_ENCODING_HT hash表（字典dict） 3 OBJ_ENCODING_ZIPMAP 已废弃 4 OBJ_ENCODING_LINKEDLIST 双端链表 5 OBJ_ENCODING_ZIPLIST 压缩列表 6 OBJ_ENCODING_INTSET 整数集合 7 OBJ_ENCODING_SKIPLIST 跳表 8 OBJ_ENCODING_EMBSTR embstr的动态字符串 9 OBJ_ENCODING_QUICKLIST 快速列表 10 OBJ_ENCODING_STREAM Stream流 5种数据类型 数据类型 编码方式 OBJ_STRING int、embstr、raw OBJ_LIST LinkedList和ZipList(3.2以前)、QuickList（3.2以后） OBJ_SET intset、HT OBJ_ZSET ZipList、HT、SkipList OBJ_HASH ZipList、HT BitMap, HyperLogLog 底层就是 String ","date":"2022-08-05","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/3-redis-principle-1-data-structure/:1:7","tags":["redis","数据库","缓存","实现原理","数据结构"],"title":"高级篇（三）Redis 原理篇（一）数据结构","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/3-redis-principle-1-data-structure/"},{"categories":["学习笔记","redis"],"content":"2. 五种数据类型 ","date":"2022-08-05","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/3-redis-principle-1-data-structure/:2:0","tags":["redis","数据库","缓存","实现原理","数据结构"],"title":"高级篇（三）Redis 原理篇（一）数据结构","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/3-redis-principle-1-data-structure/"},{"categories":["学习笔记","redis"],"content":"2.1 String 其基本编码方式是RAW，基于简单动态字符串（SDS）实现，存储上限为512mb。 如果存储的SDS长度小于44字节（实际内容长度，不包括 SDS head），则会采用 EMBSTR 编码，此时 object head 与 SDS 是一段连续空间（Redis Object 和 SDS 加一起不超过 64 字节）。申请内存时只需要调用一次内存分配函数，效率更高。 如果存储的字符串是整数值，并且大小在 LONG_MAX 范围内，则会采用 INT 编码：直接将数据保存在 RedisObject 的 ptr 指针位置（刚好 8 字节），不再需要 SDS 了。 使用 String 时尽量小于 44 字节，能用整数值尽量用整数；key 也是 String 类型，因此尽量不超过 44 字节。 ","date":"2022-08-05","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/3-redis-principle-1-data-structure/:2:1","tags":["redis","数据库","缓存","实现原理","数据结构"],"title":"高级篇（三）Redis 原理篇（一）数据结构","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/3-redis-principle-1-data-structure/"},{"categories":["学习笔记","redis"],"content":"2.2 List 在 3.2 版本之后，Redis 统一采用 QuickList 来实现 List ","date":"2022-08-05","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/3-redis-principle-1-data-structure/:2:2","tags":["redis","数据库","缓存","实现原理","数据结构"],"title":"高级篇（三）Redis 原理篇（一）数据结构","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/3-redis-principle-1-data-structure/"},{"categories":["学习笔记","redis"],"content":"2.3 Set 为了查询效率和唯一性，set采用HT编码（Dict）。Dict中的key用来存储元素，value统一为null。 当存储的所有数据都是整数，并且元素数量不超过set-max-intset-entries时，Set 会采用 IntSet 编码，以节省内存 插入时，如果不满足 IntSet 条件，会进行编码转换 ","date":"2022-08-05","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/3-redis-principle-1-data-structure/:2:3","tags":["redis","数据库","缓存","实现原理","数据结构"],"title":"高级篇（三）Redis 原理篇（一）数据结构","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/3-redis-principle-1-data-structure/"},{"categories":["学习笔记","redis"],"content":"2.4 ZSet(SortedSet) 通过 Dict 和 SkipList 实现： 当元素数量不多时，HT和SkipList的优势不明显，而且更耗内存。因此zset还会采用ZipList结构来节省内存，不过需要同时满足两个条件： 元素数量小于zset_max_ziplist_entries，默认值128 每个元素都小于zset_max_ziplist_value字节，默认值64 ziplist本身没有排序功能，而且没有键值对的概念，因此需要有zset通过编码实现： ZipList是连续内存，因此score和element是紧挨在一起的两个entry， element在前，score在后 score越小越接近队首，score越大越接近队尾，按照score值升序排列 添加元素时可能触发编码转换 ","date":"2022-08-05","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/3-redis-principle-1-data-structure/:2:4","tags":["redis","数据库","缓存","实现原理","数据结构"],"title":"高级篇（三）Redis 原理篇（一）数据结构","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/3-redis-principle-1-data-structure/"},{"categories":["学习笔记","redis"],"content":"2.5 Hash Hash结构默认采用ZipList编码，用以节省内存。 ZipList中相邻的两个entry 分别保存field和value 当数据量较大时，Hash结构会转为HT编码，也就是Dict，触发条件有两个： ZipList中的元素数量超过了hash-max-ziplist-entries（默认512） ZipList中的任意entry大小超过了hash-max-ziplist-value（默认64字节） Redis的hash之所以这样设计，是因为当ziplist变得很⼤的时候，它有如下几个缺点： 每次插⼊或修改引发的realloc操作会有更⼤的概率造成内存拷贝，从而降低性能。 ⼀旦发生内存拷贝，内存拷贝的成本也相应增加，因为要拷贝更⼤的⼀块数据。 当ziplist数据项过多的时候，在它上⾯查找指定的数据项就会性能变得很低，因为ziplist上的查找需要进行遍历。 总之，ziplist本来就设计为各个数据项挨在⼀起组成连续的内存空间，这种结构并不擅长做修改操作。⼀旦数据发⽣改动，就会引发内存realloc，可能导致内存拷贝。 ","date":"2022-08-05","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/3-redis-principle-1-data-structure/:2:5","tags":["redis","数据库","缓存","实现原理","数据结构"],"title":"高级篇（三）Redis 原理篇（一）数据结构","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/3-redis-principle-1-data-structure/"},{"categories":["学习笔记","redis"],"content":"1. Redis键值设计 ","date":"2022-08-04","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/2-redis-best-practice/:1:0","tags":["redis","数据库","缓存","最佳实践"],"title":"高级篇（二）Redis 最佳实践","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/2-redis-best-practice/"},{"categories":["学习笔记","redis"],"content":"1.1 优雅的key结构 key 最佳实践约定： 遵循基本格式：[业务名称]:[数据名]:[id] 长度不超过44字节 不包含特殊字符 key是string类型，底层编码包含int、embstr和raw三种。embstr在小于44字节使用，采用连续内存空间，内存占用更小。当字节数大于44字节时，会转为raw模式存储，在raw模式下，内存空间不是连续的，而是采用一个指针指向了另外一段内存空间，在这段空间里存储SDS内容，这样空间不连续，访问的时候性能也就会收到影响，还有可能产生内存碎片。 ","date":"2022-08-04","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/2-redis-best-practice/:1:1","tags":["redis","数据库","缓存","最佳实践"],"title":"高级篇（二）Redis 最佳实践","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/2-redis-best-practice/"},{"categories":["学习笔记","redis"],"content":"1.2 拒绝BigKey 推荐值： 单个key的value小于10KB 对于集合类型的key，建议元素数量小于1000 1.2.1 BigKey的危害 网络阻塞 对 BigKey 执行读请求时，少量的 QPS 就可能导致带宽使用率被占满，导致 Redis 实例，乃至所在物理机变慢 数据倾斜 BigKey 所在的 Redis 实例内存使用率远超其他实例，无法使数据分片的内存资源达到均衡 Redis 阻塞 对元素较多的 hash、list、zset 等做运算会耗时较长，使主线程被阻塞 CPU 压力 对 BigKey 的数据序列化和反序列化会导致 CPU 的使用率飙升，影响 Redis 实例和本机其它应用 1.2.2 如何发现BigKey redis-cli --bigkeys SCAN 命令 第三方工具 网络监控 1.2.3 如何删除BigKey BigKey 内存占用较多，即便时删除这样的 key 也需要耗费很长时间，导致 Redis 主线程阻塞，引发一系列问题。 使用unlink 命令异步删除 ","date":"2022-08-04","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/2-redis-best-practice/:1:2","tags":["redis","数据库","缓存","最佳实践"],"title":"高级篇（二）Redis 最佳实践","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/2-redis-best-practice/"},{"categories":["学习笔记","redis"],"content":"1.3 恰当的数据类型 例1：比如存储一个User对象，我们有三种存储方式： json 字符串：实现简单；但数据耦合 字段打散：可以访问任意字段；但占用空间大，没法统一控制 hash（推荐）：底层 ziplist，占用空间小，可以访问任意字段；但代码相对复杂 例2：假如有hash类型的key，其中有100万对 field 和 value ，field 是自增 id，这个 key 存在什么问题？如何优化？ 存在的问题： hash 的 entry 数量超过 500 时，会使用哈希表而不是 ZipList，内存占用较多 可以通过 hash-max-ziplist-entries 配置 entry 上限。但是如果 entry 过多就会导致 BigKey 问题 解决方案： 拆分为小的 hash，将 id / 100 作为 key， 将 id % 100 作为 field，这样每 100 个元素为一个 Hash ","date":"2022-08-04","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/2-redis-best-practice/:1:3","tags":["redis","数据库","缓存","最佳实践"],"title":"高级篇（二）Redis 最佳实践","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/2-redis-best-practice/"},{"categories":["学习笔记","redis"],"content":"2. 批处理优化 ","date":"2022-08-04","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/2-redis-best-practice/:2:0","tags":["redis","数据库","缓存","最佳实践"],"title":"高级篇（二）Redis 最佳实践","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/2-redis-best-practice/"},{"categories":["学习笔记","redis"],"content":"2.1 pipeline redis 处理指令是很快的，主要花费的时候在于网络传输。于是乎很容易想到将多条指令批量的传输给 redis 方案： mset、hmset 批量插入命令 pipeline：redis-py 可指定是否 transaction ","date":"2022-08-04","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/2-redis-best-practice/:2:1","tags":["redis","数据库","缓存","最佳实践"],"title":"高级篇（二）Redis 最佳实践","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/2-redis-best-practice/"},{"categories":["学习笔记","redis"],"content":"2.2 集群下的批处理 redis-py: cluster.mset({'k1': 'v1', 'k2': 'v2', 'k3': 'v3'}) 不能用，必须同一个 slot 才行。因此要先用 cluster.keyslot(\u003ckey\u003e)分组。 cluster.pipeline().set('k1', 'v1').set('k2', 'v2').set('k3', 'v3').execute() 可以用。 ","date":"2022-08-04","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/2-redis-best-practice/:2:2","tags":["redis","数据库","缓存","最佳实践"],"title":"高级篇（二）Redis 最佳实践","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/2-redis-best-practice/"},{"categories":["学习笔记","redis"],"content":"3. 服务端优化 ","date":"2022-08-04","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/2-redis-best-practice/:3:0","tags":["redis","数据库","缓存","最佳实践"],"title":"高级篇（二）Redis 最佳实践","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/2-redis-best-practice/"},{"categories":["学习笔记","redis"],"content":"3.1 持久化配置 做缓存的 Redis 实例不要做持久化 建议关闭 RDB，使用 AOF，RDB 安全性不好，太频繁了性能消耗大 利用脚本定期在 slave 做 RDB，实现数据备份 设置合理的 rewrite 阈值，避免频繁的 bgrewrite 配置 no-appendfsync-on-rewrite yes，禁止在 rewrite 期间做 AOF， 避免 AOF 引起阻塞（牺牲数据安全性） 部署相关： 要预留足够内存应对 fork 和 rewrite 单个实例内存上限不要太大（可单机多实例），以加快 fork 速度、减少主从同步、数据迁移压力 不要和 CPU 密集型应用部署在一起 不要和高硬盘负载应用部署在一起 ","date":"2022-08-04","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/2-redis-best-practice/:3:1","tags":["redis","数据库","缓存","最佳实践"],"title":"高级篇（二）Redis 最佳实践","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/2-redis-best-practice/"},{"categories":["学习笔记","redis"],"content":"3.2 慢查询优化 配置慢查询日志 slowlog-log-slower-than：慢查询阈值，单位是微秒。默认是10000，建议1000 slowlog-max-len：慢查询日志（本质是一个队列）的长度。默认是128，建议1000 查看慢查询 slowlog len：查询慢查询日志长度 slowlog get [n]：读取n条慢查询日志 slowlog reset：清空慢查询列表 ","date":"2022-08-04","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/2-redis-best-practice/:3:2","tags":["redis","数据库","缓存","最佳实践"],"title":"高级篇（二）Redis 最佳实践","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/2-redis-best-practice/"},{"categories":["学习笔记","redis"],"content":"3.3 命令及安全配置 Redis 未授权访问配合 SSH key 文件利用分析漏洞 为了避免这样的漏洞，这里给出一些建议： Redis 一定要设置密码 禁止线上使用下面命令：keys、flushall、flushdb、config set 等命令。可以利用 rename-command 配置禁用。 bind 配置：限制网卡，禁止外网网卡访问 开启防火墙 不要使用 Root 账户启动 Redis 尽量不用默认的端口 ","date":"2022-08-04","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/2-redis-best-practice/:3:3","tags":["redis","数据库","缓存","最佳实践"],"title":"高级篇（二）Redis 最佳实践","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/2-redis-best-practice/"},{"categories":["学习笔记","redis"],"content":"3.4 内存配置 当 Redis 内存不足时，可能导致 Key 频繁被删除、响应时间变长、QPS 不稳定等问题。当内存使用率达到 90% 以上时就需要我们警惕，并快速定位到内存占用的原因。 内存占用 说明 数据内存 是Redis最主要的部分，存储Redis的键值信息。主要问题是BigKey问题、内存碎片问题 进程内存 Redis主进程本身运⾏肯定需要占⽤内存，如代码、常量池等等；这部分内存⼤约⼏兆，在⼤多数⽣产环境中与Redis数据占⽤的内存相⽐可以忽略。 缓冲区内存 一般包括客户端缓冲区、AOF缓冲区、复制缓冲区等。客户端缓冲区又包括输入缓冲区和输出缓冲区两种。这部分内存占用波动较大，不当使用BigKey，可能导致内存溢出。 查看内存占用命令： info memory： 查看内存分配的情况 memory …：查看 key 的内存占用情况 内存缓冲区常见的有三种： 复制缓冲区：主从复制的 repl_backlog_buf，如果太小可能导致频繁的全量复制，影响性能。通过 replbacklog-size 来设置，默认1mb AOF 缓冲区：AOF 刷盘之前的缓存区域，AOF 执行 rewrite 的缓冲区。无法设置容量上限 客户端缓冲区：分为输入缓冲区和输出缓冲区，输入缓冲区最大 1G 且不能设置。输出缓冲区（client-output-buffer-limit 配置）可以设置 处理大量的 big value，那么会导致我们的输出结果过多，如果输出缓存区过大，内存占满，会导致 redis 直接断开，而默认配置的情况下， 其实他是没有大小的，这就比较坑了，内存可能一下子被占满，会直接导致咱们的 redis 断开，所以解决方案有两个 设置一个大小 增加我们带宽的大小，避免我们出现大量数据从而直接超过了redis的承受能力 ","date":"2022-08-04","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/2-redis-best-practice/:3:4","tags":["redis","数据库","缓存","最佳实践"],"title":"高级篇（二）Redis 最佳实践","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/2-redis-best-practice/"},{"categories":["学习笔记","redis"],"content":"3.5 集群还是主从 集群虽然具备高可用特性，能实现自动故障恢复，但是如果使用不当，也会存在一些问题： 集群完整性问题：cluster-require-full-coverage 配置是否所有 slot 都能用，集群才提供服务 集群带宽问题：集群节点之间会不断的互相 Ping 来确定集群中其它节点的状态，节点太多时，会占用很多带宽 数据倾斜问题 客户端性能问题 命令的集群兼容性问题 lua 和事务问题：lua 和事务都是要保证原子性问题，如果你的 key 不在一个节点，那么是无法保证lua的执行和事务的特性的，所以在集群模式是没有办法执行 lua 和事务的 单体 Redis（主从 Redis）已经能达到万级别的 QPS，并且也具备很强的高可用特性。如果主从能满足业务需求的情况下，所以如果不是在万不得已的情况下，尽量不搭建 Redis 集群。 ","date":"2022-08-04","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/2-redis-best-practice/:3:5","tags":["redis","数据库","缓存","最佳实践"],"title":"高级篇（二）Redis 最佳实践","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/2-redis-best-practice/"},{"categories":["学习笔记","redis"],"content":"单机的Redis存在四大问题: 数据丢失问题：redis 持久化 并发能力问题：主从集群，读写分离 储存能力问题：分配集群，插槽机制动态扩容 故障恢复问题：redis 哨兵，健康检测和自动恢复 ","date":"2022-07-29","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/:0:0","tags":["redis","数据库","缓存","分布式","集群"],"title":"高级篇（一）Redis 分布式缓存","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/"},{"categories":["学习笔记","redis"],"content":"1. Redis 持久化 ","date":"2022-07-29","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/:1:0","tags":["redis","数据库","缓存","分布式","集群"],"title":"高级篇（一）Redis 分布式缓存","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/"},{"categories":["学习笔记","redis"],"content":"1.1 RDB （Redis Database Backup file） Redis数据快照，把内存中的所有数据都记录到磁盘中。 1.1.1 执行时机 执行 save 命令：主进程执行，会阻塞所有命令 执行 bgsave 命令：开启子进程执行 Redis 停机时 触发 RDB 条件时：redis.conf 中配置，如 save 900 1 表示 900 秒内至少一个 key 被修改，则执行 bgsave 1.1.2 RDB 原理 fork采用的是copy-on-write技术： 当主进程执行读操作时，访问共享内存 当主进程执行写操作时，则会拷贝一份数据，执行写操作 极端情况内存占用翻倍 1.1.3 总结 RDB 基本流程：fork (共享内存空间) -\u003e 子进程读内存写入新 RDB 文件 -\u003e 替换旧 RDB 文件 save 60 1000 的含义？ RDB 缺点： 数据丢失风险 耗时长 ","date":"2022-07-29","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/:1:1","tags":["redis","数据库","缓存","分布式","集群"],"title":"高级篇（一）Redis 分布式缓存","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/"},{"categories":["学习笔记","redis"],"content":"1.2 AOF (Append Only File) 1.2.1 AOF 原理 AOF 记录写命令，可以看作命令日志，恢复时把记录的命令执行一遍 1.2.2 AOF 配置 默认关闭 记录频率配置 appendfsync always：立即记录 appendfsync everysec：每秒记录一次(默认) appendfsync no：由操作系统 fsync 1.2.3 AOF 文件重写 AOF会记录对同一个key的多次写操作，但只有最后一次写操作才有意义。通过执行 bgrewriteaof 命令，可以让AOF文件执行重写功能，用最少的命令达到相同效果。 bgrewriteaof 也可以在 redis.conf 中配置阈值触发 ","date":"2022-07-29","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/:1:2","tags":["redis","数据库","缓存","分布式","集群"],"title":"高级篇（一）Redis 分布式缓存","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/"},{"categories":["学习笔记","redis"],"content":"1.3 RDB vs AOF ","date":"2022-07-29","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/:1:3","tags":["redis","数据库","缓存","分布式","集群"],"title":"高级篇（一）Redis 分布式缓存","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/"},{"categories":["学习笔记","redis"],"content":"2. Redis 主从 命令或配置文件创建主从关系：{slaveof | replicaof} \u003cmasterip\u003e \u003cmasterport\u003e ","date":"2022-07-29","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/:2:0","tags":["redis","数据库","缓存","分布式","集群"],"title":"高级篇（一）Redis 分布式缓存","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/"},{"categories":["学习笔记","redis"],"content":"2.2 主从同步原理 2.2.1 全量同步 主从第一次建立连接时，会执行全量同步 master如何得知salve是第一次来连接呢？？ 有几个概念，可以作为判断依据(版本信息)： Replication Id：简称 replid，是数据集的标记，id一致则说明是同一数据集。每一个 master 都有唯一的 replid，slave 则会继承 master 节点的 replid offset：偏移量，随着记录在 repl_backlog 中的数据增多而逐渐增大。slave 完成同步时也会记录当前同步的 offset。如果 slave 的 offset小于 master 的 offset，说明 slave 数据落后于 master，需要更新。 因此slave做数据同步，必须向 master 声明自己的 replication id 和 offset，master 才可以判断到底需要同步哪些数据。 master判断一个节点是否是第一次同步的依据，就是看replid是否一致。 2.2.2 增量同步 如果 slave 重启，执行增量同步 2.2.4 repl_backlog 原理 这个文件是一个固定大小的数组，只不过数组是环形，也就是说角标到达数组末尾后，会再次从0开始读写，这样数组头部的数据就会被覆盖。 直到数组被填满，会覆盖旧数据，如果覆盖的是已同步的数据，没有影响；但如果被覆盖的是未同步的数据，那只能做全量同步了。 ","date":"2022-07-29","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/:2:1","tags":["redis","数据库","缓存","分布式","集群"],"title":"高级篇（一）Redis 分布式缓存","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/"},{"categories":["学习笔记","redis"],"content":"2.3 主从同步优化 在master中配置 repl-diskless-sync yes 启用无磁盘复制，避免全量同步时的磁盘IO。 Redis 单节点上的内存占用不要太大，减少 RDB 导致的过多磁盘 IO 适当提高 repl_backlog 的大小，发现 slave 宕机时尽快实现故障恢复，尽可能避免全量同步 限制一个 master 上的 slave 节点数量，如果实在是太多 slave，则可以采用主-从-从链式结构，减少 master 压力 ","date":"2022-07-29","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/:2:2","tags":["redis","数据库","缓存","分布式","集群"],"title":"高级篇（一）Redis 分布式缓存","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/"},{"categories":["学习笔记","redis"],"content":"2.4 小结 简述全量同步和增量同步区别？ 全量同步：master 将完整内存数据生成 RDB，发送 RDB 到 slave。后续命令则记录在 repl_backlog，逐个发送给 slave。 增量同步：slave 提交自己的 offset 到 master，master 获取 repl_backlog 中从 offset 之后的命令给 slave 什么时候执行全量同步？ slave 节点第一次连接 master 节点时 slave 节点断开时间太久，repl_backlog 中的 offset 已经被覆盖时 什么时候执行增量同步？ slave 节点断开又恢复，并且在 repl_backlog 中能找到 offset 时 ","date":"2022-07-29","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/:2:3","tags":["redis","数据库","缓存","分布式","集群"],"title":"高级篇（一）Redis 分布式缓存","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/"},{"categories":["学习笔记","redis"],"content":"3. Redis 哨兵 ","date":"2022-07-29","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/:3:0","tags":["redis","数据库","缓存","分布式","集群"],"title":"高级篇（一）Redis 分布式缓存","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/"},{"categories":["学习笔记","redis"],"content":"3.1 哨兵原理 3.1.1 集群结构和作用 结构： 作用： 监控 自动故障恢复：将一个 slave 提升为 master， 故障实力恢复后也以新 master 为主 通知：Sentinel 充当 Redis 客户端的服务发现来源，故障结构变化后，会通知客户端(谁是 master，谁是 slave) 3.1.2 集群监控原理 Sentinel 基于心跳机制，每秒发个 ping 命令： 主观下线：某个 Sentinel 发现某个实例超时未响应 客观下线(实际判定为故障节点)：超过指定数量的 Sentinel 都认为该实例主观下线 3.1.3 集群故障恢复原理 选举新的 master： 判断 slave 于 master 断开时间长短，超过指定值则排除该 slave 判断 slave 的 slave-priority，越小越优先 如果 slave-priority 一样，则判断 slave 的 offset，越新越优先 随便挑一个(id 越小越优先) 实现故障转移 向 slave 发送 slaveof no one 命令，让该节点成为 master Sentinel 让其他所有 slave 发送 slaveof \u003cip\u003e \u003cport\u003e，使其成为新 master 的 slave 将故障节点标记为 slave，故障恢复后自动成为新 master 的 slave 3.1.4.小结 Sentinel的三个作用是什么？ 监控 故障转移 通知 Sentinel 如何判断一个 redis 实例是否健康？ 每隔1秒发送一次 ping 命令，如果超过一定时间没有相向则认为是主观下线 如果大多数 sentinel 都认为实例主观下线，则判定服务下线 故障转移步骤有哪些？ 首先选定一个slave作为新的master，执行 slaveof no one 然后让所有节点都执行 slaveof 新master 修改故障节点配置，添加 slaveof 新master ","date":"2022-07-29","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/:3:1","tags":["redis","数据库","缓存","分布式","集群"],"title":"高级篇（一）Redis 分布式缓存","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/"},{"categories":["学习笔记","redis"],"content":"3.2 搭建哨兵集群 配置哨兵: # sentinel.conf port 27001 sentinel announce-ip 192.168.31.57 sentinel monitor mymaster 192.168.31.57 7001 2 sentinel down-after-milliseconds mymaster 5000 sentinel failover-timeout mymaster 60000 dir \"/tmp/s1\" 启动：redis-sentinel s1/sentinel.conf ","date":"2022-07-29","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/:3:2","tags":["redis","数据库","缓存","分布式","集群"],"title":"高级篇（一）Redis 分布式缓存","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/"},{"categories":["学习笔记","redis"],"content":"3.3 redis-py 使用哨兵集群 sentinel = redis.sentinel.Sentinel([('192.168.31.57', 27001), ('192.168.31.57', 27002), ('192.168.31.57', 27003)]) master = sentinel.master_for('mymaster') master.set('foo', 'bar') slave = sentinel.slave_for('mymaster') resp = slave.get('foo') print(resp) ","date":"2022-07-29","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/:3:3","tags":["redis","数据库","缓存","分布式","集群"],"title":"高级篇（一）Redis 分布式缓存","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/"},{"categories":["学习笔记","redis"],"content":"4. Redis 分片集群 ","date":"2022-07-29","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/:4:0","tags":["redis","数据库","缓存","分布式","集群"],"title":"高级篇（一）Redis 分布式缓存","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/"},{"categories":["学习笔记","redis"],"content":"4.1 搭建分片集群 分配集群解决的问题(主从、哨兵无法解决): 海量数据存储 高并发写 分片集群特征： 集群中有多个 master，每个 master 保存不同数据 每个 master 都可以有多个 slave 节点 master 之间通过 ping 监测彼此健康状态 客户端请求可以访问集群任意节点，最终都会被转发到正确节点 创建： redis-cli --cluster create --cluster-replicas 1 192.168.31.57:7001 192.168.31.57:7002 192.168.31.57:7003 192.168.31.57:8001 192.168.31.57:8002 192.168.31.57:8003 --replicas 1或者--cluster-replicas 1 ：指定集群中每个master的副本个数为1，此时节点总数 ÷ (replicas + 1) 得到的就是master的数量。因此节点列表中的前n个就是master，其它节点都是slave节点，随机分配到不同master 查看： redis-cli -p 7001 cluster nodes 连接集群： redis-cli -c -p 7001 # -c Enable cluster mode (follow -ASK and -MOVED redirections). ","date":"2022-07-29","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/:4:1","tags":["redis","数据库","缓存","分布式","集群"],"title":"高级篇（一）Redis 分布式缓存","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/"},{"categories":["学习笔记","redis"],"content":"4.2 散列插槽 Redis 会把每一个 master 节点映射到 0~16383 共 16384 个插槽（hash slot）上。 数据 key 不是与节点绑定，而是与插槽绑定。 redis 会根据 key 的有效部分计算插槽值，分两种情况： key 中包含\"{}\"，且“{}”中至少包含1个字符，“{}”中的部分是有效部分 key 中不包含“{}”，整个key都是有效部分 计算方式：利用 CRC16 算法得到一个 hash 值，然后对 16384 取余，得到的结果就是 slot 值。 4.2.1 小结 Redis 如何判断某个key应该在哪个实例？ 将 16384 个插槽分配到不同的实例 根据 key 的有效部分计算哈希值，对 16384 取余 余数作为插槽，寻找插槽所在实例即可 如何将同一类数据固定的保存在同一个Redis实例？ 这一类数据使用相同的有效部分，例如 key 都以 {typeId} 为前缀 ","date":"2022-07-29","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/:4:2","tags":["redis","数据库","缓存","分布式","集群"],"title":"高级篇（一）Redis 分布式缓存","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/"},{"categories":["学习笔记","redis"],"content":"4.3 集群伸缩 4.3.3 添加新节点到redis redis-cli --cluster add-node 4.3.4 转移插槽 redis-cli --cluster reshard ","date":"2022-07-29","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/:4:3","tags":["redis","数据库","缓存","分布式","集群"],"title":"高级篇（一）Redis 分布式缓存","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/"},{"categories":["学习笔记","redis"],"content":"4.4 故障转移 4.4.1 自动故障转移 当分片集群中一个 master 宕机： 该实例与其他实例失去连接 疑似宕机 确定下线，提升 slave 为 master master 重新上线后成为 slave 4.4.2 手动故障转移 利用 cluster failover 命令可以手动让集群中的某个 master 宕机，切换到执行 cluster failover 命令的这个 slave 节点，实现无感知的数据迁移。 这种 failover 命令可以指定三种模式： 缺省：默认的流程，如图 1~6 步 force：省略了对 offset 的一致性校验 takeover：直接执行第5歩，忽略数据一致性、忽略 master 状态和其它master的意见 ","date":"2022-07-29","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/:4:4","tags":["redis","数据库","缓存","分布式","集群"],"title":"高级篇（一）Redis 分布式缓存","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/"},{"categories":["学习笔记","redis"],"content":"4.5 redis-py 使用分片集群 nodes = [ redis.cluster.ClusterNode(host='192.168.31.57', port=7001), redis.cluster.ClusterNode(host='192.168.31.57', port=7002), redis.cluster.ClusterNode(host='192.168.31.57', port=7003), redis.cluster.ClusterNode(host='192.168.31.57', port=8001), redis.cluster.ClusterNode(host='192.168.31.57', port=8002), redis.cluster.ClusterNode(host='192.168.31.57', port=8003), ] cluster = redis.cluster.RedisCluster(startup_nodes=nodes) cluster.set('foo', 'bar') resp = cluster.get('foo') print(resp) ","date":"2022-07-29","objectID":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/:4:5","tags":["redis","数据库","缓存","分布式","集群"],"title":"高级篇（一）Redis 分布式缓存","uri":"/posts/notes/databases/redis/itheima_redis_lesson/advanced/1-redis-distribute-cache/"},{"categories":null,"content":" 待编辑 ","date":"0001-01-01","objectID":"/about/:0:0","tags":null,"title":"关于","uri":"/about/"}]